"""
æµ‹è¯•é€šè¿‡ MCP è°ƒç”¨ browse_webpage (Docker ç‰ˆæœ¬)
"""
import asyncio
import json
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "scripts" / "pubmed_data_generator"))

from fastmcp import Client


async def test_mcp_browse_webpage():
    """æµ‹è¯• MCP æ–¹å¼è°ƒç”¨ browse_webpage (Docker ç‰ˆæœ¬)"""
    
    # è¯»å– MCP é…ç½®
    mcp_host = os.environ.get("MCP_TRANSPORT_HOST", "127.0.0.1")
    mcp_port = os.environ.get("MCP_TRANSPORT_PORT", "8003")
    mcp_url = f"http://{mcp_host}:{mcp_port}/mcp"
    
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯• MCP browse_webpage (Docker ç‰ˆæœ¬)")
    print("=" * 60)
    print()
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    print("ğŸ“‹ ç¯å¢ƒå˜é‡æ£€æŸ¥:")
    print(f"  MCP_HOST: {mcp_host}")
    print(f"  MCP_PORT: {mcp_port}")
    print(f"  MCP_URL: {mcp_url}")
    
    crawl4ai_vars = {
        "CRAWL4AI_API_URL": os.environ.get("CRAWL4AI_API_URL"),
        "CRAWL4AI_API_KEY": os.environ.get("CRAWL4AI_API_KEY"),
        "CRAWL4AI_BLOCKLIST_PATH": os.environ.get("CRAWL4AI_BLOCKLIST_PATH"),
    }
    
    print(f"\n  Crawl4AI é…ç½®:")
    for key, value in crawl4ai_vars.items():
        if value:
            display_value = value[:50] + "..." if len(value) > 50 else value
            print(f"    âœ… {key}: {display_value}")
        else:
            print(f"    âš ï¸  {key}: æœªè®¾ç½®")
    print()
    
    # åˆ›å»º MCP å®¢æˆ·ç«¯
    client = Client(mcp_url, timeout=120)
    
    try:
        print("ğŸ”Œ è¿æ¥åˆ° MCP æœåŠ¡å™¨...")
        async with client:
            # æµ‹è¯•å·¥å…·è°ƒç”¨
            test_url = "https://en.wikipedia.org/wiki/Python_(programming_language)"
            
            print(f"ğŸ“„ æµ‹è¯• URL: {test_url}")
            print("â³ è°ƒç”¨å·¥å…·: crawl4ai_docker_fetch_webpage_content")
            print("   (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...)")
            print()
            
            # è°ƒç”¨å·¥å…·
            print("ğŸ”§ è°ƒç”¨å‚æ•°:")
            params = {
                "url": test_url,
                "use_ai2_config": True,  # ä½¿ç”¨ AI2 é…ç½®
                "ignore_links": True,
                "bypass_cache": True,
            }
            print(f"   {json.dumps(params, indent=4)}")
            print()
            
            result = await client.call_tool(
                "crawl4ai_docker_fetch_webpage_content",
                params
            )
            
            print("ğŸ” åŸå§‹è¿”å›å¯¹è±¡:")
            print(f"   ç±»å‹: {type(result)}")
            print(f"   hasattr content: {hasattr(result, 'content')}")
            if hasattr(result, "content"):
                print(f"   content é•¿åº¦: {len(result.content) if result.content else 0}")
                if result.content and len(result.content) > 0:
                    print(f"   content[0] ç±»å‹: {type(result.content[0])}")
                    print(f"   hasattr text: {hasattr(result.content[0], 'text')}")
            print()
            
            # è§£æç»“æœ
            if hasattr(result, "content") and result.content:
                if hasattr(result.content[0], "text"):
                    try:
                        raw_result = json.loads(result.content[0].text)
                        print("âœ… æˆåŠŸè§£æ JSON")
                    except json.JSONDecodeError as e:
                        print(f"âŒ JSON è§£æå¤±è´¥: {e}")
                        print(f"   åŸå§‹æ–‡æœ¬ (å‰ 500 å­—ç¬¦): {result.content[0].text[:500]}")
                        raw_result = {"error": f"JSON decode error: {e}"}
                else:
                    raw_result = {"data": str(result.content[0])}
                    print("âš ï¸  content[0] æ²¡æœ‰ text å±æ€§")
            else:
                raw_result = {"error": "No content in response"}
                print("âŒ result æ²¡æœ‰ content æˆ– content ä¸ºç©º")
            
            print()
            
            print("=" * 60)
            print("ğŸ“Š ç»“æœåˆ†æ")
            print("=" * 60)
            
            # æ˜¾ç¤ºå®Œæ•´çš„åŸå§‹ç»“æœç»“æ„
            print("ğŸ” raw_result é”®:")
            for key in raw_result.keys():
                value = raw_result[key]
                if isinstance(value, str) and len(value) > 100:
                    print(f"   - {key}: (å­—ç¬¦ä¸², {len(value)} å­—ç¬¦)")
                else:
                    print(f"   - {key}: {type(value).__name__}")
            print()
            
            if "error" in raw_result:
                error_msg = raw_result['error']
                print(f"âŒ è°ƒç”¨å¤±è´¥: {error_msg}")
                
                # å¦‚æœ error æ˜¯ Noneï¼Œæ˜¾ç¤ºå®Œæ•´çš„ raw_result
                if error_msg is None or error_msg == "None":
                    print()
                    print("ğŸ” å®Œæ•´çš„ raw_result:")
                    print(json.dumps(raw_result, indent=2, ensure_ascii=False))
                
                return False
            
            # æ˜¾ç¤ºç»“æœä¿¡æ¯
            print(f"âœ… è°ƒç”¨æˆåŠŸï¼")
            print()
            
            print(f"ğŸ“Œ è¿”å›å­—æ®µ:")
            for key in raw_result.keys():
                print(f"   - {key}")
            print()
            
            # æ˜¾ç¤º URL
            if "url" in raw_result:
                print(f"ğŸ”— URL: {raw_result['url']}")
            
            # æ˜¾ç¤ºæˆåŠŸçŠ¶æ€
            if "success" in raw_result:
                status = "âœ… æˆåŠŸ" if raw_result["success"] else "âŒ å¤±è´¥"
                print(f"ğŸ“Š çŠ¶æ€: {status}")
            
            # æ˜¾ç¤ºå†…å®¹é•¿åº¦
            if "markdown" in raw_result:
                markdown_len = len(raw_result["markdown"])
                print(f"ğŸ“ Markdown é•¿åº¦: {markdown_len:,} å­—ç¬¦")
                print(f"ğŸ“„ å†…å®¹é¢„è§ˆ (å‰ 300 å­—ç¬¦):")
                print("-" * 60)
                print(raw_result["markdown"][:300])
                print("-" * 60)
                print(f"ğŸ“„ å†…å®¹ç»“å°¾ (å 200 å­—ç¬¦):")
                print("-" * 60)
                print(raw_result["markdown"][-200:])
                print("-" * 60)
            
            if "fit_markdown" in raw_result and raw_result["fit_markdown"]:
                fit_len = len(raw_result["fit_markdown"])
                print(f"âœ‚ï¸  Fit Markdown é•¿åº¦: {fit_len:,} å­—ç¬¦")
            
            # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if "error" in raw_result and raw_result["error"]:
                print(f"âš ï¸  é”™è¯¯ä¿¡æ¯: {raw_result['error']}")
            
            print()
            print("=" * 60)
            print("âœ… æµ‹è¯•å®Œæˆï¼browse_webpage (Docker ç‰ˆæœ¬) å·¥ä½œæ­£å¸¸")
            print("=" * 60)
            
            return True
            
    except Exception as e:
        print("=" * 60)
        print(f"âŒ æµ‹è¯•å¤±è´¥")
        print("=" * 60)
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        print()
        
        # æ‰“å°å®Œæ•´çš„ traceback
        import traceback
        print("ğŸ“‹ å®Œæ•´é”™è¯¯å †æ ˆ:")
        print("-" * 60)
        traceback.print_exc()
        print("-" * 60)
        print()
        
        # ç»™å‡ºæ’æŸ¥å»ºè®®
        print("ğŸ’¡ æ’æŸ¥å»ºè®®:")
        print("1. ç¡®ä¿ MCP æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ:")
        print(f"   curl http://{mcp_host}:{mcp_port}/health")
        print()
        print("2. ç¡®ä¿ç¯å¢ƒå˜é‡å·²è®¾ç½®:")
        print("   export CRAWL4AI_API_URL='http://localhost:11235'")
        print("   export CRAWL4AI_API_KEY='mamba-out'")
        print("   export CRAWL4AI_BLOCKLIST_PATH='/path/to/blocklist.txt'")
        print()
        print("3. ç¡®ä¿ Crawl4AI Docker å®¹å™¨æ­£åœ¨è¿è¡Œ:")
        print("   docker ps | grep crawl4ai")
        print()
        
        return False


if __name__ == "__main__":
    success = asyncio.run(test_mcp_browse_webpage())
    sys.exit(0 if success else 1)

