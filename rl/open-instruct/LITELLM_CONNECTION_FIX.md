# LiteLLM Connection Error è¯Šæ–­å’Œä¿®å¤æŒ‡å—

## é—®é¢˜æè¿°

è®­ç»ƒæ—¶å‡ºç°ä»¥ä¸‹é”™è¯¯ï¼š
```
Error in run_litellm_async: litellm.APIError: APIError: OpenAIException - Connection error. LiteLLM Retried: 5 times
Generated instance-wise adaptive rubrics: None
```

## é—®é¢˜å®šä½

### é”™è¯¯å‘ç”Ÿä½ç½®

1. **ä»£ç æ–‡ä»¶**: `open_instruct/search_rewards/utils/run_utils.py`
   - å‡½æ•°: `run_litellm_async()` (ç¬¬237-303è¡Œ)
   - é—®é¢˜: LiteLLMæ— æ³•è¿æ¥åˆ°OpenRouter API

2. **è°ƒç”¨é“¾è·¯**:
   ```
   grpo_fast.py (ç¬¬2850è¡Œ) 
   -> _generate_instance_wise_adaptive_rubrics()
   -> generate_instance_wise_adaptive_rubrics() (rubric_utils.py ç¬¬376è¡Œ)
   -> run_litellm_async() (run_utils.py ç¬¬237è¡Œ)
   -> litellm.acompletion() è¿æ¥å¤±è´¥
   ```

### é…ç½®ä¿¡æ¯ï¼ˆæ¥è‡ªtrain_dr_tulu.shï¼‰

```bash
export http_proxy="http://httpproxy.glm.ai:8888"
export https_proxy="http://httpproxy.glm.ai:8888"
export OPENAI_API_KEY="sk-or-v1-..."
export OPENAI_API_BASE="https://openrouter.ai/api/v1"
export RUBRIC_JUDGE_MODEL=gpt-4.1-mini
```

## å¯èƒ½çš„åŸå› 

### 1. ä»£ç†é—®é¢˜ (æœ€å¯èƒ½)
- ä»£ç†æœåŠ¡å™¨ `httpproxy.glm.ai:8888` ä¸å¯ç”¨
- ä»£ç†é˜»æ­¢äº†HTTPSè¿æ¥åˆ°openrouter.ai
- ä»£ç†è¶…æ—¶è®¾ç½®å¤ªçŸ­

### 2. APIé…ç½®é—®é¢˜
- OpenRouter API keyæ— æ•ˆæˆ–è¿‡æœŸ
- OPENAI_API_BASE URLé”™è¯¯
- æ¨¡å‹åç§°ä¸æ­£ç¡®ï¼ˆgpt-4.1-miniå¯èƒ½ä¸å­˜åœ¨ï¼‰

### 3. ç½‘ç»œé—®é¢˜
- é˜²ç«å¢™é˜»æ­¢è¿æ¥
- DNSè§£æå¤±è´¥
- ç½‘ç»œä¸ç¨³å®šå¯¼è‡´è¶…æ—¶

### 4. å¹¶å‘é—®é¢˜
- å¹¶å‘è¯·æ±‚è¿‡å¤šè§¦å‘rate limiting
- åŒæ—¶å‘èµ·çš„è¯·æ±‚è¶…è¿‡äº†APIé™åˆ¶

## æµ‹è¯•æ–¹æ³•

æˆ‘å·²ç»ä¸ºä½ åˆ›å»ºäº†ä¸¤ä¸ªæµ‹è¯•è„šæœ¬ï¼š

### 1. åŸºç¡€è¿æ¥æµ‹è¯•
```bash
cd /Users/liyc/Desktop/dr-tulu/rl/open-instruct
python test_litellm_connection.py
```

è¿™ä¸ªè„šæœ¬ä¼šæµ‹è¯•ï¼š
- âœ… åŸºæœ¬LiteLLMè¿æ¥
- âœ… ä¸ä½¿ç”¨ä»£ç†çš„è¿æ¥
- âœ… è°ƒè¯•æ¨¡å¼
- âœ… Rubricç”Ÿæˆæ¨¡æ‹Ÿ

### 2. å®Œæ•´Rubricç”Ÿæˆæµ‹è¯•
```bash
cd /Users/liyc/Desktop/dr-tulu/rl/open-instruct
python test_rubric_generation.py
```

è¿™ä¸ªè„šæœ¬ä¼šæµ‹è¯•ï¼š
- âœ… ä»£ç†è¿æ¥æ€§
- âœ… LiteLLMç›´æ¥è°ƒç”¨
- âœ… ç®€å•rubricç”Ÿæˆ
- âœ… å¸¦existing rubricsçš„ç”Ÿæˆ

## ä¿®å¤æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: ç¦ç”¨ä»£ç†ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰

åœ¨ `train_dr_tulu.sh` ä¸­æ³¨é‡Šæ‰ä»£ç†è®¾ç½®ï¼š

```bash
# export http_proxy="http://httpproxy.glm.ai:8888"
# export https_proxy="http://httpproxy.glm.ai:8888"
# export no_proxy="127.0.0.1,localhost,platform.glm.ai,::1,$no_proxy"
```

### æ–¹æ¡ˆ2: ä¿®æ”¹æ¨¡å‹åç§°

OpenRouterçš„æ¨¡å‹åç§°æ ¼å¼å¯èƒ½éœ€è¦å¸¦providerå‰ç¼€ï¼š

```bash
# åŸæ¥çš„
export RUBRIC_JUDGE_MODEL=gpt-4.1-mini

# æ”¹ä¸ºä»¥ä¸‹ä¹‹ä¸€
export RUBRIC_JUDGE_MODEL=openai/gpt-4-turbo-preview
export RUBRIC_JUDGE_MODEL=openai/gpt-4o-mini
export RUBRIC_JUDGE_MODEL=anthropic/claude-3-haiku
```

### æ–¹æ¡ˆ3: å¢åŠ è¶…æ—¶æ—¶é—´

åœ¨ `run_utils.py` ä¸­ä¿®æ”¹é»˜è®¤è¶…æ—¶ï¼š

```python
# ç¬¬284-286è¡Œ
chat_kwargs["timeout"] = chat_kwargs.get(
    "timeout", float(os.environ.get("LITELLM_DEFAULT_TIMEOUT", "600"))
)

# æ”¹ä¸ºæ›´é•¿çš„è¶…æ—¶
chat_kwargs["timeout"] = chat_kwargs.get(
    "timeout", float(os.environ.get("LITELLM_DEFAULT_TIMEOUT", "1200"))  # 20åˆ†é’Ÿ
)
```

æˆ–åœ¨è®­ç»ƒè„šæœ¬ä¸­è®¾ç½®ï¼š
```bash
export LITELLM_DEFAULT_TIMEOUT=1200
```

### æ–¹æ¡ˆ4: ä¿®æ”¹é‡è¯•ç­–ç•¥

åœ¨ `run_utils.py` ç¬¬267è¡Œï¼š

```python
# å¢åŠ é‡è¯•æ¬¡æ•°å’Œä½¿ç”¨fallback
chat_kwargs["num_retries"] = chat_kwargs.get("num_retries", 10)  # ä»5æ”¹ä¸º10
chat_kwargs["fallbacks"] = chat_kwargs.get("fallbacks", ["openai/gpt-4o-mini"])
```

### æ–¹æ¡ˆ5: ä¸´æ—¶ç¦ç”¨adaptive rubricï¼ˆè®­ç»ƒç»§ç»­ï¼‰

å¦‚æœrubricä¸æ˜¯å¿…éœ€çš„ï¼Œå¯ä»¥ä¸´æ—¶ç¦ç”¨ï¼š

åœ¨ `train_dr_tulu.sh` ä¸­ï¼š
```bash
--apply_adaptive_rubric_reward false \  # æ”¹ä¸ºfalse
```

## è°ƒè¯•å‘½ä»¤

### 1. æµ‹è¯•ä»£ç†è¿æ¥
```bash
# æµ‹è¯•ä»£ç†æ˜¯å¦èƒ½è®¿é—®OpenRouter
curl -x http://httpproxy.glm.ai:8888 -I https://openrouter.ai

# æµ‹è¯•ä¸ä½¿ç”¨ä»£ç†
curl -I https://openrouter.ai
```

### 2. æµ‹è¯•API key
```bash
curl https://openrouter.ai/api/v1/models \
  -H "Authorization: Bearer sk-or-v1-..." \
  -H "HTTP-Referer: http://localhost:3000" \
  -H "X-Title: Test"
```

### 3. æ‰‹åŠ¨æµ‹è¯•LiteLLM
```python
import litellm
litellm.set_verbose = True

response = litellm.completion(
    model="openai/gpt-4o-mini",
    messages=[{"role": "user", "content": "Hello"}],
    api_key="sk-or-v1-...",
    api_base="https://openrouter.ai/api/v1"
)
print(response)
```

## æ¨èæ–¹æ¡ˆ

**ä¼˜å…ˆçº§æ’åº**ï¼š

1. ğŸ¥‡ **å…ˆè¿è¡Œæµ‹è¯•è„šæœ¬ç¡®è®¤é—®é¢˜**
   ```bash
   python test_litellm_connection.py
   ```

2. ğŸ¥ˆ **å¦‚æœæ˜¯ä»£ç†é—®é¢˜ï¼Œå°è¯•ç¦ç”¨ä»£ç†**
   
3. ğŸ¥‰ **å¦‚æœæ˜¯æ¨¡å‹åç§°é—®é¢˜ï¼Œæ”¹ä¸ºæ ‡å‡†çš„OpenRouteræ¨¡å‹å**
   ```bash
   export RUBRIC_JUDGE_MODEL=openai/gpt-4o-mini
   ```

4. ğŸ… **å¢åŠ è¶…æ—¶å’Œé‡è¯•æ¬¡æ•°**
   ```bash
   export LITELLM_DEFAULT_TIMEOUT=1200
   ```

## é¢„é˜²æªæ–½

### 1. æ·»åŠ æ›´å¥½çš„é”™è¯¯å¤„ç†

åœ¨ `rubric_utils.py` çš„ `generate_instance_wise_adaptive_rubrics` å‡½æ•°ä¸­ï¼š

```python
try:        
    resp = await run_litellm_async(
            model_name=model_name,
            user_prompt=prompt,
        )
    
    # æ£€æŸ¥è¿”å›å€¼
    if not resp or resp == "":
        print(f"Warning: Empty response from LiteLLM for model {model_name}")
        return None
    
    obj = extract_json_from_response(resp)
    print(f"Generated instance-wise adaptive rubrics: {obj}")
except Exception as e:
    print(f"Error generating instance-wise adaptive rubrics: {e}")
    return None
```

### 2. æ·»åŠ è¿æ¥é¢„æ£€æŸ¥

åœ¨è®­ç»ƒå¼€å§‹å‰ï¼Œå…ˆæµ‹è¯•LiteLLMè¿æ¥ï¼š

```python
async def check_litellm_connection():
    try:
        resp = await run_litellm_async(
            model_name=os.environ.get("RUBRIC_JUDGE_MODEL"),
            user_prompt="Hello",
            max_tokens=10,
            timeout=30
        )
        if resp:
            print("âœ… LiteLLM connection check passed")
            return True
        else:
            print("âŒ LiteLLM connection check failed: empty response")
            return False
    except Exception as e:
        print(f"âŒ LiteLLM connection check failed: {e}")
        return False
```

## ç›¸å…³æ–‡ä»¶

- è®­ç»ƒè„šæœ¬: `train_dr_tulu.sh`
- LiteLLMè°ƒç”¨: `open_instruct/search_rewards/utils/run_utils.py`
- Rubricç”Ÿæˆ: `open_instruct/search_rewards/utils/rubric_utils.py`
- ä¸»è®­ç»ƒé€»è¾‘: `open_instruct/grpo_fast.py`

## è”ç³»æ”¯æŒ

å¦‚æœä»¥ä¸Šæ–¹æ³•éƒ½ä¸èƒ½è§£å†³é—®é¢˜ï¼Œå¯ä»¥ï¼š

1. æ£€æŸ¥OpenRouterçš„çŠ¶æ€é¡µé¢: https://status.openrouter.ai/
2. æŸ¥çœ‹OpenRouteræ–‡æ¡£: https://openrouter.ai/docs
3. æäº¤issueåˆ°LiteLLM: https://github.com/BerriAI/litellm/issues

