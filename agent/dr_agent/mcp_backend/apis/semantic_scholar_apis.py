import os
import warnings
from pathlib import Path
from typing import Generic, List, Optional, TypeVar, Union
import time

import requests
from dotenv import load_dotenv
from pydantic import BaseModel, Field, HttpUrl
from requests.exceptions import RequestException

from ..cache import cached
from .data_model import (
    PaperSnippet,
    SemanticScholarAuthorData,
    SemanticScholarPaperData,
)

load_dotenv(Path(__file__).resolve().parents[2] / ".env")

S2_API_KEY = os.getenv("S2_API_KEY")
TIMEOUT = int(os.getenv("API_TIMEOUT", 10))
S2_SEARCH_LIMIT = 100

# å…è´¹è°ƒç”¨ä½¿ç”¨å®˜æ–¹åœ°å€
S2_GRAPH_API_URL_FREE = "https://api.semanticscholar.org/graph/v1"
S2_RECOMMENDATIONS_API_URL_FREE = "https://api.semanticscholar.org/recommendations/v1"

# ä»˜è´¹è°ƒç”¨ä½¿ç”¨ä»£ç†åœ°å€
S2_GRAPH_API_URL_PAID = "https://lifuai.com/api/v1/graph/v1"
S2_RECOMMENDATIONS_API_URL_PAID = "https://lifuai.com/api/v1/recommendations/v1"

# é»˜è®¤ä½¿ç”¨ä»˜è´¹åœ°å€ï¼ˆå‘åå…¼å®¹ï¼‰
S2_GRAPH_API_URL = S2_GRAPH_API_URL_PAID
S2_RECOMMENDATIONS_API_URL = S2_RECOMMENDATIONS_API_URL_PAID

# å…è´¹è°ƒç”¨é‡è¯•æ¬¡æ•°
FREE_RETRY_ATTEMPTS = 3

# authors.authorId,authors.paperCount,authors.citationCount
S2_PAPER_SEARCH_FIELDS = "paperId,corpusId,url,title,abstract,authors,authors.name,year,venue,citationCount,openAccessPdf,externalIds,isOpenAccess"
S2_PAPER_CITATION_FIELDS = (
    "paperId,corpusId,contexts,intents,isInfluential,title,abstract,venue,year,authors"
)
S2_PAPER_REFERENCE_FIELDS = (
    "paperId,corpusId,contexts,intents,isInfluential,title,abstract,venue,year,authors"
)
S2_PAPER_RECOMMENDATION_FIELDS = "paperId,corpusId,title,abstract,year,venue"

T = TypeVar("T")


class ApiResponse(BaseModel, Generic[T]):
    total: int
    offset: int = Field(..., description="Offset for pagination")
    next: int = Field(..., description="Next page offset")
    data: List[T] = Field(..., description="Data items")


# This is because the Semantic Scholar API right now doesn't support
# pagination for snippets, so we will ignore the offset and limit.
class PaperSnippetApiResponse(BaseModel, Generic[T]):
    data: List[T] = Field(..., description="Data items")


# This is a subset of the supported query parameters for the Semantic Scholar API.
# We include the most important ones and remove some for clarity. (e.g., there are year and
# publicationDateOrYear, which can be confusing to the model).
def _make_request_with_retry(
    url: str,
    params: dict,
    timeout: int,
    method: str = "GET",
    json_data: dict = None,
) -> dict:
    """
    å…ˆå°è¯•å…è´¹è°ƒç”¨ï¼ˆè®¿é—®å®˜æ–¹åœ°å€ï¼Œä¸å¸¦ API keyï¼‰ï¼Œé‡è¯• 3 æ¬¡ã€‚
    å¦‚æœéƒ½å¤±è´¥ï¼Œå†ä½¿ç”¨ä»˜è´¹è°ƒç”¨ï¼ˆè®¿é—®ä»£ç†åœ°å€ï¼Œå¸¦ API keyï¼‰ã€‚
    """
    # å°†ä»˜è´¹åœ°å€çš„ URL æ›¿æ¢ä¸ºå…è´¹åœ°å€
    free_url = url.replace(S2_GRAPH_API_URL_PAID, S2_GRAPH_API_URL_FREE)
    free_url = free_url.replace(S2_RECOMMENDATIONS_API_URL_PAID, S2_RECOMMENDATIONS_API_URL_FREE)
    
    # è·å–ä»£ç†è®¾ç½®ï¼ˆä»ç¯å¢ƒå˜é‡ï¼‰
    # requests ä¼šè‡ªåŠ¨ä» http_proxy/https_proxy ç¯å¢ƒå˜é‡è¯»å–
    # ä½†ä¸ºäº†ç¡®ä¿æ­£ç¡®ï¼Œæˆ‘ä»¬æ˜¾å¼è®¾ç½®
    proxies = None
    if os.getenv('http_proxy') or os.getenv('https_proxy'):
        proxies = {
            'http': os.getenv('http_proxy'),
            'https': os.getenv('https_proxy'),
        }
        print(f"ğŸŒ ä½¿ç”¨ä»£ç†: {proxies}")
    
    def _is_valid_response(response_json: dict) -> bool:
        """æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯é”™è¯¯æ¶ˆæ¯ï¼‰"""
        # å¦‚æœå“åº”åªåŒ…å« 'message' å­—æ®µï¼Œé€šå¸¸æ˜¯é”™è¯¯
        if 'message' in response_json and len(response_json) == 1:
            return False
        # å¦‚æœåŒ…å« 'error' å­—æ®µï¼Œæ˜¯é”™è¯¯
        if 'error' in response_json:
            return False
        # å…¶ä»–æƒ…å†µè®¤ä¸ºæ˜¯æœ‰æ•ˆå“åº”
        return True
    
    # å…ˆå°è¯•å…è´¹è°ƒç”¨ï¼ˆä½¿ç”¨å®˜æ–¹åœ°å€ï¼‰
    for attempt in range(FREE_RETRY_ATTEMPTS):
        try:
            if method.upper() == "POST":
                res = requests.post(
                    free_url,  # ä½¿ç”¨å…è´¹åœ°å€
                    params=params,
                    json=json_data,
                    headers=None,  # ä¸å¸¦ API key
                    timeout=timeout,
                    proxies=proxies,  # ä½¿ç”¨ä»£ç†
                )
            else:
                res = requests.get(
                    free_url,  # ä½¿ç”¨å…è´¹åœ°å€
                    params=params,
                    headers=None,  # ä¸å¸¦ API key
                    timeout=timeout,
                    proxies=proxies,  # ä½¿ç”¨ä»£ç†
                )
            
            res.raise_for_status()
            result = res.json()
            
            # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦æœ‰æ•ˆ
            if not _is_valid_response(result):
                error_msg = result.get('message', result.get('error', 'Unknown error'))
                raise Exception(f"API è¿”å›é”™è¯¯: {error_msg}")
            
            print(f"âœ“ å…è´¹è°ƒç”¨æˆåŠŸ (å°è¯• {attempt + 1}/{FREE_RETRY_ATTEMPTS}) - åœ°å€: {free_url}")
            return result
        
        except Exception as e:
            print(f"âœ— å…è´¹è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{FREE_RETRY_ATTEMPTS}): {str(e)}")
            if attempt < FREE_RETRY_ATTEMPTS - 1:
                time.sleep(1)  # é‡è¯•å‰ç­‰å¾… 1 ç§’
            continue
    
    # æ‰€æœ‰å…è´¹è°ƒç”¨éƒ½å¤±è´¥ï¼Œä½¿ç”¨ä»˜è´¹è°ƒç”¨ï¼ˆä½¿ç”¨ä»£ç†åœ°å€ï¼‰
    print(f"æ‰€æœ‰å…è´¹è°ƒç”¨å¤±è´¥ï¼Œåˆ‡æ¢åˆ°ä»˜è´¹è°ƒç”¨ - åœ°å€: {url}")
    try:
        if method.upper() == "POST":
            res = requests.post(
                url,  # ä½¿ç”¨ä»˜è´¹åœ°å€ï¼ˆåŸ URLï¼‰
                params=params,
                json=json_data,
                headers={"x-api-key": S2_API_KEY} if S2_API_KEY else None,
                timeout=timeout,
                proxies=proxies,  # ä½¿ç”¨ä»£ç†
            )
        else:
            res = requests.get(
                url,  # ä½¿ç”¨ä»˜è´¹åœ°å€ï¼ˆåŸ URLï¼‰
                params=params,
                headers={"x-api-key": S2_API_KEY} if S2_API_KEY else None,
                timeout=timeout,
                proxies=proxies,  # ä½¿ç”¨ä»£ç†
            )
        
        res.raise_for_status()
        result = res.json()
        
        # æ£€æŸ¥ä»˜è´¹è°ƒç”¨çš„å“åº”æ˜¯å¦æœ‰æ•ˆ
        if not _is_valid_response(result):
            error_msg = result.get('message', result.get('error', 'Unknown error'))
            raise Exception(f"API è¿”å›é”™è¯¯: {error_msg}")
        
        print("âœ“ ä»˜è´¹è°ƒç”¨æˆåŠŸ")
        return result
    
    except Exception as e:
        print(f"âœ— ä»˜è´¹è°ƒç”¨ä¹Ÿå¤±è´¥: {str(e)}")
        raise


class SemanticScholarSearchQueryParams(BaseModel):
    query: str = Field(
        ...,
        description="A plain-text search query string.",
        examples=["BERT"],
    )
    year: Optional[str] = Field(
        None,
        description="Restrict results to the given range of publication year (inclusive).",
        examples=["2015-2020", "2015-", "-2015"],
    )
    minCitationCount: Optional[int] = Field(
        None,
        description="Restrict results to only include papers with the minimum number of citations, inclusive.",
        examples=[100, 1000],
    )
    sort: Optional[str] = Field(
        None,
        description="Sort results by publicationDate and citationCount in ascending or descending order.",
        examples=[
            "citationCount:asc",
            "publicationDate:desc",
        ],
    )
    venue: Optional[str] = Field(
        None,
        description="Restrict results by venue. Input could be an ISO4 abbreviation.",
        examples=["ACL", "EMNLP"],
    )


################## NOT EXPLICITLY USED ##################
# fields: Optional[str] = Field(None, description="A comma-separated list of the fields to be returned.")
# publicationTypes: Optional[str] = Field(None, description="Restrict results by publication types, use a comma-separated list.")
# openAccessPdf: Optional[bool] = Field(None, description="Restrict results to only include papers with a public PDF.")
# publicationDateOrYear: Optional[str] = Field(None, description="""
# Restrict results to the given range of publication dates or years (inclusive).
# Accepts the format <startDate>:<endDate>. Prefixes supported for specific ranges.""")
# fieldsOfStudy: Optional[str] = Field(None, desc="Restrict results to given field-of-study, using the s2FieldsOfStudy paper field.")
# offset: Optional[int] = Field(0, description="Start with the element at this position in the list.")
# limit: Optional[int] = Field(100, description="The maximum number of results to return, must be <= 100.")


@cached()
def search_semantic_scholar_keywords(
    query_params: SemanticScholarSearchQueryParams,
    *,
    offset: int = 0,
    limit: int = 25,
    fields: str = S2_PAPER_SEARCH_FIELDS,
    timeout: int = TIMEOUT,
) -> ApiResponse[SemanticScholarPaperData]:

    results = _make_request_with_retry(
        url=f"{S2_GRAPH_API_URL}/paper/search",
        params={
            "offset": offset,
            "limit": limit,
            "fields": fields,
            **query_params.model_dump(exclude_none=True),
        },
        timeout=timeout,
        method="GET",
    )

    # For each paper, if we know their external arxiv ids, we can construct the open access pdf link
    # if it is not already provided.
    if "data" in results:
        for paper in results["data"]:
            if paper.get("openAccessPdf") is None:
                if paper["externalIds"]:
                    if "ArXiv" in paper["externalIds"]:
                        paper["openAccessPdf"] = dict(
                            url=f"https://arxiv.org/pdf/{paper['externalIds']['ArXiv']}",
                        )
                    if "ACL" in paper["externalIds"]:
                        paper["openAccessPdf"] = dict(
                            url=f"https://www.aclweb.org/anthology/{paper['externalIds']['ACL']}.pdf",
                        )
    else:
        results["data"] = []

    return results


class SemanticScholarSnippetSearchQueryParams(BaseModel):
    query: str = Field(
        ...,
        description="A plain-text search query string.",
        examples=["BERT"],
    )
    year: Optional[str] = Field(
        None,
        description="Restrict results to the given range of publication year (inclusive).",
        examples=["2015-2020", "2015-", "-2015"],
    )
    paperIds: Optional[Union[str, List[str]]] = Field(
        None,
        description="Restricts results to snippets from specific papers. To specify papers, provide a comma-separated list of their IDs. You can provide up to approximately 100 IDs.",
        examples=[
            "649def34f8be52c8b66281af98ae884c09aef38b",
            "649def34f8be52c8b66281af98ae884c09aef38b,CorpusId:215416146",
        ],
    )
    venue: Optional[str] = Field(
        None,
        description="Restrict results by venue. Input could be an ISO4 abbreviation.",
        examples=["ACL", "EMNLP"],
    )


@cached()
def search_semantic_scholar_snippets(
    query_params: SemanticScholarSnippetSearchQueryParams,
    *,
    offset: int = 0,
    limit: int = 10,
    timeout: int = TIMEOUT,
) -> PaperSnippetApiResponse[PaperSnippet]:
    if offset:
        warnings.warn(
            "Right now the API does not support pagination, so the offset will be ignored."
        )

    params = query_params.model_dump(exclude_none=True)
    if (query_params.paperIds or "paperIds" in query_params) and isinstance(
        query_params.paperIds, list
    ):
        params["paperIds"] = ",".join(query_params.paperIds)

    results = _make_request_with_retry(
        url=f"{S2_GRAPH_API_URL}/snippet/search",
        params={
            # "offset": offset,
            "limit": limit,
            **params,
        },
        timeout=timeout,
        method="GET",
    )
    return results


def search_semantic_scholar_bulk_api(
    query_params: SemanticScholarSearchQueryParams,
    *,
    fields: str = S2_PAPER_SEARCH_FIELDS,
    timeout: int = TIMEOUT,
) -> ApiResponse[SemanticScholarPaperData]:

    results = _make_request_with_retry(
        url=f"{S2_GRAPH_API_URL}/paper/search/bulk",
        params={
            "fields": fields,
            **query_params.model_dump(exclude_none=True),
        },
        timeout=timeout,
        method="GET",
    )

    # For each paper, if we know their external arxiv ids, we can construct the open access pdf link
    # if it is not already provided.
    if "data" in results:
        for paper in results["data"]:
            if paper.get("openAccessPdf") is None:
                if paper["externalIds"]:
                    if "ArXiv" in paper["externalIds"]:
                        paper["openAccessPdf"] = dict(
                            url=f"https://arxiv.org/pdf/{paper['externalIds']['ArXiv']}",
                        )
                    if "ACL" in paper["externalIds"]:
                        paper["openAccessPdf"] = dict(
                            url=f"https://www.aclweb.org/anthology/{paper['externalIds']['ACL']}.pdf",
                        )
    else:
        results["data"] = []

    return results


def download_paper_details(
    paper_id: str,
    *,
    fields: str = S2_PAPER_SEARCH_FIELDS,
    timeout: int = TIMEOUT,
):
    results = _make_request_with_retry(
        url=f"{S2_GRAPH_API_URL}/paper/{paper_id}",
        params={
            "fields": fields,
        },
        timeout=timeout,
        method="GET",
    )
    return results


def download_paper_references(
    paper_id: str,
    *,
    offset: int = 0,
    limit: int = 100,
    fields: str = S2_PAPER_REFERENCE_FIELDS,
    timeout: int = TIMEOUT,
):
    results = _make_request_with_retry(
        url=f"{S2_GRAPH_API_URL}/paper/{paper_id}/references",
        params={
            "offset": offset,
            "limit": limit,
            "fields": fields,
        },
        timeout=timeout,
        method="GET",
    )
    return results


def download_paper_citations(
    paper_id: str,
    *,
    offset: int = 0,
    limit: int = 100,
    fields: str = S2_PAPER_CITATION_FIELDS,
    timeout: int = TIMEOUT,
):
    results = _make_request_with_retry(
        url=f"{S2_GRAPH_API_URL}/paper/{paper_id}/citations",
        params={
            "offset": offset,
            "limit": limit,
            "fields": fields,
        },
        timeout=timeout,
        method="GET",
    )
    return results


def download_paper_details_batch(
    paper_ids: List[str],
    *,
    fields: str = S2_PAPER_SEARCH_FIELDS,
    timeout: int = TIMEOUT,
):
    results = _make_request_with_retry(
        url=f"{S2_GRAPH_API_URL}/paper/batch",
        params={"fields": fields},
        timeout=timeout,
        method="POST",
        json_data={"ids": paper_ids},
    )
    return results


# Example usage:
if __name__ == "__main__":
    result1 = search_semantic_scholar_snippets(
        SemanticScholarSnippetSearchQueryParams(
            query="how to set learning rate in state space models?",
        ),
    )
