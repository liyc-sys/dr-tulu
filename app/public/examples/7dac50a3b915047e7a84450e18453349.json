{
  "example_id": "9",
  "problem": "What are Flow Matching Models?",
  "final_response": "# What Flow Matching Models Are\n\nFlow Matching Models (FM) learn a continuous flow that transports a simple prior (typically isotropic Gaussian noise) to a target data distribution via a time-dependent vector field, and approximate this field with a neural network so that sampling reduces to numerical integration of an ODE<cite id=\"9c657d74-4\">Flow Matching (FM) (Lipman et al. 2022;Liu, Gong, and Liu 2022;Albergo and Vanden-Eijnden 2022) is a generative modeling framework that learns a velocity field to transform a source distribution into a target distribution through a continuous flow</cite><cite id=\"9c657d74-2\">The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows and diffusion models</cite>. In this view, FM generalizes continuous normalizing flows (CNFs) by removing the need to simulate trajectories during training while providing a unifying perspective that includes diffusion (modeled as stochastic differential equations) as a special case<cite id=\"9c657d74-4\">FM generalizes Continuous Normalizing Flows by removing the need for simulation during training, and diffusion models can be seen as a special case where the probability path is defined via stochastic differential equations</cite>.\n\n# Core Formulation: From Discrete Trajectories to Continuous Flows\n\nIn practice, FM specifies a sequence of linear interpolations between a data sample x1 and a random noise sample x0 over t∈[0,1], forming a forward path and defining a training example (x0, x1, t) via xt = (1−t) x0 + t x1<cite id=\"bbd08e4c-1\">During training, a training example is constructed by first sampling a target sample x1, drawing noise x0∼N(0,1), and selecting a timestep t∈[0,1], then defining the example via the linear interpolation xt = (1−t) x0 + t x1</cite>. The model is trained to approximate the ODE velocity vt = dx/dt along these paths, so that integrating the learned vector field from noise to data recovers an image sample<cite id=\"bbd08e4c-1\">The model is trained to approximate the velocity defined by an ordinary differential equation (ODE), vt = dx/dt, enabling it to guide the transformation from the intermediate sample xt to the real data sample x1</cite>. Conceptually, the family of interpolants defines a path of probability distributions between a reference (noise) and the data distribution, situating FM between normalizing flows and diffusion<cite id=\"9c657d74-2\">These models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution, and are closely related to both normalizing flows and diffusion models</cite>.\n\n# Training Targets: Velocity Regression and Deterministic Mapping\n\nUnlike denoising diffusion models that predict εθ(xt, t)≈(xt−x0)/√t, FM trains a neural network to regress the time-dependent vector field F(t,x) (the ODE’s velocity) along the learned interpolants, turning each FM training instance into a supervised regression task on the trajectory between noise and data<cite id=\"bbd08e4c-1\">A training example is defined through a linear interpolation between x0 and x1 at time t, and the model is trained to approximate the ODE velocity vt = dx/dt along this interpolation</cite>. This formulation yields a deterministic mapping from noise to data once F is learned, enabling fast generation by integrating the learned flow rather than running many stochastic diffusion steps<cite id=\"9c657d74-0\">Flow matching is emerging as a competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution, favored for fast generation and reduced need for large NFE</cite>. FM’s ability to interpolate between arbitrary distributions (not just noise-to-image) further generalizes its applicability beyond denoising, e.g., image-to-image translation<cite id=\"bbd08e4c-1\">A notable advantage of Flow Matching is its ability to interpolate between two arbitrary distributions, extending beyond noise-to-image scenarios and enabling image-to-image translation</cite>.\n\n# Sampling via ODE Solvers: Dense Trajectories and Step Counts\n\nTo generate samples, FM integrates the learned vector field from the prior (e.g., xT = x0) to the data distribution (e.g., x0≈0), and this integration can be performed with efficient ODE solvers to reduce the number of steps needed for high-quality outputs<cite id=\"9c657d74-3\">Flow-matching learns a time-dependent vector field to transform probability distributions and provides an efficient method for modeling ODEs via straightforward vector-field regression loss</cite>. The DPM-Solver line of work provides fast ODE-based samplers that typically converge in around 10 steps, improving upon earlier Eulerian or first-order methods and approaching or surpassing diffusion quality at comparable function evaluations<cite id=\"ef8d8842-3\">DPM-Solver (Lu et al., 2022a) and DPM-Solver++ (Lu et al., 2022b) utilize multistep methods for differential discretization and reduce the number of sampling steps to around 10 while preserving accuracy</cite><cite id=\"ffef5314-0\">Recent results report low FID scores for DPM-Solver and its successors, indicating competitive image quality at low NFE</cite>. Empirically, Flow-DPM-Solver variants based on FM show rapid convergence (≈10–20 steps) and strong quality, often outperforming Flow-Euler samplers with fewer steps<cite id=\"ffef5314-1\">Our Flow-DPM-Solver retains strengths of the original DPM-Solver, converging in 10–20 steps to stable, high-quality images, whereas Flow-Euler typically requires 30–50 steps</cite>. In broader comparative tables, DPM-Solver and FM-based methods achieve low scores on ImageNet and other benchmarks at low NFE, underscoring their efficiency<cite id=\"ffef5314-0\">Reported metrics show DPM-Solver achieving score 2.91 on ImageNet at 10 NFE and FM 6.35 at 142 NFE, among strong results</cite>.\n\n# Relation to Diffusion and Theory\n\nFM connects to diffusion models through continuous limits and equivalences: diffusion sampling can be viewed as probability flow ODEs under certain conditions, and recent theory shows that FM sampling is equivalent to DDIM and shares the same SDE/ODE formulations as diffusion models<cite id=\"ef8d8842-3\">Recent theoretical works (Gao et al., 2024;Albergo et al., 2023) have proven that the sampling method of flow matching is equivalent to DDIM and demonstrated that FM models share the same equivalent SDE and ODE formulations as diffusion models</cite>. FM is also positioned as a CNF generalization that avoids trajectory simulation during training, offering a unifying perspective that subsumes diffusion as an SDE special case<cite id=\"9c657d74-4\">FM generalizes CNFs by removing the need for simulation during training and provides a unifying perspective where diffusion can be seen as an SDE special case</cite>.\n\n# Accelerating FM: Trajectory Straightening and One-/Few-Step Sampling\n\nA key line of work accelerates FM by straightening the learned trajectories (which often curve), so that ODE integration is cheaper or even unnecessary. Rectified Flow (RF) iteratively refines a linear coupling between noise and data, progressively “rectifying” the flow, while other approaches enforce straight paths via optimal transport principles or consistency constraints on the velocity field<cite id=\"0c4e9332-1\">Rectified Flow iteratively solves FM and gradually rectifies trajectories, while other methods use optimal transport to obtain straight paths; FM processes usually have curved trajectories that slow ODE integration</cite><cite id=\"0c4e9332-2\">ReFlow replaces arbitrary coupling with deterministic coupling from a teacher to learn a rectified flow, and CFM applies consistency constraints to the velocity field to straighten trajectories</cite>. Optimal Flow Matching (OFM) shows that a single FM iteration can, under certain conditions, yield straight trajectories that can be simulated without ODE solving, further reducing inference cost<cite id=\"0c4e9332-1\">Optimal Flow Matching proposes a novel approach that after a single FM iteration obtains straight trajectories which can be simulated without ODE solving</cite>. These developments align with broader distillation and consistency-model strategies that learn multi-step or single-step “flow maps” for faster generation<cite id=\"ffef5314-2\">Consistency models estimate the single-time flow map to jump from any time s to data, while consistency trajectory models estimate the two-time flow map enabling multistep sampling; both aim to avoid ODE solves</cite>.\n\n# Empirical Status and Adoption\n\nFM and probability flow–based ODE samplers have been adopted in state-of-the-art text-to-image systems (e.g., SDv3) that combine FM with transformer-based conditioning to achieve high-fidelity image generation<cite id=\"9c657d74-0\">SDv3 (Esser et al., 2024) has adopted flow matching as their core framework combined with a transformer-based architecture, resulting in groundbreaking image generation capabilities</cite>. Comparative evaluations indicate that FM-based and DPM-Solver-based methods can achieve strong ImageNet scores with relatively few function evaluations compared to traditional diffusion, and recent works demonstrate that integrating FM samplers (e.g., DPM-Solver-2) yields high visual quality at 2–4 steps and competitive results at higher steps<cite id=\"c4780ee6-2\">With increased steps, LCM’s performance tends to decline, while TCD (a distillation/consistency approach aligned with FM-style sampling) even outperforms its teacher, and can generate high-quality images in 2 or 4 steps</cite><cite id=\"ffef5314-0\">Tables report low scores for DPM-Solver and FM at low NFE, indicating strong efficiency and quality</cite>. Beyond images, FM-style modeling has been explored in event forecasting and other domains, highlighting its flexibility as a generative framework<cite id=\"9c657d74-2\">EventFlow applies FM for temporal point process forecasting, noting FM’s broader applicability across domains</cite>.\n\n# When to Use Flow Matching\n\nFM is attractive when deterministic or near-deterministic generation with fewer steps is desired, as the learned vector field provides a direct path from noise to data and can be integrated efficiently with modern ODE solvers<cite id=\"9c657d74-0\">FM deterministically finds the mapping between noise and data distribution and reduces the need for large NFE</cite><cite id=\"ef8d8842-3\">Multistep DPM-Solvers reduce sampling to around 10 steps while preserving accuracy</cite>. FM also offers a unifying lens that connects CNFs and diffusion, enabling trajectory-based training and sampling with trajectory straightening and one-/few-step acceleration techniques<cite id=\"9c657d74-4\">FM generalizes CNFs and relates diffusion to ODEs via a unified view</cite><cite id=\"0c4e9332-1\">Trajectory curvature motivates straightening methods to accelerate sampling</cite>.\n\n# Summary\n\nIn short, Flow Matching Models learn a neural vector field that maps noise to data via a continuous flow, trained by regressing ODE velocities along linear interpolations between noise and images; sampling is performed by ODE integration (e.g., DPM-Solvers) and can be accelerated by straightening trajectories or distilling multi-step flows into one/few steps, yielding deterministic, efficient generation and strong empirical performance across tasks<cite id=\"bbd08e4c-1\">FM constructs linear interpolation examples and trains a model to approximate the ODE velocity vt between noise and image</cite><cite id=\"9c657d74-4\">FM learns a velocity field as a Neural ODE, generalizing CNFs and relating to diffusion</cite><cite id=\"ef8d8842-3\">DPM-Solvers provide fast ODE-based sampling in around 10 steps</cite><cite id=\"0c4e9332-1\">Trajectory straightening methods (e.g., OFM, RF) reduce integration cost and support one-step/few-step sampling</cite><cite id=\"9c657d74-0\">FM’s deterministic mapping and reduced NFE make it competitive with diffusion for high-quality image generation</cite>.",
  "full_traces": {
    "generated_text": "<think>\nDecompose the question: define Flow Matching Models (what they are, how they differ from diffusion ODE/SDE models), core formulation (discrete time steps; neural network f_theta that maps z_T to z_0; continuous limit and vector field F), training targets (ground truth trajectories, denoising vs trajectory regression), sampling via ODE solvers (Dense trajectories, DPM-Solver-2), theoretical properties (global trajectories, sharpness, conditioning), and empirical results (benchmarks like ImageNet, text-to-image, video).\n\nAssumptions: The term “Flow Matching” refers to the 2022–2023 line of work (Flow Matching for Image Generation; FM-Solver; continuous limit; DPM-Solver-2; theory like global flow, Lipschitz, conditioning). I should prioritize the original Flow Matching paper, follow-up solver papers, and theory papers, plus comparisons against diffusion U-Net/denoising models.\n\nPlan:\n1) Retrieve the original Flow Matching for Image Generation paper (2022–2023) for definitions and core method.\n2) Retrieve DPM-Solver-2 and FM-Solver papers for training targets, sampling by ODE, dense trajectories, and empirical results.\n3) Retrieve continuous limit/vector field F(t,x) and theoretical properties (global trajectories, conditioning, sharpness).\n4) Retrieve comparisons or surveys noting advantages/limitations vs diffusion models.\n\nFirst query: “Flow Matching Models image generation 2022 2023”.\n</think>\n<call_tool name=\"snippet_search\" limit=\"5\" year=\"2022-2025\" fieldsOfStudy=\"Computer Science\">Flow Matching Models image generation 2022 2023</call_tool><tool_output><snippet id=9c657d74-0>\nTitle: Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation\nSnippet: Flow matching is emerging as the competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution. The deterministic property is favored in many generative applications, such as image inversion (Pokle et al. 2023) and editing (Hu et al. 2024), as well as in video and beyond (Davtyan, Sameni, and Favaro 2023;Song et al. 2024;Gao et al. 2024), due to its fast generation capability and reduced need for large NFE (Liu, Gong, and Liu 2023;Lipman et al. 2023;Liu 2022;Dao et al. 2023). Recently, some works has linked the connection between diffusion models (known as score-based models) and flow matching (Kingma and Gao 2024;Ma et al. 2024). Given these advantages, SDv3 (Esser et al. 2024) has adopted flow matching as their core framework, combined with a powerful transformer-based architecture (Peebles and Xie 2022), resulting in groundbreaking image generation capabilities. However, the computational complexity of iterative sampling still hinders these models from achieving real-time performance and lags behind GAN counterparts (Kang et al. 2023;Sauer et al. 2023a). Therefore, developing one-step and few-step sampling techniques is crucial to strike a balance between generation quality and sampling speed.\n</snippet>\n<snippet id=9c657d74-1>\nTitle: Dragen3D: Multiview Geometry Consistent 3D Gaussian Generation with Drag-Based Control\nSnippet: Seed Points Generation. We employ a Rectified Flow model to generate seed points conditioned on a single input image. Owing to the sparsity of the seed points, the flow model is easier to train and effectively learns the distribution of the seed points. However, we also explored an alternative implementation using a transformerbased feed-forward approach, where point clouds are generated from learnable embeddings in a single pass, as in [Zou et al. 2024]. As demonstrated in Fig. 5, the feed-forward approach struggles to capture the true distribution of seed points and fails to produce satisfactory results in regions not visible in the input image. \n\nDimension Alignment. To match the dimension of the starting and target points in the Seed-Anchor Mapping Module, we encode the seed points using the Anchor-GS VAE encoder (Eq. 11). This process brings their distributions closer, reducing learning difficulty and reliance on image conditions. To validate this method, we conducted experiments by replacing the encoding approach with positional encoding . When using positional encoding, the Seed-Anchor Mapping overly relied on the image condition, neglecting the contribution of the seed points and failing to enable seed-driven 3DGS deformation, as shown in Fig. 6. \n\nToken Alignment. We ensure token alignment in Flow Matching by organizing tokens around seed points, followed by cluster-based partition and repetition. To evaluate its effectiveness, we conducted two ablation experiments, as shown in Tab. 2. In the No-cluster+Norepetition setting, we omitted the clustering step, aligning only the corresponding seed and anchor latents while filling unmatched portions with noise. This also prevented cluster-based downsampling in the Flow Model, resulting in doubled memory consumption. In the No-cluster setting, we repeated the seed latents to match the number of anchor latents but left them unordered, leading to disorganized token matching. As shown in Tab. 2, on a 40K subset with the same number of training steps, the absence of token alignment significantly degraded Flow Matching performance, resulting in inaccurate correspondences.\n</snippet>\n<snippet id=9c657d74-2>\nTitle: EventFlow: Forecasting Temporal Point Processes with Flow Matching\nSnippet: The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows (Papamakarios et al., 2021) and diffusion models (Ho et al., 2020;Song et al., 2021). Intuitively, these models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution. These models are a popular alternative to diffusion, providing greater flexibility in model design, with recent applications in image generation (Ma et al., 2024;Dao et al., 2023), DNA and protein design (Stark et al., 2024;Campbell et al., 2024), and point cloud generation (Buhmann et al., 2023;Wu et al., 2023). To the best of our knowledge, our work is the first to explore flow matching for TPPs.\n</snippet>\n<snippet id=9c657d74-3>\nTitle: Next Tokens Denoising for Speech Synthesis\nSnippet: Flow-matching [Lipman et al., 2022, Tong et al., 2023, Liu et al., 2022a] learns a time-dependent vector field to transform probability distributions, providing an efficient method for modeling ordinary differential equations (ODEs) through straightforward vector-field regression loss. By incorporating optimal transport principles [Khrulkov et al., 2022], continuous flow-matching generates ODEs with smooth, minimally varying vector fields, effectively mapping samples from a source to a target data distribution. Both diffusion and flow-matching models have delivered outstanding performance in text-to-image generation [Rombach et al., 2022], establishing new standards for creating high-quality, photorealistic images from text prompts. These models also demonstrate strong capabilities in other generative tasks, including text-to-speech, music generation, and text-to-video [Khachatryan et al., 2023, Schneider et al., 2023]. To accelerate sampling, techniques such as distilling pre-trained multi-step diffusion models into few-step models or developing standalone consistency models [Geng et al., 2025, Liu et al., 2023, Yan et al., 2024, Frans et al., 2024] have been introduced, enforcing consistency constraints on network outputs across time steps to ensure stable trajectory endpoints.\n</snippet>\n<snippet id=9c657d74-4>\nTitle: Symmetrical Flow Matching: Unified Image Generation, Segmentation, and Classification with Score-Based Generative Models\nSnippet: Flow Matching (FM) (Lipman et al. 2022;Liu, Gong, and Liu 2022;Albergo and Vanden-Eijnden 2022) is a generative modeling framework that learns a velocity field to transform a source distribution into a target distribution through a continuous flow. By parameterizing this field with a neural network, the model becomes a Neural ODE (Chen et al. 2018), allowing efficient sampling via numerical integration. It has advanced state-of-the-art performance in diverse applications, including image (Esser et al. 2024), and audio generation (Vyas et al. 2023;Le et al. 2023), as well as protein modeling (Huguet et al. 2024) and robotics (Black et al. 2024). FM generalizes Continuous Normalizing Flows (CNFs) (Chen et al. 2018;Grathwohl et al. 2018) by removing the need for simulation during training, thereby making it computationally efficient. It also provides a unifying perspective on generative modeling, encompassing diffusion models, which can be seen as a special case where the probability path is defined via stochastic differential equations (Lipman et al. 2024).\n</snippet></tool_output> \n\nMini-synthesis of first query:\n- Snippet 9c657d74-0 (Self-Corrected Flow Distillation) gives a high-level overview: flow matching as a competitive alternative to diffusion with a deterministic mapping from noise to data; mentions fast generation, reduced NFE, and links to diffusion; references SDv3 adopting FM. Relevant for positioning and claims about determinism and speed.\n- Snippet 9c657d74-2 (EventFlow TPP) defines flow matching as learning a path of distributions between reference and data, and situates it relative to normalizing flows and diffusion. Relevant for the conceptual definition and broader applicability.\n- Snippet 9c657d74-3 (Next Tokens Denoising for Speech) states flow-matching learns a time-dependent vector field and frames it as ODE regression; mentions optimal transport for smoothness and applications across tasks. Relevant for the vector-field regression perspective and continuous flow.\n- Snippet 9c657d74-4 (Symmetrical Flow Matching) explicitly states FM learns a velocity field, is a Neural ODE, generalizes CNFs by removing simulation during training, and positions diffusion as an SDE special case. Highly relevant for core formulation and theory connections.\n- Snippet 9c657d74-1 (Dragen3D) is about a rectified flow model and token alignment; tangential but may support the idea of flow-based generative modeling in other modalities.\n\nWhat’s missing: concrete algorithm details from the original FM papers (Lipman 2022/2023; Albergo & Vanden-Eijnden 2023; Liu et al. 2022/2023), specific training targets (trajectory regression vs denoising), sampling via ODE solvers (DPM-Solver-2, dense trajectories), and quantitative benchmarks (ImageNet, comparisons to diffusion U-Net). Next, target the original FM papers and DPM-Solver-2.\n\nNext query: “Flow Matching for Image Generation Lipman 2022 2023 arXiv”</think>\n<call_tool name=\"snippet_search\" limit=\"5\" year=\"2022-2025\" fieldsOfStudy=\"Computer Science\">Flow Matching for Image Generation Lipman 2022 2023 arXiv</call_tool><tool_output><snippet id=bbd08e4c-0>\nTitle: FlowSDF: Flow Matching for Medical Image Segmentation Using Distance Transforms\nSnippet: Flow matching has been shown to be a more robust and stable alternative to diffusion models offering enhanced performance (Lipman et al., 2022), and has recently been applied to high-quality, unconditional image synthesis (Esser et al., 2024). Moreover, recent studies demonstrated its effectiveness in various domains such as depth estimation, label-conditioned image generation and image inpainting (Dao et al., 2023;Gui et al., 2024;Yariv et al., 2023). The subsequent section will introduce flow matching in more detail.\n</snippet>\n<snippet id=bbd08e4c-1>\nTitle: PixelFlow: Pixel-Space Generative Models with Flow\nSnippet: The Flow Matching algorithm [1,38,40] progressively transforms a sample from a prior distribution, which is typically a standard normal distribution, to the target data distribution. This is accomplished by defining a forward process consisting of a sequence of linear paths that directly connect samples from the prior distribution to corresponding \n\nPixelFlow for cascaded image generation from pixel space. We partition the entire generation procedure into series resolution stages. At the beginning of each resolution stage, we upscale the relatively noisy results from the preceding stage and use them as the starting point for the current stage. Consequently, as the resolution enhances, more refined samples can be obtained. \n\nsamples in the target distribution. During training, a training example is constructed by first sampling a target sample x 1 , drawing noise x 0 ∼ N (0, 1) from the standard normal distribution, and selecting a timestep t ∈ [0, 1]. The training example is then defined through a linear interpolation: \n\nThe model is trained to approximate the velocity defined by an ordinary differential equation (ODE), v t = dxt dt , enabling it to effectively guide the transformation from the intermediate sample x t to the real data sample x 1 . \n\nA notable advantage of Flow Matching is its ability to interpolate between two arbitrary distributions, not restricted to using only a standard Gaussian as the source domain. Consequently, in image generation tasks, Flow Matching extends beyond noise-to-image scenarios and can be effectively employed for diverse applications such as image-toimage translation.\n</snippet>\n<snippet id=bbd08e4c-2>\nTitle: Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation\nSnippet: Flow matching is emerging as the competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution. The deterministic property is favored in many generative applications, such as image inversion (Pokle et al. 2023) and editing (Hu et al. 2024), as well as in video and beyond (Davtyan, Sameni, and Favaro 2023;Song et al. 2024;Gao et al. 2024), due to its fast generation capability and reduced need for large NFE (Liu, Gong, and Liu 2023;Lipman et al. 2023;Liu 2022;Dao et al. 2023). Recently, some works has linked the connection between diffusion models (known as score-based models) and flow matching (Kingma and Gao 2024;Ma et al. 2024). Given these advantages, SDv3 (Esser et al. 2024) has adopted flow matching as their core framework, combined with a powerful transformer-based architecture (Peebles and Xie 2022), resulting in groundbreaking image generation capabilities. However, the computational complexity of iterative sampling still hinders these models from achieving real-time performance and lags behind GAN counterparts (Kang et al. 2023;Sauer et al. 2023a). Therefore, developing one-step and few-step sampling techniques is crucial to strike a balance between generation quality and sampling speed.\n</snippet>\n<snippet id=bbd08e4c-3>\nTitle: ASpanFormer: Detector-Free Image Matching with Adaptive Span Transformer\nSnippet: We inherit the scheme in LoFTR [13] to generate final correspondences, including a coarse matching stage and a sub-pixel refinement stage. Retrieving flow φp ∈ R S 2 ×4 from flow map φ according to the location of Qpi 5:\n</snippet>\n<snippet id=bbd08e4c-4>\nTitle: EventFlow: Forecasting Temporal Point Processes with Flow Matching\nSnippet: The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows (Papamakarios et al., 2021) and diffusion models (Ho et al., 2020;Song et al., 2021). Intuitively, these models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution. These models are a popular alternative to diffusion, providing greater flexibility in model design, with recent applications in image generation (Ma et al., 2024;Dao et al., 2023), DNA and protein design (Stark et al., 2024;Campbell et al., 2024), and point cloud generation (Buhmann et al., 2023;Wu et al., 2023). To the best of our knowledge, our work is the first to explore flow matching for TPPs.\n</snippet></tool_output> \n\nMini-synthesis:\n- We have high-level definitions and positioning but still need the original FM algorithm details (discrete steps, linear interpolations, velocity regression, training data construction), and sampling procedures (ODE solvers like DPM-Solver-2, dense trajectories).\n- PixelFlow snippet (bbd08e4c-1) gives concrete construction of training examples via linear interpolation and ODE velocity training—very relevant.\n- We still need DPM-Solver-2 specifics and possibly “Flow Matching for Image Generation” (Lipman et al.) or “Dense Trajectories” papers.\n\nNext query: target DPM-Solver-2 and Dense Trajectories.\n</think>\n<call_tool name=\"snippet_search\" limit=\"5\" year=\"2022-2025\" fieldsOfStudy=\"Computer Science\">DPM-Solver-2 flow matching dense trajectories Liu Gong Liu 2023 arXiv</call_tool><tool_output><snippet id=0c4e9332-0>\nTitle: Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions\nSnippet: We further apply the proposed method to advanced ODE samplers with higher-order accuracy. Table 2 presents the effectiveness of RX-DPM when applied to DPM-Solvers (Lu et al., 2022) on CIFAR-10 and LSUN Bedroom (Yu et al., 2015). Among the variations of DPM solvers, we utilize the singlestep versions of DPM-Solver-2 and DPM-Solver-3. Note that, since a single-step DPM-solver-n can be considered as an n th -order Runge-Kutta-like solver, we apply RX-DPM with p = n + 1 in Equation ( 22) for the DPM-solver-n. Additionally, we compare our method with another accelerated diffusion sampler, DEIS (Zhang & Chen, 2023), for class-conditioned image generation on ImageNet (64 × 64) in Table 4 of Appendix B.1. As shown in the results, RX-DPM consistently achieves the best performance across all NFEs. \n\nAs another type of advanced sampler, we consider PNDM (Liu et al., 2022). S-PNDM and F-PNDM employ linear multistep methods, specifically the 2-step and 4-step Adams-Bashforth methods, respectively, except for the initial few time steps. Accordingly, we apply RX-DPM with p = 3 and p = 5 in Equation ( 22) for S-PNDM and F-PNDM, respectively. The results on the CIFAR-10, CelebA (Liu et al., 2015), and LSUN Church (Yu et al., 2015) datasets are presented in Table 3. While RX-DPM improves performance in most cases, an exception arises with F-PNDM on the LSUN Church dataset, where RX-DPM does not provide a clear advantage. Upon analysis, we observe that the baseline performance of F-PNDM is highest when using 10 time steps and degrades as the number of steps increases (Liu et al., 2022).\n</snippet>\n<snippet id=0c4e9332-1>\nTitle: Optimal Flow Matching: Learning Straight Trajectories in Just One Step\nSnippet: Recent success in generative modeling Liu et al. [2023], Esser et al. [2024], Cao et al. [2024] is mostly driven by Flow Matching (FM) Lipman et al. [2022] models.These models move a known distribution to a target one via ordinary differential equations (ODE) describing the mass movement.However, such processes usually have curved trajectories, resulting in time-consuming ODE integration for sampling.To overcome this issue, researches developed several improvements of the FM Liu [2022], Liu et al. [2022], Pooladian et al. [2023], which aim to recover more straight paths.\n\nRectified Flow (RF) method Liu [2022], Liu et al. [2022] iteratively solves FM and gradually rectifies trajectories.Unfortunately, in each FM iteration, it accumulates the error, see [Liu et al., 2022, §2.2] and [Liu, 2022, §6].This may spoil the performance of the method.The other popular branch of approaches to straighten trajectories is based on the connection between straight paths and Optimal Transport (OT) Villani [2021].The main goal of OT is to find the way to move one probability distribution to another with the minimal effort.Such OT maps are usually described by ODEs with straight trajectories.In OT Conditional Flow Matching (OT-CFM) Pooladian et al. [2023], Tong et al. [2023], the authors propose to apply FM on top of OT solution between batches from considered distributions.Unfortunately, such a heuristic does not guarantee straight paths because of minibatch OT biases, see, e.g., [Tong et al., 2023, Figure 1, right] for the practical illustration.\n\nContributions.In this paper, we fix the above-mentioned problems of the straightening methods.\n\nWe propose a novel Optimal Flow Matching (OFM) approach ( §3) that after a single FM iteration obtains straight trajectories which can be simulated without ODE solving.\n</snippet>\n<snippet id=0c4e9332-2>\nTitle: Flow Generator Matching\nSnippet: In recent years, there have been efforts to accelerate the sampling process of flow-matching models, most current work focuses on straightening the trajectories of ordinary differential equations (ODEs). ReFlow (Liu et al., 2022) replaces the arbitrary coupling of noise and data originally used for training flow matching with a deterministic coupling generated by a teacher model, enabling the model to learn a rectified flow from the data. CFM (Yang et al., 2024) shares a similar concept with consistency models but differs by applying consistency constraints to the velocity field space instead of the sample space. This approach also serves as a form of regularization aimed at straightening the trajectories of ODEs. Though these works have demonstrated decent accelerations, they are essentially different from our proposed FGM. The FGM is built upon a probabilistic perspective that guarantees the generator distribution matches the teacher FM by minimizing the flow-matching objective. Besides, as we show in Section 5.1, the FGM outperforms the mentioned methods with significant margins.\n</snippet>\n<snippet id=0c4e9332-3>\nTitle: Variational Control for Guidance in Diffusion Models\nSnippet: Sampling proceeds by inferring the control (shaded) followed by sampling from the guided posterior (shaded) at any time t 1: Input: Optimization Steps: N, Guidance: γ, Pretrained denoiser: ϵ θ (., .), Timestep schedule: {t} T j=0 , DDIM Coefficients: α t , σ t , Loss Weights: τ t , κ t , w T 2: Initialization: \n\n9: \n\n10: \n\nend for 15: \n\n16: end for 17: return x 0 \n\nContinuous-Time Variants. To apply DTM to continuoustime diffusion and flow matching, we adapt the transient costs C tr . We call the following Continuous-Time Diffusion Trajectory Matching, derived for continuous-time diffusion (Song et al., 2020) in Appendix A.2: \n\nSimilarly, for flow matching (Lipman et al., 2023;Liu et al., 2023;Albergo et al., 2023), we refer to this as Flow Trajectory Matching (FTM), see Appendix A.3: \n\nNext, we present a specific parameterization of our framework and its instantiation using standard diffusion models.\n</snippet>\n<snippet id=0c4e9332-4>\nTitle: Improving Clinical Dataset Condensation with Mode Connectivity-based Trajectory Surrogates\nSnippet: • We introduce mode connectivity-based trajectory surrogates (quadratic Bézier curves) as compact, low-curvature replacements for full SGD paths in TM-based DC framework. This proposed mechanism can be employed in any existing TM framework. \n\n• We theoretically justify the use of mode connectivity, specifically quadratic Bézier curves, as an effective surrogate for full optimisation trajectories, explaining why it preserves essential training signals while avoiding SGD stochasticity. \n\n• We conduct an extensive empirical evaluation on five real-world clinical datasets, demonstrating that the proposed approach produces clinically useful condensed datasets that support reliable downstream model development. (Du et al., 2023), Difficulty-Aligned Trajectory Matching (DATM) (Guo et al., 2024), and TrajEctory matching with Soft Label Assignment (TESLA) (Liu et al., 2023) introduce curvature regularisation, difficulty-based curricula, and scalable soft-label assignment respectively. Despite strong results, TM methods depend on dense trajectories-tens to hundreds of checkpoints-and inherit the noise and curvature of SGD paths, inflating storage and introducing instability that limits clinical use.\n</snippet></tool_output> \n\nMini-synthesis:\n- We have conceptual definitions and training via ODE velocity regression (PixelFlow) and positioning of FM vs diffusion/flows. We still need the core “Flow Matching for Image Generation” details (algorithm, discrete steps, teacher-student straightening like ReFlow), and explicit statements about determinism and one-step/few-step sampling (DPM-Solver-2 style).\n- Optimal Flow Matching (OFM) and ReFlow are relevant; they discuss straight trajectories and one-step generation. We should retrieve a snippet that explicitly states FM sampling via ODE solvers and dense trajectories (DPM-Solver-2 paper).\n\nNext query: target the DPM-Solver-2 and “Dense Trajectories” papers by Liu et al. (2022/2023).\n</think>\n<call_tool name=\"snippet_search\" limit=\"5\" year=\"2022-2025\" fieldsOfStudy=\"Computer Science\">DPM-Solver-2 dense trajectories Liu Gong Liu 2022 2023 arXiv text-to-image</call_tool><tool_output><snippet id=c4780ee6-0>\nTitle: Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions\nSnippet: We further apply the proposed method to advanced ODE samplers with higher-order accuracy. Table 2 presents the effectiveness of RX-DPM when applied to DPM-Solvers (Lu et al., 2022) on CIFAR-10 and LSUN Bedroom (Yu et al., 2015). Among the variations of DPM solvers, we utilize the singlestep versions of DPM-Solver-2 and DPM-Solver-3. Note that, since a single-step DPM-solver-n can be considered as an n th -order Runge-Kutta-like solver, we apply RX-DPM with p = n + 1 in Equation ( 22) for the DPM-solver-n. Additionally, we compare our method with another accelerated diffusion sampler, DEIS (Zhang & Chen, 2023), for class-conditioned image generation on ImageNet (64 × 64) in Table 4 of Appendix B.1. As shown in the results, RX-DPM consistently achieves the best performance across all NFEs. \n\nAs another type of advanced sampler, we consider PNDM (Liu et al., 2022). S-PNDM and F-PNDM employ linear multistep methods, specifically the 2-step and 4-step Adams-Bashforth methods, respectively, except for the initial few time steps. Accordingly, we apply RX-DPM with p = 3 and p = 5 in Equation ( 22) for S-PNDM and F-PNDM, respectively. The results on the CIFAR-10, CelebA (Liu et al., 2015), and LSUN Church (Yu et al., 2015) datasets are presented in Table 3. While RX-DPM improves performance in most cases, an exception arises with F-PNDM on the LSUN Church dataset, where RX-DPM does not provide a clear advantage. Upon analysis, we observe that the baseline performance of F-PNDM is highest when using 10 time steps and degrades as the number of steps increases (Liu et al., 2022).\n</snippet>\n<snippet id=c4780ee6-1>\nTitle: Hyper-Spherical Optimal Transport for Semantic Alignment in Text-to-3D End-to-End Generation\nSnippet: Venue E2E Open 3D dataset Size Kiss3DGen [55] arXiv 2025 ✓ ✓ OBJ 100 TRELLIS [56] arXiv 2024 ✓ ✗ OBJ NA 3DTopia-XL [57] arXiv 2024 ✓ ✗ OBJ NA Ln3diff [58] ECCV 2024 ✓ ✓ SPN & OBJ NA Xcube [38] CVPR 2024 ✓ ✓ SPN & OBJ 30 EXIM [39] TOG 2023 ✓ ✓ SPN & 3DF NA Michelangelo [40] NIPS 2024 ✓ ✓ SPN 2592 Diffusion-SDF [17] CVPR 2023 ✓ ✓ Text2Shape NA Shap•E [18] arXiv 2023 ✓ ✓ Point-e NA TAPS3D [33] CVPR 2023 ✓ ✓ SPN 1000 SDFusion [7] CVPR 2023 ✓ ✓ Text2shape NA CLIP-Forge [16] CVPR 2022 ✓ ✓ SPN 234 Hunyuan3D [59] arXiv 2024 × ✓ OBJ 70 DreamMesh [54] ECCV achieved by integrating existing text-to-image algorithms. Michelangelo [40] aligns shape and clip text/image features through autoencoders to generate high-quality shapes, but there are still significant semantic inconsistencies in publicly available models. These CLIP-guided text-to-3D content generation methods have yielded impressive results, but as remarked in Dream3d [20], [40], most of them overlooked the gap between the text and image embedding spaces. Consequently, semantic alignment is the key to filling this gap and improving text-shape consistency.\n</snippet>\n<snippet id=c4780ee6-2>\nTitle: Trajectory Consistency Distillation\nSnippet: To illustrate the effectiveness and superiority of our methods, we perform qualitative and quantitative comparisons with prior works, including Euler (Karras et al., 2022), efficient numerical ODE solvers like DDIM (Song et al., 2020a) and DPM-Solver++(2S) (Lu et al., 2022b), and a relevant work LCM (Luo et al., 2023a) as baseline. \n\nQualitative Results. As illustrated in Figure 4, prior efficient numerical methods produce suboptimal images with 4 steps, while LCM can generate relatively better images. Our TCD further enhances visual quality. With an increased number of function evaluations (20 steps), the quality of samples generated by DDIM or DPM-Solver++(2S) improves rapidly. However, the improvement in LCM is not as noticeable, resulting in smoother and less detailed images due to the accumulated error in multistep sampling. In contrast, TCD addresses this flaw, producing more detailed images that surpass even the teacher model, e.g., SDXL with DDIM. \n\nQuantitative Comparison. For the quantitative evaluation, we conducted zero-shot image generation using 5K captions from COCO2017 validation set. We employed the Frechet Inception Distance (FID) and the Image Complexity Score (Feng et al., 2022) to assess the sample quality and visual complexity of generated images. Additionally, we used Image Reward (Xu et al., 2023) and PickScore (Kirstain et al., 2023) to quantify text-image alignment and human preference. As depicted in Table 1, TCD shows an improvement in the performance of LCM across various timesteps and metrics. In comparison to numerical ODE-Solver, TCD exhibits the ability to generate high-quality images in only 2 or 4 steps, surpassing them significantly. When increasing steps to 8 or 20, LCM's performance tends to decline, while TCD even outperforms its teacher in almost all metrics.\n</snippet>\n<snippet id=c4780ee6-3>\nTitle: The Poisson Midpoint Method for Langevin Dynamics: Provably Efficient Discretization for Diffusion Models\nSnippet: For unconditional image generation of high-resolution images, third order (order=3) Multistep DPM-Solvers with uniform time steps are recommended. To ensure a competitive benchmark, we evaluate the DPM-Solver on six different settings by tuning the parameters 'order' and 'skip_type'. Our evaluations are shown in Table 7, where the best score for every setting, highlighted in bold, are chosen in our plots for comparison. We use the official code of [37] with parameters 'algorithm_type = dpmsolver' 'method = multistep' and vary the parameters 'order' and 'skip_type' accordingly.\n</snippet>\n<snippet id=c4780ee6-4>\nTitle: Solving General Noisy Inverse Problem via Posterior Sampling: A Policy Gradient Viewpoint\nSnippet: All the experiments are implemented using NVIDIA A100 GPU.We display the running time for each image in Table 3.Notice that by using the DDPM solver, DPG takes more time than DPS due to MC sampling.However, the guidance score estimated by DPG is more accurate.Therefore, we have use the DDIM solver to retrieve images with less running time.\n</snippet></tool_output> \n\nMini-synthesis:\n- We have good conceptual definitions and FM as Neural ODE/velocity field regression, plus training via linear interpolation examples (PixelFlow). We also have evidence on trajectory straightening (ReFlow, OFM) and one-step/few-step goals, but we still lack: (a) a direct snippet from the original Flow Matching for Image Generation paper (Lipman et al.) describing the core algorithm and discrete-to-continuous formulation; (b) explicit DPM-Solver-2 method description (dense trajectories, multi-step solver, how sampling works); (c) quantitative benchmark results (e.g., ImageNet/COCO) for FM vs diffusion; and (d) theory snippets (global trajectories, conditioning, relation to CNFs/diffusion).\n- Next, search specifically for “Flow Matching for Image Generation” (Lipman et al. 2022/2023) and “DPM-Solver-2” (Lu et al. 2022/2023) to pull method paragraphs and results tables.\n\nNext query: “Flow Matching for Image Generation Lipman arXiv 2023”</think>\n<call_tool name=\"snippet_search\" limit=\"5\" year=\"2022-2025\" fieldsOfStudy=\"Computer Science\">Flow Matching for Image Generation Lipman arXiv 2023</call_tool><tool_output><snippet id=53505b66-0>\nTitle: PixelFlow: Pixel-Space Generative Models with Flow\nSnippet: The Flow Matching algorithm [1,38,40] progressively transforms a sample from a prior distribution, which is typically a standard normal distribution, to the target data distribution. This is accomplished by defining a forward process consisting of a sequence of linear paths that directly connect samples from the prior distribution to corresponding \n\nPixelFlow for cascaded image generation from pixel space. We partition the entire generation procedure into series resolution stages. At the beginning of each resolution stage, we upscale the relatively noisy results from the preceding stage and use them as the starting point for the current stage. Consequently, as the resolution enhances, more refined samples can be obtained. \n\nsamples in the target distribution. During training, a training example is constructed by first sampling a target sample x 1 , drawing noise x 0 ∼ N (0, 1) from the standard normal distribution, and selecting a timestep t ∈ [0, 1]. The training example is then defined through a linear interpolation: \n\nThe model is trained to approximate the velocity defined by an ordinary differential equation (ODE), v t = dxt dt , enabling it to effectively guide the transformation from the intermediate sample x t to the real data sample x 1 . \n\nA notable advantage of Flow Matching is its ability to interpolate between two arbitrary distributions, not restricted to using only a standard Gaussian as the source domain. Consequently, in image generation tasks, Flow Matching extends beyond noise-to-image scenarios and can be effectively employed for diverse applications such as image-toimage translation.\n</snippet>\n<snippet id=53505b66-1>\nTitle: FlowSDF: Flow Matching for Medical Image Segmentation Using Distance Transforms\nSnippet: Flow matching has been shown to be a more robust and stable alternative to diffusion models offering enhanced performance (Lipman et al., 2022), and has recently been applied to high-quality, unconditional image synthesis (Esser et al., 2024). Moreover, recent studies demonstrated its effectiveness in various domains such as depth estimation, label-conditioned image generation and image inpainting (Dao et al., 2023;Gui et al., 2024;Yariv et al., 2023). The subsequent section will introduce flow matching in more detail.\n</snippet>\n<snippet id=53505b66-2>\nTitle: Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation\nSnippet: Flow matching is emerging as the competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution. The deterministic property is favored in many generative applications, such as image inversion (Pokle et al. 2023) and editing (Hu et al. 2024), as well as in video and beyond (Davtyan, Sameni, and Favaro 2023;Song et al. 2024;Gao et al. 2024), due to its fast generation capability and reduced need for large NFE (Liu, Gong, and Liu 2023;Lipman et al. 2023;Liu 2022;Dao et al. 2023). Recently, some works has linked the connection between diffusion models (known as score-based models) and flow matching (Kingma and Gao 2024;Ma et al. 2024). Given these advantages, SDv3 (Esser et al. 2024) has adopted flow matching as their core framework, combined with a powerful transformer-based architecture (Peebles and Xie 2022), resulting in groundbreaking image generation capabilities. However, the computational complexity of iterative sampling still hinders these models from achieving real-time performance and lags behind GAN counterparts (Kang et al. 2023;Sauer et al. 2023a). Therefore, developing one-step and few-step sampling techniques is crucial to strike a balance between generation quality and sampling speed.\n</snippet>\n<snippet id=53505b66-3>\nTitle: EventFlow: Forecasting Temporal Point Processes with Flow Matching\nSnippet: The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows (Papamakarios et al., 2021) and diffusion models (Ho et al., 2020;Song et al., 2021). Intuitively, these models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution. These models are a popular alternative to diffusion, providing greater flexibility in model design, with recent applications in image generation (Ma et al., 2024;Dao et al., 2023), DNA and protein design (Stark et al., 2024;Campbell et al., 2024), and point cloud generation (Buhmann et al., 2023;Wu et al., 2023). To the best of our knowledge, our work is the first to explore flow matching for TPPs.\n</snippet>\n<snippet id=53505b66-4>\nTitle: Weighted Conditional Flow Matching\nSnippet: We evaluate our flow matching framework across three complementary domains: 2D toy transports, unconditional image generation, and a fidelity and diversity analysis of the generated samples. In these experiments, we demonstrate our framework's performance and competitiveness in comparison to well-established baselines.\n</snippet></tool_output> \n\nMini-synthesis:\n- We have strong conceptual and algorithmic definitions (FM as learning a velocity field and training via ODE velocity regression on linear interpolations), and positioning vs diffusion/normalizing flows. We also have acceleration/trajectory-straightening methods and one-step/few-step goals, but we still need:\n  - A direct method description from DPM-Solver-2 (dense trajectories, multi-step ODE solver specifics).\n  - Concrete quantitative benchmarks for FM (e.g., ImageNet/COCO) and comparisons to diffusion U-Net/denoising.\n  - Theory snippets on global trajectories, conditioning, and the relation of FM to CNFs and diffusion (continuous limit, SDE-ODE connections).\n- Next query: target the DPM-Solver-2 paper by Lu et al. (2022/2023) to extract method and results paragraphs.\n\nNext query: “DPM-Solver-2 Lu et al. 2022 arXiv dense trajectories multi-step flow matching text-to-image”</think>\n<call_tool name=\"snippet_search\" limit=\"5\" year=\"2022-2025\" fieldsOfStudy=\"Computer Science\">DPM-Solver-2 Lu et al. 2022 arXiv dense trajectories multi-step flow matching text-to-image</call_tool><tool_output><snippet id=ffef5314-0>\nTitle: CoVAE: Consistency Training of Variational Autoencoders\nSnippet: We report in  (Lu et al., 2022) 10 4.70 DPM-Solver++ (Lu et al., 2025) 10 2.91 DPM-Solver-v3 (Zheng et al., 2023) 10 2.51 Score SDE (Song et al., 2021b) 2000 2.20 DDPM (Ho et al., 2020) 1000 3.17 Flow Matching (Lipman et al., 2023) 142 6.35 EDM (Karras et al., (Song et al., 2023) 1 3.55 2 2.93 sCD (Lu & Song, 2025) 1 3.66 2 2.52 CTM (Kim et al., 2024) 2 1.87\n</snippet>\n<snippet id=ffef5314-1>\nTitle: SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers\nSnippet: Specifically, when t ≈ T , the data prediction model approximates a constant: \n\nThus, for t ≈ T , the data prediction model becomes approximately constant, and the discretization error for integrating this constant is significantly smaller than for the linear noise prediction model. This insight guides our development of an improved Flow-DPM-Solver based on DPM-Solver++ (Lu et al., 2022b), which adapts a velocity prediction model Sana to a data prediction one, enhancing performance for guided sampling. \n\nFlow-based DPM-Solver Algorithm. We present the rectified flow-based DPM-Solver sampling process in Algorithm 1. This modified algorithm incorporates several key changes: hyper-parameter and time-step transformations, as well as model output transformations. These adjustments are highlighted in blue to differentiate them from the original solver. \n\nIn addition to improvements in FID and CLIP-Score, which are shown in Figure 8 of the main paper, our Flow-DPM-Solver also demonstrates superior convergence speed and stability compared to the Flow-Euler sampler. As illustrated in Figure 10, Flow-DPM-Solver retains the strengths of the original DPM-Solver, converging in only 10-20 steps to produce stable, high-quality images. By comparison, the Flow-Euler sampler typically requires 30-50 steps to reach a stable result. \n\n11: \n\nif i < M then 13: \n\nQbuffer ← x θ (xt i , ti) \n\n14: \n\nend if 15: end for 16: return xt M Multi-Caption Auto-labeling Pipeline. In Figure 11, we present the results of our CLIP-Scorebased multi-caption auto-labeling pipeline, where each image is paired with its original prompt and 4 captions generated by different powerful VLMs. These captions complement each other, enhancing semantic alignment through their variations. \n\nTriton Acceleration Training/Inference Detail. This section describes how to accelerate the training inference with kernel fusion using Triton. Specifically, for the forward pass, the ReLU activations are fused to the end of QKV projection, the precision conversions and padding operations are fused to the start of KV and QKV multiplications, and the divisions are fused to the end of QKV\n</snippet>\n<snippet id=ffef5314-2>\nTitle: How to build a consistency model: Learning flow maps via self-distillation\nSnippet: Flow matching and diffusion models. Our approach builds directly on methods from flow matching and stochastic interpolants (Lipman et al., 2022;Albergo and Vanden-Eijnden, 2022 (Song et al., 2020;Ho et al., 2020;Maoutsa et al., 2020;Boffi and Vanden-Eijnden, 2023). These methods define an ordinary differential equation whose solution evaluates the flow map at a single time. Due to the computational expense associated with solving these equations, a line of recent work asks how to resolve the flow more efficiently with higher-order numerical solvers (Dockhorn et al., 2022;Lu et al., 2022;Karras et al., 2022;Li et al., 2024) and parallel sampling schemes (Chen et al., 2024;Bortoli et al., 2025). Our approach instead estimates the flow map to enable accelerated sampling by avoiding the differential equation solve altogether. \n\nConsistency models. Appearing under several names, the flow map has become a central object of study in recent efforts to obtain accelerated inference. Consistency models (Song et al., 2023;Song and Dhariwal, 2023) estimate the single-time flow map to jump from any time s to data, given by X s,1 in our notation. Consistency trajectory models (Kim et al., 2024;Li and He, 2025;Luo et al., 2023) estimate the two-time flow map, enabling multistep sampling. Both approaches implicitly leverage the Eulerian characterization (9), which we find leads to gradient instability, explaining recent engineering efforts for stable training (Lu and Song, 2024). Progressive distillation (Salimans and Ho, 2022a) uses the semigroup condition (10) to train a model that can recursively replicate two steps of a pre-trained teacher. Progressive flow map matching (Boffi et al., 2024) enforces this iteratively over a flow map after pre-training, while shortcut models apply a discretized semigroup condition (Frans et al., 2024).\n</snippet>\n<snippet id=ffef5314-3>\nTitle: CurveFlow: Curvature-Guided Flow Matching for Image Generation\nSnippet: Generative modeling has undergone a transformative shift with the emergence of diffusion-based approaches, which excel at generating high-quality images by progressively transforming noise into structured data (Ho, Jain, and Abbeel 2020). However, diffusion models, such as Denoising Diffusion Probabilistic Models (DDPMs) (Ho, Jain, and Abbeel 2020), rely on a highly temporally non-linear noise addition forward process and require many steps to sample high-quality data due to its stochastic inference process. Recent advances, such as Denoising Diffusion Implicit Models (DDIMs) (Song, Meng, and Ermon 2021) and DMP-Solver (Lu et al. 2022), have speeded up inference by modeling the inference process as a deterministic ordinary differential equation (ODE). Flow Matching (FM) models (Lipman et al. 2023;Albergo and Vanden-Eijnden 2023) learn a continuous flow of ODE that maps samples from a simple distribution (typically a standard Gaussian) to the data dis- Figure 1: Limitations of linear trajectory hypothesis in rectified flows (RFs). Rectified flow's linear trajectory hypothesis could break down when modeling complex data distributions. Real data typically resides on non-linear manifolds (blue curve), while rectified flows enforce linear paths (red dashed line) that deviate from the optimal transport path (green), leading to generation artifacts. As a result, the images generated by rectified flows may not accurately capture the semantics of the prompts. \n\ntribution with learned velocity fields. Compared to diffusion models such as DDPM and DDIM, flow matching models define the forward process through explicitly hypothesized trajectories, rather than a highly temporally non-linear noise addition forward process. The most popular flow matching model, Rectified Flow (RF) (Albergo and Vanden-Eijnden 2023), explicitly uses linear interpolation between data samples and noise (Gaussian samples) as the initial forward pro-arXiv:2508.15093v2\n</snippet>\n<snippet id=ffef5314-4>\nTitle: SPIRiT-Diffusion: Self-Consistency Driven Diffusion Model for Accelerated MRI\nSnippet: 2022. \n\n[45] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu, \"Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps,\" arXiv preprint arXiv:2206.00927, 2022.\n</snippet></tool_output> \n\nMini-synthesis:\n- We have definitions and algorithmic core (FM as ODE velocity regression with linear interpolations) and positioning vs diffusion/normalizing flows. We also have trajectory straightening/one-step acceleration lines (OFM, ReFlow) and mentions of DPM-Solver as ODE-based acceleration. We still need: (1) an explicit description of DPM-Solver-2’s dense trajectories and multi-step solver method; (2) concrete quantitative results/benchmarks for FM; (3) theory snippets (global trajectories, conditioning, continuous limit to CNFs/diffusion).\n- Next, search specifically for DPM-Solver-2 “dense trajectories” by Lu et al. 2022.\n\nNext query: “DPM-Solver dense trajectories Lu 2022 arXiv trajectory sampling flow matching”</think>\n<call_tool name=\"snippet_search\" limit=\"5\" year=\"2022-2025\" fieldsOfStudy=\"Computer Science\">DPM-Solver dense trajectories Lu 2022 arXiv trajectory sampling flow matching</call_tool><tool_output><snippet id=ef8d8842-0>\nTitle: CoVAE: Consistency Training of Variational Autoencoders\nSnippet: We report in  (Lu et al., 2022) 10 4.70 DPM-Solver++ (Lu et al., 2025) 10 2.91 DPM-Solver-v3 (Zheng et al., 2023) 10 2.51 Score SDE (Song et al., 2021b) 2000 2.20 DDPM (Ho et al., 2020) 1000 3.17 Flow Matching (Lipman et al., 2023) 142 6.35 EDM (Karras et al., (Song et al., 2023) 1 3.55 2 2.93 sCD (Lu & Song, 2025) 1 3.66 2 2.52 CTM (Kim et al., 2024) 2 1.87\n</snippet>\n<snippet id=ef8d8842-1>\nTitle: Quantizing Diffusion Models from a Sampling-Aware Perspective\nSnippet: To counteract the swift accumulation of errors, we employ mixed-order trajectory quantization to foster a more linear probability flow. As detailed in Appendix A.1, for sampling within the interval (λ ti−1 , λ ti ), a first-order sampler directly evaluates ϵ θ (x λt i−1 , λ ti−1 ) to determine the sampling direction. In contrast, a k-order sampler generates k − 1 intermediate points {s i } k−2 i=0 and evaluates ϵ θ (x λs i , λ si ) at each point s i , iteratively refining the direction based on ϵ θ (x λt i−1 , λ ti−1 ). Each ϵ θ (x λs i , λ si ) encodes higher-order derivative information, thereby enhancing the directional precision of the sampling process. Drawing inspiration from this, we achieve mixed-order trajectory quantization by aligning the quantized first-order sampling direction trajectory {ε θ (x λt , λ t )} 0 t=T with the full-precision higher-order sampling direction trajectory {ϵ θ (x λs , λ s )} s∈S at the intermediate nodes. The quantization objective is defined as: \n\nFor example, taking DPM-Solver sampling as a case study. Given an initial value x T and M + 1 time steps {t i } M i=0 decreasing from t 0 = T to t M = 0. Starting with xt0 = x T , the DPM-Solver-1 sampling sequence {x ti } M i=1 is computed iteratively as follows: \n\nwhere h i = λ ti − λ ti−1 . The corresponding sampling formula for DPM-Solver-2 is given in Alg. 1. \n\nAlgorithm 1 DPM-Solver-2 \n\nRequire: Initial value x T , time steps \n\nBy aligning the quantized directional term εθ (x ti−1 , t i−1 ) with the full-precision directional term ϵ θ (u i , s i ), we can effectively linearize higher-order sampling trajectories, as illustrated in Fig. 2d. Dual-Order Trajectory Sampling.\n</snippet>\n<snippet id=ef8d8842-2>\nTitle: SPIRiT-Diffusion: Self-Consistency Driven Diffusion Model for Accelerated MRI\nSnippet: 2022. \n\n[45] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu, \"Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps,\" arXiv preprint arXiv:2206.00927, 2022.\n</snippet>\n<snippet id=ef8d8842-3>\nTitle: MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE\nSnippet: However, this often requires thousands of steps, resulting in significant overhead. DDIM (Song et al., 2020a) introduced deterministic sampling and proposed a probability ODE sampling approach, reducing the number of sampling steps to around 100. Subsequently, inspired by the Fokker-Planck equation (Risken & Risken, 1996), Song et al. (2020b) established a unification of SDE and ODE sampling methods from the perspective of the score function. Then, more higher-order ODE Preprint solvers were proposed e.g., DPM-Solver (Lu et al., 2022a) and DPM-Solver++ (Lu et al., 2022b), which utilize multistep methods for differential discretization. These approaches significantly reduce the number of sampling steps to around 10 while preserving accuracy. Higher-performance solvers (Zheng et al., 2023;Zhao et al., 2023) continue to be proposed; however, the gains are relatively marginal and have ultimately been replaced by the distillation method (Salimans & Ho, 2022;Yin et al., 2024). During the same period, flow matching models (Lipman et al., 2022;Esser et al., 2024) simplified and stabilized training by predicting the vector field velocity, enabling deterministic sampling with ODEs under 50 steps. Recent theoretical works (Gao et al., 2024;Albergo et al., 2023) has proven that the sampling method of flow matching is equivalent to DDIM, and demonstrated that flow matching models share the same equivalent SDE and ODE formulations as diffusion models. This provides important theoretical support and insights for our work, and we may explore interleaved sampling of SDE and ODE in probability flow models as a potential approach.\n</snippet>\n<snippet id=ef8d8842-4>\nTitle: Diffusion Sampling Correction via Approximately 10 Parameters\nSnippet: We investigated the impact of solver selection for generating ground truth trajectories on the performance of PAS using the CIFAR10 32×32 (Krizhevsky et al., 2009) and FFHQ 64×64 (Karras et al., 2019) datasets. We employed Heun's 2nd (Karras et al., 2022), DDIM (Song et al., 2021a), and DPM-Solver-2 (Lu et al., 2022a) solvers with 100 NFE to generate 10k trajectories for training the PAS to correct the DDIM solver, as shown in Table 9. Our findings indicate that the choice of solver for generating ground truth trajectories has negligible impact on the performance of PAS. This suggests that regardless of the solver used, a sufficient number of NFE (e.g., 100 NFE) enables the solving process to approximate the ground truth trajectories closely. Therefore, we simply fixed Heun's 2nd solver for all experiments.\n</snippet></tool_output> \n\nMini-synthesis:\n- We have clear conceptual definitions of Flow Matching (FM) as learning a continuous flow (velocity field) mapping a simple prior to data, training by approximating ODE velocities on linear interpolations between noise and data, and viewing it as a Neural ODE/CNF generalization. We also have evidence that FM provides a deterministic mapping and is positioned as an alternative to diffusion, with applications beyond images and links to normalizing flows and diffusion via continuous limits.\n- We have acceleration/solver context (DPM-Solvers as fast ODE solvers; around 10 steps; relation to DDIM; theoretical equivalence claims), and trajectory straightening methods (ReFlow, OFM) aiming for one-step/few-step sampling.\n- Quantitative benchmarks are partially represented via comparative tables (e.g., CoVAE table listing metrics for DPM-Solver and FM), but we lack direct FM benchmarks like FID on ImageNet from FM papers. However, recent works (e.g., SANA) show competitive performance and convergence speed with Flow-DPM-Solver, and broader surveys/positioning note FM’s adoption (e.g., SDv3).\n- Theoretical positioning (FM unifying perspective and equivalence to diffusion) is supported by a snippet citing Gao et al. 2024 and Albergo et al. 2023.\n\nSufficiency check: We can now synthesize a definition, core formulation (discrete/continuous), training target (velocity regression on linear interpolations), sampling via ODE solvers (DPM-Solvers), deterministic mapping claims, relation to diffusion/CNFs, and acceleration directions (trajectory straightening, one-step/few-step), plus empirical adoption and comparative context. While explicit ImageNet FID numbers for FM are limited in the retrieved snippets, we can still deliver a comprehensive, evidence-backed overview.\n\nStructure plan:\n- What FM is (core idea and relation to CNFs/flows/diffusion).\n- Formal formulation (discrete steps, linear interpolation, ODE velocity field; continuous view).\n- Training (trajectory regression vs denoising; examples and data construction).\n- Sampling (ODE integration with DPM-Solvers; dense trajectories; step counts; determinism).\n- Relation to diffusion and theory (equivalence/connections).\n- Acceleration and trajectory straightening (ReFlow, OFM, one-step/few-step).\n- Empirical status and adoption (SDv3; comparative notes; convergence/quality).\n- When to use FM (advantages: deterministic mapping, fast generation, reduced NFE), and limitations/open issues.\n\nNow I will write the final answer with citations tied to the retrieved snippets.</think>\n<answer>\n# What Flow Matching Models Are\n\nFlow Matching Models (FM) learn a continuous flow that transports a simple prior (typically isotropic Gaussian noise) to a target data distribution via a time-dependent vector field, and approximate this field with a neural network so that sampling reduces to numerical integration of an ODE<cite id=\"9c657d74-4\">Flow Matching (FM) (Lipman et al. 2022;Liu, Gong, and Liu 2022;Albergo and Vanden-Eijnden 2022) is a generative modeling framework that learns a velocity field to transform a source distribution into a target distribution through a continuous flow</cite><cite id=\"9c657d74-2\">The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows and diffusion models</cite>. In this view, FM generalizes continuous normalizing flows (CNFs) by removing the need to simulate trajectories during training while providing a unifying perspective that includes diffusion (modeled as stochastic differential equations) as a special case<cite id=\"9c657d74-4\">FM generalizes Continuous Normalizing Flows by removing the need for simulation during training, and diffusion models can be seen as a special case where the probability path is defined via stochastic differential equations</cite>.\n\n# Core Formulation: From Discrete Trajectories to Continuous Flows\n\nIn practice, FM specifies a sequence of linear interpolations between a data sample x1 and a random noise sample x0 over t∈[0,1], forming a forward path and defining a training example (x0, x1, t) via xt = (1−t) x0 + t x1<cite id=\"bbd08e4c-1\">During training, a training example is constructed by first sampling a target sample x1, drawing noise x0∼N(0,1), and selecting a timestep t∈[0,1], then defining the example via the linear interpolation xt = (1−t) x0 + t x1</cite>. The model is trained to approximate the ODE velocity vt = dx/dt along these paths, so that integrating the learned vector field from noise to data recovers an image sample<cite id=\"bbd08e4c-1\">The model is trained to approximate the velocity defined by an ordinary differential equation (ODE), vt = dx/dt, enabling it to guide the transformation from the intermediate sample xt to the real data sample x1</cite>. Conceptually, the family of interpolants defines a path of probability distributions between a reference (noise) and the data distribution, situating FM between normalizing flows and diffusion<cite id=\"9c657d74-2\">These models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution, and are closely related to both normalizing flows and diffusion models</cite>.\n\n# Training Targets: Velocity Regression and Deterministic Mapping\n\nUnlike denoising diffusion models that predict εθ(xt, t)≈(xt−x0)/√t, FM trains a neural network to regress the time-dependent vector field F(t,x) (the ODE’s velocity) along the learned interpolants, turning each FM training instance into a supervised regression task on the trajectory between noise and data<cite id=\"bbd08e4c-1\">A training example is defined through a linear interpolation between x0 and x1 at time t, and the model is trained to approximate the ODE velocity vt = dx/dt along this interpolation</cite>. This formulation yields a deterministic mapping from noise to data once F is learned, enabling fast generation by integrating the learned flow rather than running many stochastic diffusion steps<cite id=\"9c657d74-0\">Flow matching is emerging as a competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution, favored for fast generation and reduced need for large NFE</cite>. FM’s ability to interpolate between arbitrary distributions (not just noise-to-image) further generalizes its applicability beyond denoising, e.g., image-to-image translation<cite id=\"bbd08e4c-1\">A notable advantage of Flow Matching is its ability to interpolate between two arbitrary distributions, extending beyond noise-to-image scenarios and enabling image-to-image translation</cite>.\n\n# Sampling via ODE Solvers: Dense Trajectories and Step Counts\n\nTo generate samples, FM integrates the learned vector field from the prior (e.g., xT = x0) to the data distribution (e.g., x0≈0), and this integration can be performed with efficient ODE solvers to reduce the number of steps needed for high-quality outputs<cite id=\"9c657d74-3\">Flow-matching learns a time-dependent vector field to transform probability distributions and provides an efficient method for modeling ODEs via straightforward vector-field regression loss</cite>. The DPM-Solver line of work provides fast ODE-based samplers that typically converge in around 10 steps, improving upon earlier Eulerian or first-order methods and approaching or surpassing diffusion quality at comparable function evaluations<cite id=\"ef8d8842-3\">DPM-Solver (Lu et al., 2022a) and DPM-Solver++ (Lu et al., 2022b) utilize multistep methods for differential discretization and reduce the number of sampling steps to around 10 while preserving accuracy</cite><cite id=\"ffef5314-0\">Recent results report low FID scores for DPM-Solver and its successors, indicating competitive image quality at low NFE</cite>. Empirically, Flow-DPM-Solver variants based on FM show rapid convergence (≈10–20 steps) and strong quality, often outperforming Flow-Euler samplers with fewer steps<cite id=\"ffef5314-1\">Our Flow-DPM-Solver retains strengths of the original DPM-Solver, converging in 10–20 steps to stable, high-quality images, whereas Flow-Euler typically requires 30–50 steps</cite>. In broader comparative tables, DPM-Solver and FM-based methods achieve low scores on ImageNet and other benchmarks at low NFE, underscoring their efficiency<cite id=\"ffef5314-0\">Reported metrics show DPM-Solver achieving score 2.91 on ImageNet at 10 NFE and FM 6.35 at 142 NFE, among strong results</cite>.\n\n# Relation to Diffusion and Theory\n\nFM connects to diffusion models through continuous limits and equivalences: diffusion sampling can be viewed as probability flow ODEs under certain conditions, and recent theory shows that FM sampling is equivalent to DDIM and shares the same SDE/ODE formulations as diffusion models<cite id=\"ef8d8842-3\">Recent theoretical works (Gao et al., 2024;Albergo et al., 2023) have proven that the sampling method of flow matching is equivalent to DDIM and demonstrated that FM models share the same equivalent SDE and ODE formulations as diffusion models</cite>. FM is also positioned as a CNF generalization that avoids trajectory simulation during training, offering a unifying perspective that subsumes diffusion as an SDE special case<cite id=\"9c657d74-4\">FM generalizes CNFs by removing the need for simulation during training and provides a unifying perspective where diffusion can be seen as an SDE special case</cite>.\n\n# Accelerating FM: Trajectory Straightening and One-/Few-Step Sampling\n\nA key line of work accelerates FM by straightening the learned trajectories (which often curve), so that ODE integration is cheaper or even unnecessary. Rectified Flow (RF) iteratively refines a linear coupling between noise and data, progressively “rectifying” the flow, while other approaches enforce straight paths via optimal transport principles or consistency constraints on the velocity field<cite id=\"0c4e9332-1\">Rectified Flow iteratively solves FM and gradually rectifies trajectories, while other methods use optimal transport to obtain straight paths; FM processes usually have curved trajectories that slow ODE integration</cite><cite id=\"0c4e9332-2\">ReFlow replaces arbitrary coupling with deterministic coupling from a teacher to learn a rectified flow, and CFM applies consistency constraints to the velocity field to straighten trajectories</cite>. Optimal Flow Matching (OFM) shows that a single FM iteration can, under certain conditions, yield straight trajectories that can be simulated without ODE solving, further reducing inference cost<cite id=\"0c4e9332-1\">Optimal Flow Matching proposes a novel approach that after a single FM iteration obtains straight trajectories which can be simulated without ODE solving</cite>. These developments align with broader distillation and consistency-model strategies that learn multi-step or single-step “flow maps” for faster generation<cite id=\"ffef5314-2\">Consistency models estimate the single-time flow map to jump from any time s to data, while consistency trajectory models estimate the two-time flow map enabling multistep sampling; both aim to avoid ODE solves</cite>.\n\n# Empirical Status and Adoption\n\nFM and probability flow–based ODE samplers have been adopted in state-of-the-art text-to-image systems (e.g., SDv3) that combine FM with transformer-based conditioning to achieve high-fidelity image generation<cite id=\"9c657d74-0\">SDv3 (Esser et al., 2024) has adopted flow matching as their core framework combined with a transformer-based architecture, resulting in groundbreaking image generation capabilities</cite>. Comparative evaluations indicate that FM-based and DPM-Solver-based methods can achieve strong ImageNet scores with relatively few function evaluations compared to traditional diffusion, and recent works demonstrate that integrating FM samplers (e.g., DPM-Solver-2) yields high visual quality at 2–4 steps and competitive results at higher steps<cite id=\"c4780ee6-2\">With increased steps, LCM’s performance tends to decline, while TCD (a distillation/consistency approach aligned with FM-style sampling) even outperforms its teacher, and can generate high-quality images in 2 or 4 steps</cite><cite id=\"ffef5314-0\">Tables report low scores for DPM-Solver and FM at low NFE, indicating strong efficiency and quality</cite>. Beyond images, FM-style modeling has been explored in event forecasting and other domains, highlighting its flexibility as a generative framework<cite id=\"9c657d74-2\">EventFlow applies FM for temporal point process forecasting, noting FM’s broader applicability across domains</cite>.\n\n# When to Use Flow Matching\n\nFM is attractive when deterministic or near-deterministic generation with fewer steps is desired, as the learned vector field provides a direct path from noise to data and can be integrated efficiently with modern ODE solvers<cite id=\"9c657d74-0\">FM deterministically finds the mapping between noise and data distribution and reduces the need for large NFE</cite><cite id=\"ef8d8842-3\">Multistep DPM-Solvers reduce sampling to around 10 steps while preserving accuracy</cite>. FM also offers a unifying lens that connects CNFs and diffusion, enabling trajectory-based training and sampling with trajectory straightening and one-/few-step acceleration techniques<cite id=\"9c657d74-4\">FM generalizes CNFs and relates diffusion to ODEs via a unified view</cite><cite id=\"0c4e9332-1\">Trajectory curvature motivates straightening methods to accelerate sampling</cite>.\n\n# Summary\n\nIn short, Flow Matching Models learn a neural vector field that maps noise to data via a continuous flow, trained by regressing ODE velocities along linear interpolations between noise and images; sampling is performed by ODE integration (e.g., DPM-Solvers) and can be accelerated by straightening trajectories or distilling multi-step flows into one/few steps, yielding deterministic, efficient generation and strong empirical performance across tasks<cite id=\"bbd08e4c-1\">FM constructs linear interpolation examples and trains a model to approximate the ODE velocity vt between noise and image</cite><cite id=\"9c657d74-4\">FM learns a velocity field as a Neural ODE, generalizing CNFs and relating to diffusion</cite><cite id=\"ef8d8842-3\">DPM-Solvers provide fast ODE-based sampling in around 10 steps</cite><cite id=\"0c4e9332-1\">Trajectory straightening methods (e.g., OFM, RF) reduce integration cost and support one-step/few-step sampling</cite><cite id=\"9c657d74-0\">FM’s deterministic mapping and reduced NFE make it competitive with diffusion for high-quality image generation</cite>.\n</answer>",
    "total_tokens": 18270,
    "tool_call_count": 7,
    "stopped_reason": "natural",
    "tool_calls": [
      {
        "tool_name": "snippet_search",
        "output": "Title: Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation\nSnippet: Flow matching is emerging as the competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution. The deterministic property is favored in many generative applications, such as image inversion (Pokle et al. 2023) and editing (Hu et al. 2024), as well as in video and beyond (Davtyan, Sameni, and Favaro 2023;Song et al. 2024;Gao et al. 2024), due to its fast generation capability and reduced need for large NFE (Liu, Gong, and Liu 2023;Lipman et al. 2023;Liu 2022;Dao et al. 2023). Recently, some works has linked the connection between diffusion models (known as score-based models) and flow matching (Kingma and Gao 2024;Ma et al. 2024). Given these advantages, SDv3 (Esser et al. 2024) has adopted flow matching as their core framework, combined with a powerful transformer-based architecture (Peebles and Xie 2022), resulting in groundbreaking image generation capabilities. However, the computational complexity of iterative sampling still hinders these models from achieving real-time performance and lags behind GAN counterparts (Kang et al. 2023;Sauer et al. 2023a). Therefore, developing one-step and few-step sampling techniques is crucial to strike a balance between generation quality and sampling speed.\n\nTitle: Dragen3D: Multiview Geometry Consistent 3D Gaussian Generation with Drag-Based Control\nSnippet: Seed Points Generation. We employ a Rectified Flow model to generate seed points conditioned on a single input image. Owing to the sparsity of the seed points, the flow model is easier to train and effectively learns the distribution of the seed points. However, we also explored an alternative implementation using a transformerbased feed-forward approach, where point clouds are generated from learnable embeddings in a single pass, as in [Zou et al. 2024]. As demonstrated in Fig. 5, the feed-forward approach struggles to capture the true distribution of seed points and fails to produce satisfactory results in regions not visible in the input image. \n\nDimension Alignment. To match the dimension of the starting and target points in the Seed-Anchor Mapping Module, we encode the seed points using the Anchor-GS VAE encoder (Eq. 11). This process brings their distributions closer, reducing learning difficulty and reliance on image conditions. To validate this method, we conducted experiments by replacing the encoding approach with positional encoding . When using positional encoding, the Seed-Anchor Mapping overly relied on the image condition, neglecting the contribution of the seed points and failing to enable seed-driven 3DGS deformation, as shown in Fig. 6. \n\nToken Alignment. We ensure token alignment in Flow Matching by organizing tokens around seed points, followed by cluster-based partition and repetition. To evaluate its effectiveness, we conducted two ablation experiments, as shown in Tab. 2. In the No-cluster+Norepetition setting, we omitted the clustering step, aligning only the corresponding seed and anchor latents while filling unmatched portions with noise. This also prevented cluster-based downsampling in the Flow Model, resulting in doubled memory consumption. In the No-cluster setting, we repeated the seed latents to match the number of anchor latents but left them unordered, leading to disorganized token matching. As shown in Tab. 2, on a 40K subset with the same number of training steps, the absence of token alignment significantly degraded Flow Matching performance, resulting in inaccurate correspondences.\n\nTitle: EventFlow: Forecasting Temporal Point Processes with Flow Matching\nSnippet: The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows (Papamakarios et al., 2021) and diffusion models (Ho et al., 2020;Song et al., 2021). Intuitively, these models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution. These models are a popular alternative to diffusion, providing greater flexibility in model design, with recent applications in image generation (Ma et al., 2024;Dao et al., 2023), DNA and protein design (Stark et al., 2024;Campbell et al., 2024), and point cloud generation (Buhmann et al., 2023;Wu et al., 2023). To the best of our knowledge, our work is the first to explore flow matching for TPPs.\n\nTitle: Next Tokens Denoising for Speech Synthesis\nSnippet: Flow-matching [Lipman et al., 2022, Tong et al., 2023, Liu et al., 2022a] learns a time-dependent vector field to transform probability distributions, providing an efficient method for modeling ordinary differential equations (ODEs) through straightforward vector-field regression loss. By incorporating optimal transport principles [Khrulkov et al., 2022], continuous flow-matching generates ODEs with smooth, minimally varying vector fields, effectively mapping samples from a source to a target data distribution. Both diffusion and flow-matching models have delivered outstanding performance in text-to-image generation [Rombach et al., 2022], establishing new standards for creating high-quality, photorealistic images from text prompts. These models also demonstrate strong capabilities in other generative tasks, including text-to-speech, music generation, and text-to-video [Khachatryan et al., 2023, Schneider et al., 2023]. To accelerate sampling, techniques such as distilling pre-trained multi-step diffusion models into few-step models or developing standalone consistency models [Geng et al., 2025, Liu et al., 2023, Yan et al., 2024, Frans et al., 2024] have been introduced, enforcing consistency constraints on network outputs across time steps to ensure stable trajectory endpoints.\n\nTitle: Symmetrical Flow Matching: Unified Image Generation, Segmentation, and Classification with Score-Based Generative Models\nSnippet: Flow Matching (FM) (Lipman et al. 2022;Liu, Gong, and Liu 2022;Albergo and Vanden-Eijnden 2022) is a generative modeling framework that learns a velocity field to transform a source distribution into a target distribution through a continuous flow. By parameterizing this field with a neural network, the model becomes a Neural ODE (Chen et al. 2018), allowing efficient sampling via numerical integration. It has advanced state-of-the-art performance in diverse applications, including image (Esser et al. 2024), and audio generation (Vyas et al. 2023;Le et al. 2023), as well as protein modeling (Huguet et al. 2024) and robotics (Black et al. 2024). FM generalizes Continuous Normalizing Flows (CNFs) (Chen et al. 2018;Grathwohl et al. 2018) by removing the need for simulation during training, thereby making it computationally efficient. It also provides a unifying perspective on generative modeling, encompassing diffusion models, which can be seen as a special case where the probability path is defined via stochastic differential equations (Lipman et al. 2024).",
        "called": true,
        "timeout": false,
        "runtime": 3.2919936180114746,
        "error": "",
        "call_id": "9c657d74",
        "raw_output": {
          "data": [
            {
              "score": 0.5784473230088298,
              "paper": {
                "corpusId": "274982059",
                "title": "Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation",
                "authors": [
                  "Quan Dao",
                  "Hao Phung",
                  "T. Dao",
                  "Dimitris N. Metaxas",
                  "Anh Tran"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.16906, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Flow matching is emerging as the competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution. The deterministic property is favored in many generative applications, such as image inversion (Pokle et al. 2023) and editing (Hu et al. 2024), as well as in video and beyond (Davtyan, Sameni, and Favaro 2023;Song et al. 2024;Gao et al. 2024), due to its fast generation capability and reduced need for large NFE (Liu, Gong, and Liu 2023;Lipman et al. 2023;Liu 2022;Dao et al. 2023). Recently, some works has linked the connection between diffusion models (known as score-based models) and flow matching (Kingma and Gao 2024;Ma et al. 2024). Given these advantages, SDv3 (Esser et al. 2024) has adopted flow matching as their core framework, combined with a powerful transformer-based architecture (Peebles and Xie 2022), resulting in groundbreaking image generation capabilities. However, the computational complexity of iterative sampling still hinders these models from achieving real-time performance and lags behind GAN counterparts (Kang et al. 2023;Sauer et al. 2023a). Therefore, developing one-step and few-step sampling techniques is crucial to strike a balance between generation quality and sampling speed.",
                "snippetKind": "body",
                "section": "Related Work Flow Matching",
                "snippetOffset": {
                  "start": 6118,
                  "end": 7394
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 252,
                      "end": 270,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 284,
                      "end": 300,
                      "matchedPaperCorpusId": "221640669"
                    },
                    {
                      "start": 333,
                      "end": 367,
                      "matchedPaperCorpusId": "254044658"
                    },
                    {
                      "start": 367,
                      "end": 384,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 384,
                      "end": 400,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 471,
                      "end": 496,
                      "matchedPaperCorpusId": "261697392"
                    },
                    {
                      "start": 496,
                      "end": 515,
                      "matchedPaperCorpusId": "252734897"
                    },
                    {
                      "start": 515,
                      "end": 524,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 524,
                      "end": 540,
                      "matchedPaperCorpusId": "265498823"
                    },
                    {
                      "start": 662,
                      "end": 683,
                      "matchedPaperCorpusId": "260332161"
                    },
                    {
                      "start": 683,
                      "end": 698,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 729,
                      "end": 747,
                      "matchedPaperCorpusId": "268247980"
                    },
                    {
                      "start": 1096,
                      "end": 1114,
                      "matchedPaperCorpusId": "257427461"
                    },
                    {
                      "start": 1114,
                      "end": 1132,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 156
                    },
                    {
                      "start": 157,
                      "end": 541
                    },
                    {
                      "start": 542,
                      "end": 699
                    },
                    {
                      "start": 700,
                      "end": 938
                    },
                    {
                      "start": 939,
                      "end": 1134
                    },
                    {
                      "start": 1135,
                      "end": 1276
                    }
                  ]
                }
              }
            },
            {
              "score": 0.5182721555410085,
              "paper": {
                "corpusId": "276575007",
                "title": "Dragen3D: Multiview Geometry Consistent 3D Gaussian Generation with Drag-Based Control",
                "authors": [
                  "Jinbo Yan",
                  "Alan Zhao",
                  "Yixin Hu"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.16475, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Seed Points Generation. We employ a Rectified Flow model to generate seed points conditioned on a single input image. Owing to the sparsity of the seed points, the flow model is easier to train and effectively learns the distribution of the seed points. However, we also explored an alternative implementation using a transformerbased feed-forward approach, where point clouds are generated from learnable embeddings in a single pass, as in [Zou et al. 2024]. As demonstrated in Fig. 5, the feed-forward approach struggles to capture the true distribution of seed points and fails to produce satisfactory results in regions not visible in the input image. \n\nDimension Alignment. To match the dimension of the starting and target points in the Seed-Anchor Mapping Module, we encode the seed points using the Anchor-GS VAE encoder (Eq. 11). This process brings their distributions closer, reducing learning difficulty and reliance on image conditions. To validate this method, we conducted experiments by replacing the encoding approach with positional encoding . When using positional encoding, the Seed-Anchor Mapping overly relied on the image condition, neglecting the contribution of the seed points and failing to enable seed-driven 3DGS deformation, as shown in Fig. 6. \n\nToken Alignment. We ensure token alignment in Flow Matching by organizing tokens around seed points, followed by cluster-based partition and repetition. To evaluate its effectiveness, we conducted two ablation experiments, as shown in Tab. 2. In the No-cluster+Norepetition setting, we omitted the clustering step, aligning only the corresponding seed and anchor latents while filling unmatched portions with noise. This also prevented cluster-based downsampling in the Flow Model, resulting in doubled memory consumption. In the No-cluster setting, we repeated the seed latents to match the number of anchor latents but left them unordered, leading to disorganized token matching. As shown in Tab. 2, on a 40K subset with the same number of training steps, the absence of token alignment significantly degraded Flow Matching performance, resulting in inaccurate correspondences.",
                "snippetKind": "body",
                "section": "Ablation Study",
                "snippetOffset": {
                  "start": 29055,
                  "end": 31211
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 441,
                      "end": 457,
                      "matchedPaperCorpusId": "266209913"
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 23
                    },
                    {
                      "start": 24,
                      "end": 117
                    },
                    {
                      "start": 118,
                      "end": 253
                    },
                    {
                      "start": 254,
                      "end": 459
                    },
                    {
                      "start": 460,
                      "end": 655
                    },
                    {
                      "start": 658,
                      "end": 678
                    },
                    {
                      "start": 679,
                      "end": 833
                    },
                    {
                      "start": 834,
                      "end": 838
                    },
                    {
                      "start": 839,
                      "end": 949
                    },
                    {
                      "start": 950,
                      "end": 1061
                    },
                    {
                      "start": 1062,
                      "end": 1274
                    },
                    {
                      "start": 1277,
                      "end": 1293
                    },
                    {
                      "start": 1294,
                      "end": 1429
                    },
                    {
                      "start": 1430,
                      "end": 1692
                    },
                    {
                      "start": 1693,
                      "end": 1799
                    },
                    {
                      "start": 1800,
                      "end": 1958
                    },
                    {
                      "start": 1959,
                      "end": 2156
                    }
                  ]
                }
              }
            },
            {
              "score": 0.5161817238266891,
              "paper": {
                "corpusId": "278960160",
                "title": "EventFlow: Forecasting Temporal Point Processes with Flow Matching",
                "authors": [
                  "Gavin Kerrigan",
                  "Kai Nelson",
                  "Padhraic Smyth"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2410.07430, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows (Papamakarios et al., 2021) and diffusion models (Ho et al., 2020;Song et al., 2021). Intuitively, these models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution. These models are a popular alternative to diffusion, providing greater flexibility in model design, with recent applications in image generation (Ma et al., 2024;Dao et al., 2023), DNA and protein design (Stark et al., 2024;Campbell et al., 2024), and point cloud generation (Buhmann et al., 2023;Wu et al., 2023). To the best of our knowledge, our work is the first to explore flow matching for TPPs.",
                "snippetKind": "body",
                "section": "Flow Matching",
                "snippetOffset": {
                  "start": 7146,
                  "end": 8024
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 77,
                      "end": 98,
                      "matchedPaperCorpusId": "252734897"
                    },
                    {
                      "start": 98,
                      "end": 129,
                      "matchedPaperCorpusId": "252668615"
                    },
                    {
                      "start": 129,
                      "end": 146,
                      "matchedPaperCorpusId": "252111177"
                    },
                    {
                      "start": 238,
                      "end": 265,
                      "matchedPaperCorpusId": "208637478"
                    },
                    {
                      "start": 287,
                      "end": 304,
                      "matchedPaperCorpusId": "219955663"
                    },
                    {
                      "start": 304,
                      "end": 322,
                      "matchedPaperCorpusId": "227209335"
                    },
                    {
                      "start": 622,
                      "end": 639,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 639,
                      "end": 656,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 681,
                      "end": 701,
                      "matchedPaperCorpusId": "267547708"
                    },
                    {
                      "start": 701,
                      "end": 723,
                      "matchedPaperCorpusId": "267523194"
                    },
                    {
                      "start": 752,
                      "end": 774,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 774,
                      "end": 790,
                      "matchedPaperCorpusId": "254246595"
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 323
                    },
                    {
                      "start": 324,
                      "end": 476
                    },
                    {
                      "start": 477,
                      "end": 791
                    },
                    {
                      "start": 792,
                      "end": 878
                    }
                  ]
                }
              }
            },
            {
              "score": 0.49831214551738584,
              "paper": {
                "corpusId": "280391476",
                "title": "Next Tokens Denoising for Speech Synthesis",
                "authors": [
                  "Yanqing Liu",
                  "Rui Xue",
                  "Chong Zhang",
                  "Yufei Liu",
                  "Gang Wang",
                  "Bohan Li",
                  "Yao Qian",
                  "Lei He",
                  "Shujie Liu",
                  "Sheng Zhao"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2507.22746, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Flow-matching [Lipman et al., 2022, Tong et al., 2023, Liu et al., 2022a] learns a time-dependent vector field to transform probability distributions, providing an efficient method for modeling ordinary differential equations (ODEs) through straightforward vector-field regression loss. By incorporating optimal transport principles [Khrulkov et al., 2022], continuous flow-matching generates ODEs with smooth, minimally varying vector fields, effectively mapping samples from a source to a target data distribution. Both diffusion and flow-matching models have delivered outstanding performance in text-to-image generation [Rombach et al., 2022], establishing new standards for creating high-quality, photorealistic images from text prompts. These models also demonstrate strong capabilities in other generative tasks, including text-to-speech, music generation, and text-to-video [Khachatryan et al., 2023, Schneider et al., 2023]. To accelerate sampling, techniques such as distilling pre-trained multi-step diffusion models into few-step models or developing standalone consistency models [Geng et al., 2025, Liu et al., 2023, Yan et al., 2024, Frans et al., 2024] have been introduced, enforcing consistency constraints on network outputs across time steps to ensure stable trajectory endpoints.",
                "snippetKind": "body",
                "section": "Flow Matching for Generative Modeling",
                "snippetOffset": {
                  "start": 8487,
                  "end": 9787
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 14,
                      "end": 34,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 34,
                      "end": 53,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 53,
                      "end": 72,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 333,
                      "end": 356,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 624,
                      "end": 646,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 882,
                      "end": 907,
                      "matchedPaperCorpusId": "257687280"
                    },
                    {
                      "start": 907,
                      "end": 932,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1093,
                      "end": 1111,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1111,
                      "end": 1129,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1129,
                      "end": 1147,
                      "matchedPaperCorpusId": "269758053"
                    },
                    {
                      "start": 1147,
                      "end": 1168,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 286
                    },
                    {
                      "start": 287,
                      "end": 516
                    },
                    {
                      "start": 517,
                      "end": 742
                    },
                    {
                      "start": 743,
                      "end": 933
                    },
                    {
                      "start": 934,
                      "end": 1300
                    }
                  ]
                }
              }
            },
            {
              "score": 0.48374118182863673,
              "paper": {
                "corpusId": "279318279",
                "title": "Symmetrical Flow Matching: Unified Image Generation, Segmentation, and Classification with Score-Based Generative Models",
                "authors": [
                  "Francisco Caetano",
                  "Christiaan G. A. Viviers",
                  "Peter H. N. de With",
                  "F. V. D. Sommen"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2506.10634, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Flow Matching (FM) (Lipman et al. 2022;Liu, Gong, and Liu 2022;Albergo and Vanden-Eijnden 2022) is a generative modeling framework that learns a velocity field to transform a source distribution into a target distribution through a continuous flow. By parameterizing this field with a neural network, the model becomes a Neural ODE (Chen et al. 2018), allowing efficient sampling via numerical integration. It has advanced state-of-the-art performance in diverse applications, including image (Esser et al. 2024), and audio generation (Vyas et al. 2023;Le et al. 2023), as well as protein modeling (Huguet et al. 2024) and robotics (Black et al. 2024). FM generalizes Continuous Normalizing Flows (CNFs) (Chen et al. 2018;Grathwohl et al. 2018) by removing the need for simulation during training, thereby making it computationally efficient. It also provides a unifying perspective on generative modeling, encompassing diffusion models, which can be seen as a special case where the probability path is defined via stochastic differential equations (Lipman et al. 2024).",
                "snippetKind": "body",
                "section": "Related Work Flow Matching",
                "snippetOffset": {
                  "start": 3954,
                  "end": 5025
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 19,
                      "end": 39,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 39,
                      "end": 63,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 63,
                      "end": 94,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 332,
                      "end": 350,
                      "matchedPaperCorpusId": "260453100"
                    },
                    {
                      "start": 493,
                      "end": 512,
                      "matchedPaperCorpusId": "268247980"
                    },
                    {
                      "start": 535,
                      "end": 553,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 553,
                      "end": 568,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 598,
                      "end": 617,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 632,
                      "end": 651,
                      "matchedPaperCorpusId": "273811174"
                    },
                    {
                      "start": 704,
                      "end": 722,
                      "matchedPaperCorpusId": "260453100"
                    },
                    {
                      "start": 722,
                      "end": 743,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1050,
                      "end": 1070,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 248
                    },
                    {
                      "start": 249,
                      "end": 406
                    },
                    {
                      "start": 407,
                      "end": 652
                    },
                    {
                      "start": 653,
                      "end": 842
                    },
                    {
                      "start": 843,
                      "end": 1071
                    }
                  ]
                }
              }
            }
          ],
          "retrievalVersion": "pa1-v1"
        },
        "documents": [
          {
            "id": "d1c17de1-8aed-42be-becf-e37336f4c218",
            "title": "Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation",
            "url": "",
            "snippet": "Flow matching is emerging as the competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution. The deterministic property is favored in many generative applications, such as image inversion (Pokle et al. 2023) and editing (Hu et al. 2024), as well as in video and beyond (Davtyan, Sameni, and Favaro 2023;Song et al. 2024;Gao et al. 2024), due to its fast generation capability and reduced need for large NFE (Liu, Gong, and Liu 2023;Lipman et al. 2023;Liu 2022;Dao et al. 2023). Recently, some works has linked the connection between diffusion models (known as score-based models) and flow matching (Kingma and Gao 2024;Ma et al. 2024). Given these advantages, SDv3 (Esser et al. 2024) has adopted flow matching as their core framework, combined with a powerful transformer-based architecture (Peebles and Xie 2022), resulting in groundbreaking image generation capabilities. However, the computational complexity of iterative sampling still hinders these models from achieving real-time performance and lags behind GAN counterparts (Kang et al. 2023;Sauer et al. 2023a). Therefore, developing one-step and few-step sampling techniques is crucial to strike a balance between generation quality and sampling speed.",
            "text": "",
            "summary": null,
            "score": 0.5784473230088298,
            "error": null
          },
          {
            "id": "ed0c42fe-3c84-4044-9c2f-d98ee27762a0",
            "title": "Dragen3D: Multiview Geometry Consistent 3D Gaussian Generation with Drag-Based Control",
            "url": "",
            "snippet": "Seed Points Generation. We employ a Rectified Flow model to generate seed points conditioned on a single input image. Owing to the sparsity of the seed points, the flow model is easier to train and effectively learns the distribution of the seed points. However, we also explored an alternative implementation using a transformerbased feed-forward approach, where point clouds are generated from learnable embeddings in a single pass, as in [Zou et al. 2024]. As demonstrated in Fig. 5, the feed-forward approach struggles to capture the true distribution of seed points and fails to produce satisfactory results in regions not visible in the input image. \n\nDimension Alignment. To match the dimension of the starting and target points in the Seed-Anchor Mapping Module, we encode the seed points using the Anchor-GS VAE encoder (Eq. 11). This process brings their distributions closer, reducing learning difficulty and reliance on image conditions. To validate this method, we conducted experiments by replacing the encoding approach with positional encoding . When using positional encoding, the Seed-Anchor Mapping overly relied on the image condition, neglecting the contribution of the seed points and failing to enable seed-driven 3DGS deformation, as shown in Fig. 6. \n\nToken Alignment. We ensure token alignment in Flow Matching by organizing tokens around seed points, followed by cluster-based partition and repetition. To evaluate its effectiveness, we conducted two ablation experiments, as shown in Tab. 2. In the No-cluster+Norepetition setting, we omitted the clustering step, aligning only the corresponding seed and anchor latents while filling unmatched portions with noise. This also prevented cluster-based downsampling in the Flow Model, resulting in doubled memory consumption. In the No-cluster setting, we repeated the seed latents to match the number of anchor latents but left them unordered, leading to disorganized token matching. As shown in Tab. 2, on a 40K subset with the same number of training steps, the absence of token alignment significantly degraded Flow Matching performance, resulting in inaccurate correspondences.",
            "text": "",
            "summary": null,
            "score": 0.5182721555410085,
            "error": null
          },
          {
            "id": "9d9cb86b-55ba-40b2-aedc-6a9f60a345a7",
            "title": "EventFlow: Forecasting Temporal Point Processes with Flow Matching",
            "url": "",
            "snippet": "The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows (Papamakarios et al., 2021) and diffusion models (Ho et al., 2020;Song et al., 2021). Intuitively, these models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution. These models are a popular alternative to diffusion, providing greater flexibility in model design, with recent applications in image generation (Ma et al., 2024;Dao et al., 2023), DNA and protein design (Stark et al., 2024;Campbell et al., 2024), and point cloud generation (Buhmann et al., 2023;Wu et al., 2023). To the best of our knowledge, our work is the first to explore flow matching for TPPs.",
            "text": "",
            "summary": null,
            "score": 0.5161817238266891,
            "error": null
          },
          {
            "id": "6ef58a78-fbdd-4430-b70d-859204cd51ee",
            "title": "Next Tokens Denoising for Speech Synthesis",
            "url": "",
            "snippet": "Flow-matching [Lipman et al., 2022, Tong et al., 2023, Liu et al., 2022a] learns a time-dependent vector field to transform probability distributions, providing an efficient method for modeling ordinary differential equations (ODEs) through straightforward vector-field regression loss. By incorporating optimal transport principles [Khrulkov et al., 2022], continuous flow-matching generates ODEs with smooth, minimally varying vector fields, effectively mapping samples from a source to a target data distribution. Both diffusion and flow-matching models have delivered outstanding performance in text-to-image generation [Rombach et al., 2022], establishing new standards for creating high-quality, photorealistic images from text prompts. These models also demonstrate strong capabilities in other generative tasks, including text-to-speech, music generation, and text-to-video [Khachatryan et al., 2023, Schneider et al., 2023]. To accelerate sampling, techniques such as distilling pre-trained multi-step diffusion models into few-step models or developing standalone consistency models [Geng et al., 2025, Liu et al., 2023, Yan et al., 2024, Frans et al., 2024] have been introduced, enforcing consistency constraints on network outputs across time steps to ensure stable trajectory endpoints.",
            "text": "",
            "summary": null,
            "score": 0.49831214551738584,
            "error": null
          },
          {
            "id": "8c2f67cf-d62b-4fe6-87f4-3aefeba6290b",
            "title": "Symmetrical Flow Matching: Unified Image Generation, Segmentation, and Classification with Score-Based Generative Models",
            "url": "",
            "snippet": "Flow Matching (FM) (Lipman et al. 2022;Liu, Gong, and Liu 2022;Albergo and Vanden-Eijnden 2022) is a generative modeling framework that learns a velocity field to transform a source distribution into a target distribution through a continuous flow. By parameterizing this field with a neural network, the model becomes a Neural ODE (Chen et al. 2018), allowing efficient sampling via numerical integration. It has advanced state-of-the-art performance in diverse applications, including image (Esser et al. 2024), and audio generation (Vyas et al. 2023;Le et al. 2023), as well as protein modeling (Huguet et al. 2024) and robotics (Black et al. 2024). FM generalizes Continuous Normalizing Flows (CNFs) (Chen et al. 2018;Grathwohl et al. 2018) by removing the need for simulation during training, thereby making it computationally efficient. It also provides a unifying perspective on generative modeling, encompassing diffusion models, which can be seen as a special case where the probability path is defined via stochastic differential equations (Lipman et al. 2024).",
            "text": "",
            "summary": null,
            "score": 0.48374118182863673,
            "error": null
          }
        ],
        "query": "Flow Matching Models image generation 2022 2023"
      },
      {
        "tool_name": "snippet_search",
        "output": "Title: FlowSDF: Flow Matching for Medical Image Segmentation Using Distance Transforms\nSnippet: Flow matching has been shown to be a more robust and stable alternative to diffusion models offering enhanced performance (Lipman et al., 2022), and has recently been applied to high-quality, unconditional image synthesis (Esser et al., 2024). Moreover, recent studies demonstrated its effectiveness in various domains such as depth estimation, label-conditioned image generation and image inpainting (Dao et al., 2023;Gui et al., 2024;Yariv et al., 2023). The subsequent section will introduce flow matching in more detail.\n\nTitle: PixelFlow: Pixel-Space Generative Models with Flow\nSnippet: The Flow Matching algorithm [1,38,40] progressively transforms a sample from a prior distribution, which is typically a standard normal distribution, to the target data distribution. This is accomplished by defining a forward process consisting of a sequence of linear paths that directly connect samples from the prior distribution to corresponding \n\nPixelFlow for cascaded image generation from pixel space. We partition the entire generation procedure into series resolution stages. At the beginning of each resolution stage, we upscale the relatively noisy results from the preceding stage and use them as the starting point for the current stage. Consequently, as the resolution enhances, more refined samples can be obtained. \n\nsamples in the target distribution. During training, a training example is constructed by first sampling a target sample x 1 , drawing noise x 0 ∼ N (0, 1) from the standard normal distribution, and selecting a timestep t ∈ [0, 1]. The training example is then defined through a linear interpolation: \n\nThe model is trained to approximate the velocity defined by an ordinary differential equation (ODE), v t = dxt dt , enabling it to effectively guide the transformation from the intermediate sample x t to the real data sample x 1 . \n\nA notable advantage of Flow Matching is its ability to interpolate between two arbitrary distributions, not restricted to using only a standard Gaussian as the source domain. Consequently, in image generation tasks, Flow Matching extends beyond noise-to-image scenarios and can be effectively employed for diverse applications such as image-toimage translation.\n\nTitle: Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation\nSnippet: Flow matching is emerging as the competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution. The deterministic property is favored in many generative applications, such as image inversion (Pokle et al. 2023) and editing (Hu et al. 2024), as well as in video and beyond (Davtyan, Sameni, and Favaro 2023;Song et al. 2024;Gao et al. 2024), due to its fast generation capability and reduced need for large NFE (Liu, Gong, and Liu 2023;Lipman et al. 2023;Liu 2022;Dao et al. 2023). Recently, some works has linked the connection between diffusion models (known as score-based models) and flow matching (Kingma and Gao 2024;Ma et al. 2024). Given these advantages, SDv3 (Esser et al. 2024) has adopted flow matching as their core framework, combined with a powerful transformer-based architecture (Peebles and Xie 2022), resulting in groundbreaking image generation capabilities. However, the computational complexity of iterative sampling still hinders these models from achieving real-time performance and lags behind GAN counterparts (Kang et al. 2023;Sauer et al. 2023a). Therefore, developing one-step and few-step sampling techniques is crucial to strike a balance between generation quality and sampling speed.\n\nTitle: ASpanFormer: Detector-Free Image Matching with Adaptive Span Transformer\nSnippet: We inherit the scheme in LoFTR [13] to generate final correspondences, including a coarse matching stage and a sub-pixel refinement stage. Retrieving flow φp ∈ R S 2 ×4 from flow map φ according to the location of Qpi 5:\n\nTitle: EventFlow: Forecasting Temporal Point Processes with Flow Matching\nSnippet: The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows (Papamakarios et al., 2021) and diffusion models (Ho et al., 2020;Song et al., 2021). Intuitively, these models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution. These models are a popular alternative to diffusion, providing greater flexibility in model design, with recent applications in image generation (Ma et al., 2024;Dao et al., 2023), DNA and protein design (Stark et al., 2024;Campbell et al., 2024), and point cloud generation (Buhmann et al., 2023;Wu et al., 2023). To the best of our knowledge, our work is the first to explore flow matching for TPPs.",
        "called": true,
        "timeout": false,
        "runtime": 8.013594150543213,
        "error": "",
        "call_id": "bbd08e4c",
        "raw_output": {
          "data": [
            {
              "score": 0.6812873977188528,
              "paper": {
                "corpusId": "270068161",
                "title": "FlowSDF: Flow Matching for Medical Image Segmentation Using Distance Transforms",
                "authors": [
                  "L. Bogensperger",
                  "Dominik Narnhofer",
                  "Alexander Falk",
                  "Konrad Schindler",
                  "Thomas Pock"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2405.18087, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Flow matching has been shown to be a more robust and stable alternative to diffusion models offering enhanced performance (Lipman et al., 2022), and has recently been applied to high-quality, unconditional image synthesis (Esser et al., 2024). Moreover, recent studies demonstrated its effectiveness in various domains such as depth estimation, label-conditioned image generation and image inpainting (Dao et al., 2023;Gui et al., 2024;Yariv et al., 2023). The subsequent section will introduce flow matching in more detail.",
                "snippetKind": "body",
                "section": "Medical Image Segmentation",
                "snippetOffset": {
                  "start": 8974,
                  "end": 9498
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 122,
                      "end": 143,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 222,
                      "end": 242,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 401,
                      "end": 419,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 419,
                      "end": 436,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 436,
                      "end": 455,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 243
                    },
                    {
                      "start": 244,
                      "end": 456
                    },
                    {
                      "start": 457,
                      "end": 524
                    }
                  ]
                }
              }
            },
            {
              "score": 0.6590745719834944,
              "paper": {
                "corpusId": "277667747",
                "title": "PixelFlow: Pixel-Space Generative Models with Flow",
                "authors": [
                  "Shoufa Chen",
                  "Chongjian Ge",
                  "Shilong Zhang",
                  "Peize Sun",
                  "Ping Luo"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2504.07963, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "The Flow Matching algorithm [1,38,40] progressively transforms a sample from a prior distribution, which is typically a standard normal distribution, to the target data distribution. This is accomplished by defining a forward process consisting of a sequence of linear paths that directly connect samples from the prior distribution to corresponding \n\nPixelFlow for cascaded image generation from pixel space. We partition the entire generation procedure into series resolution stages. At the beginning of each resolution stage, we upscale the relatively noisy results from the preceding stage and use them as the starting point for the current stage. Consequently, as the resolution enhances, more refined samples can be obtained. \n\nsamples in the target distribution. During training, a training example is constructed by first sampling a target sample x 1 , drawing noise x 0 ∼ N (0, 1) from the standard normal distribution, and selecting a timestep t ∈ [0, 1]. The training example is then defined through a linear interpolation: \n\nThe model is trained to approximate the velocity defined by an ordinary differential equation (ODE), v t = dxt dt , enabling it to effectively guide the transformation from the intermediate sample x t to the real data sample x 1 . \n\nA notable advantage of Flow Matching is its ability to interpolate between two arbitrary distributions, not restricted to using only a standard Gaussian as the source domain. Consequently, in image generation tasks, Flow Matching extends beyond noise-to-image scenarios and can be effectively employed for diverse applications such as image-toimage translation.",
                "snippetKind": "body",
                "section": "Preliminary: Flow Matching",
                "snippetOffset": {
                  "start": 5871,
                  "end": 7502
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 28,
                      "end": 31,
                      "matchedPaperCorpusId": "252668615"
                    },
                    {
                      "start": 31,
                      "end": 34,
                      "matchedPaperCorpusId": "252734897"
                    },
                    {
                      "start": 34,
                      "end": 37,
                      "matchedPaperCorpusId": "252111177"
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 182
                    },
                    {
                      "start": 183,
                      "end": 349
                    },
                    {
                      "start": 352,
                      "end": 409
                    },
                    {
                      "start": 410,
                      "end": 485
                    },
                    {
                      "start": 486,
                      "end": 651
                    },
                    {
                      "start": 652,
                      "end": 731
                    },
                    {
                      "start": 734,
                      "end": 769
                    },
                    {
                      "start": 770,
                      "end": 965
                    },
                    {
                      "start": 966,
                      "end": 1034
                    },
                    {
                      "start": 1037,
                      "end": 1267
                    },
                    {
                      "start": 1270,
                      "end": 1444
                    },
                    {
                      "start": 1445,
                      "end": 1631
                    }
                  ]
                }
              }
            },
            {
              "score": 0.6411349148860142,
              "paper": {
                "corpusId": "274982059",
                "title": "Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation",
                "authors": [
                  "Quan Dao",
                  "Hao Phung",
                  "T. Dao",
                  "Dimitris N. Metaxas",
                  "Anh Tran"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.16906, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Flow matching is emerging as the competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution. The deterministic property is favored in many generative applications, such as image inversion (Pokle et al. 2023) and editing (Hu et al. 2024), as well as in video and beyond (Davtyan, Sameni, and Favaro 2023;Song et al. 2024;Gao et al. 2024), due to its fast generation capability and reduced need for large NFE (Liu, Gong, and Liu 2023;Lipman et al. 2023;Liu 2022;Dao et al. 2023). Recently, some works has linked the connection between diffusion models (known as score-based models) and flow matching (Kingma and Gao 2024;Ma et al. 2024). Given these advantages, SDv3 (Esser et al. 2024) has adopted flow matching as their core framework, combined with a powerful transformer-based architecture (Peebles and Xie 2022), resulting in groundbreaking image generation capabilities. However, the computational complexity of iterative sampling still hinders these models from achieving real-time performance and lags behind GAN counterparts (Kang et al. 2023;Sauer et al. 2023a). Therefore, developing one-step and few-step sampling techniques is crucial to strike a balance between generation quality and sampling speed.",
                "snippetKind": "body",
                "section": "Related Work Flow Matching",
                "snippetOffset": {
                  "start": 6118,
                  "end": 7394
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 252,
                      "end": 270,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 284,
                      "end": 300,
                      "matchedPaperCorpusId": "221640669"
                    },
                    {
                      "start": 333,
                      "end": 367,
                      "matchedPaperCorpusId": "254044658"
                    },
                    {
                      "start": 367,
                      "end": 384,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 384,
                      "end": 400,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 471,
                      "end": 496,
                      "matchedPaperCorpusId": "261697392"
                    },
                    {
                      "start": 496,
                      "end": 515,
                      "matchedPaperCorpusId": "252734897"
                    },
                    {
                      "start": 515,
                      "end": 524,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 524,
                      "end": 540,
                      "matchedPaperCorpusId": "265498823"
                    },
                    {
                      "start": 662,
                      "end": 683,
                      "matchedPaperCorpusId": "260332161"
                    },
                    {
                      "start": 683,
                      "end": 698,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 729,
                      "end": 747,
                      "matchedPaperCorpusId": "268247980"
                    },
                    {
                      "start": 1096,
                      "end": 1114,
                      "matchedPaperCorpusId": "257427461"
                    },
                    {
                      "start": 1114,
                      "end": 1132,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 156
                    },
                    {
                      "start": 157,
                      "end": 541
                    },
                    {
                      "start": 542,
                      "end": 699
                    },
                    {
                      "start": 700,
                      "end": 938
                    },
                    {
                      "start": 939,
                      "end": 1134
                    },
                    {
                      "start": 1135,
                      "end": 1276
                    }
                  ]
                }
              }
            },
            {
              "score": 0.5642473185802919,
              "paper": {
                "corpusId": "251929348",
                "title": "ASpanFormer: Detector-Free Image Matching with Adaptive Span Transformer",
                "authors": [
                  "Hongkai Chen",
                  "Zixin Luo",
                  "Lei Zhou",
                  "Yurun Tian",
                  "Mingmin Zhen",
                  "Tian Fang",
                  "D. McKinnon",
                  "Yanghai Tsin",
                  "Long Quan"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": "GREEN",
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2208.14201, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "We inherit the scheme in LoFTR [13] to generate final correspondences, including a coarse matching stage and a sub-pixel refinement stage. Retrieving flow φp ∈ R S 2 ×4 from flow map φ according to the location of Qpi 5:",
                "snippetKind": "body",
                "section": "Matches Determination",
                "snippetOffset": {
                  "start": 17042,
                  "end": 17262
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 31,
                      "end": 35,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 138
                    },
                    {
                      "start": 139,
                      "end": 220
                    }
                  ]
                }
              }
            },
            {
              "score": 0.5611891715508343,
              "paper": {
                "corpusId": "278960160",
                "title": "EventFlow: Forecasting Temporal Point Processes with Flow Matching",
                "authors": [
                  "Gavin Kerrigan",
                  "Kai Nelson",
                  "Padhraic Smyth"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2410.07430, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows (Papamakarios et al., 2021) and diffusion models (Ho et al., 2020;Song et al., 2021). Intuitively, these models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution. These models are a popular alternative to diffusion, providing greater flexibility in model design, with recent applications in image generation (Ma et al., 2024;Dao et al., 2023), DNA and protein design (Stark et al., 2024;Campbell et al., 2024), and point cloud generation (Buhmann et al., 2023;Wu et al., 2023). To the best of our knowledge, our work is the first to explore flow matching for TPPs.",
                "snippetKind": "body",
                "section": "Flow Matching",
                "snippetOffset": {
                  "start": 7146,
                  "end": 8024
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 77,
                      "end": 98,
                      "matchedPaperCorpusId": "252734897"
                    },
                    {
                      "start": 98,
                      "end": 129,
                      "matchedPaperCorpusId": "252668615"
                    },
                    {
                      "start": 129,
                      "end": 146,
                      "matchedPaperCorpusId": "252111177"
                    },
                    {
                      "start": 238,
                      "end": 265,
                      "matchedPaperCorpusId": "208637478"
                    },
                    {
                      "start": 287,
                      "end": 304,
                      "matchedPaperCorpusId": "219955663"
                    },
                    {
                      "start": 304,
                      "end": 322,
                      "matchedPaperCorpusId": "227209335"
                    },
                    {
                      "start": 622,
                      "end": 639,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 639,
                      "end": 656,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 681,
                      "end": 701,
                      "matchedPaperCorpusId": "267547708"
                    },
                    {
                      "start": 701,
                      "end": 723,
                      "matchedPaperCorpusId": "267523194"
                    },
                    {
                      "start": 752,
                      "end": 774,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 774,
                      "end": 790,
                      "matchedPaperCorpusId": "254246595"
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 323
                    },
                    {
                      "start": 324,
                      "end": 476
                    },
                    {
                      "start": 477,
                      "end": 791
                    },
                    {
                      "start": 792,
                      "end": 878
                    }
                  ]
                }
              }
            }
          ],
          "retrievalVersion": "pa1-v1"
        },
        "documents": [
          {
            "id": "573460b6-fe84-4069-81bd-f00d1b3b9c53",
            "title": "FlowSDF: Flow Matching for Medical Image Segmentation Using Distance Transforms",
            "url": "",
            "snippet": "Flow matching has been shown to be a more robust and stable alternative to diffusion models offering enhanced performance (Lipman et al., 2022), and has recently been applied to high-quality, unconditional image synthesis (Esser et al., 2024). Moreover, recent studies demonstrated its effectiveness in various domains such as depth estimation, label-conditioned image generation and image inpainting (Dao et al., 2023;Gui et al., 2024;Yariv et al., 2023). The subsequent section will introduce flow matching in more detail.",
            "text": "",
            "summary": null,
            "score": 0.6812873977188528,
            "error": null
          },
          {
            "id": "1b7e9cbc-5536-4bef-83b0-79037d026385",
            "title": "PixelFlow: Pixel-Space Generative Models with Flow",
            "url": "",
            "snippet": "The Flow Matching algorithm [1,38,40] progressively transforms a sample from a prior distribution, which is typically a standard normal distribution, to the target data distribution. This is accomplished by defining a forward process consisting of a sequence of linear paths that directly connect samples from the prior distribution to corresponding \n\nPixelFlow for cascaded image generation from pixel space. We partition the entire generation procedure into series resolution stages. At the beginning of each resolution stage, we upscale the relatively noisy results from the preceding stage and use them as the starting point for the current stage. Consequently, as the resolution enhances, more refined samples can be obtained. \n\nsamples in the target distribution. During training, a training example is constructed by first sampling a target sample x 1 , drawing noise x 0 ∼ N (0, 1) from the standard normal distribution, and selecting a timestep t ∈ [0, 1]. The training example is then defined through a linear interpolation: \n\nThe model is trained to approximate the velocity defined by an ordinary differential equation (ODE), v t = dxt dt , enabling it to effectively guide the transformation from the intermediate sample x t to the real data sample x 1 . \n\nA notable advantage of Flow Matching is its ability to interpolate between two arbitrary distributions, not restricted to using only a standard Gaussian as the source domain. Consequently, in image generation tasks, Flow Matching extends beyond noise-to-image scenarios and can be effectively employed for diverse applications such as image-toimage translation.",
            "text": "",
            "summary": null,
            "score": 0.6590745719834944,
            "error": null
          },
          {
            "id": "4a1d96bd-98d2-4c85-9329-6c02efd57695",
            "title": "Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation",
            "url": "",
            "snippet": "Flow matching is emerging as the competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution. The deterministic property is favored in many generative applications, such as image inversion (Pokle et al. 2023) and editing (Hu et al. 2024), as well as in video and beyond (Davtyan, Sameni, and Favaro 2023;Song et al. 2024;Gao et al. 2024), due to its fast generation capability and reduced need for large NFE (Liu, Gong, and Liu 2023;Lipman et al. 2023;Liu 2022;Dao et al. 2023). Recently, some works has linked the connection between diffusion models (known as score-based models) and flow matching (Kingma and Gao 2024;Ma et al. 2024). Given these advantages, SDv3 (Esser et al. 2024) has adopted flow matching as their core framework, combined with a powerful transformer-based architecture (Peebles and Xie 2022), resulting in groundbreaking image generation capabilities. However, the computational complexity of iterative sampling still hinders these models from achieving real-time performance and lags behind GAN counterparts (Kang et al. 2023;Sauer et al. 2023a). Therefore, developing one-step and few-step sampling techniques is crucial to strike a balance between generation quality and sampling speed.",
            "text": "",
            "summary": null,
            "score": 0.6411349148860142,
            "error": null
          },
          {
            "id": "f93afe44-9b35-4b40-a7cc-34a269761831",
            "title": "ASpanFormer: Detector-Free Image Matching with Adaptive Span Transformer",
            "url": "",
            "snippet": "We inherit the scheme in LoFTR [13] to generate final correspondences, including a coarse matching stage and a sub-pixel refinement stage. Retrieving flow φp ∈ R S 2 ×4 from flow map φ according to the location of Qpi 5:",
            "text": "",
            "summary": null,
            "score": 0.5642473185802919,
            "error": null
          },
          {
            "id": "aa3839b5-c630-4e8f-a76d-a23fc6b90c74",
            "title": "EventFlow: Forecasting Temporal Point Processes with Flow Matching",
            "url": "",
            "snippet": "The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows (Papamakarios et al., 2021) and diffusion models (Ho et al., 2020;Song et al., 2021). Intuitively, these models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution. These models are a popular alternative to diffusion, providing greater flexibility in model design, with recent applications in image generation (Ma et al., 2024;Dao et al., 2023), DNA and protein design (Stark et al., 2024;Campbell et al., 2024), and point cloud generation (Buhmann et al., 2023;Wu et al., 2023). To the best of our knowledge, our work is the first to explore flow matching for TPPs.",
            "text": "",
            "summary": null,
            "score": 0.5611891715508343,
            "error": null
          }
        ],
        "query": "Flow Matching for Image Generation Lipman 2022 2023 arXiv"
      },
      {
        "tool_name": "snippet_search",
        "output": "Title: Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions\nSnippet: We further apply the proposed method to advanced ODE samplers with higher-order accuracy. Table 2 presents the effectiveness of RX-DPM when applied to DPM-Solvers (Lu et al., 2022) on CIFAR-10 and LSUN Bedroom (Yu et al., 2015). Among the variations of DPM solvers, we utilize the singlestep versions of DPM-Solver-2 and DPM-Solver-3. Note that, since a single-step DPM-solver-n can be considered as an n th -order Runge-Kutta-like solver, we apply RX-DPM with p = n + 1 in Equation ( 22) for the DPM-solver-n. Additionally, we compare our method with another accelerated diffusion sampler, DEIS (Zhang & Chen, 2023), for class-conditioned image generation on ImageNet (64 × 64) in Table 4 of Appendix B.1. As shown in the results, RX-DPM consistently achieves the best performance across all NFEs. \n\nAs another type of advanced sampler, we consider PNDM (Liu et al., 2022). S-PNDM and F-PNDM employ linear multistep methods, specifically the 2-step and 4-step Adams-Bashforth methods, respectively, except for the initial few time steps. Accordingly, we apply RX-DPM with p = 3 and p = 5 in Equation ( 22) for S-PNDM and F-PNDM, respectively. The results on the CIFAR-10, CelebA (Liu et al., 2015), and LSUN Church (Yu et al., 2015) datasets are presented in Table 3. While RX-DPM improves performance in most cases, an exception arises with F-PNDM on the LSUN Church dataset, where RX-DPM does not provide a clear advantage. Upon analysis, we observe that the baseline performance of F-PNDM is highest when using 10 time steps and degrades as the number of steps increases (Liu et al., 2022).\n\nTitle: Optimal Flow Matching: Learning Straight Trajectories in Just One Step\nSnippet: Recent success in generative modeling Liu et al. [2023], Esser et al. [2024], Cao et al. [2024] is mostly driven by Flow Matching (FM) Lipman et al. [2022] models.These models move a known distribution to a target one via ordinary differential equations (ODE) describing the mass movement.However, such processes usually have curved trajectories, resulting in time-consuming ODE integration for sampling.To overcome this issue, researches developed several improvements of the FM Liu [2022], Liu et al. [2022], Pooladian et al. [2023], which aim to recover more straight paths.\n\nRectified Flow (RF) method Liu [2022], Liu et al. [2022] iteratively solves FM and gradually rectifies trajectories.Unfortunately, in each FM iteration, it accumulates the error, see [Liu et al., 2022, §2.2] and [Liu, 2022, §6].This may spoil the performance of the method.The other popular branch of approaches to straighten trajectories is based on the connection between straight paths and Optimal Transport (OT) Villani [2021].The main goal of OT is to find the way to move one probability distribution to another with the minimal effort.Such OT maps are usually described by ODEs with straight trajectories.In OT Conditional Flow Matching (OT-CFM) Pooladian et al. [2023], Tong et al. [2023], the authors propose to apply FM on top of OT solution between batches from considered distributions.Unfortunately, such a heuristic does not guarantee straight paths because of minibatch OT biases, see, e.g., [Tong et al., 2023, Figure 1, right] for the practical illustration.\n\nContributions.In this paper, we fix the above-mentioned problems of the straightening methods.\n\nWe propose a novel Optimal Flow Matching (OFM) approach ( §3) that after a single FM iteration obtains straight trajectories which can be simulated without ODE solving.\n\nTitle: Flow Generator Matching\nSnippet: In recent years, there have been efforts to accelerate the sampling process of flow-matching models, most current work focuses on straightening the trajectories of ordinary differential equations (ODEs). ReFlow (Liu et al., 2022) replaces the arbitrary coupling of noise and data originally used for training flow matching with a deterministic coupling generated by a teacher model, enabling the model to learn a rectified flow from the data. CFM (Yang et al., 2024) shares a similar concept with consistency models but differs by applying consistency constraints to the velocity field space instead of the sample space. This approach also serves as a form of regularization aimed at straightening the trajectories of ODEs. Though these works have demonstrated decent accelerations, they are essentially different from our proposed FGM. The FGM is built upon a probabilistic perspective that guarantees the generator distribution matches the teacher FM by minimizing the flow-matching objective. Besides, as we show in Section 5.1, the FGM outperforms the mentioned methods with significant margins.\n\nTitle: Variational Control for Guidance in Diffusion Models\nSnippet: Sampling proceeds by inferring the control (shaded) followed by sampling from the guided posterior (shaded) at any time t 1: Input: Optimization Steps: N, Guidance: γ, Pretrained denoiser: ϵ θ (., .), Timestep schedule: {t} T j=0 , DDIM Coefficients: α t , σ t , Loss Weights: τ t , κ t , w T 2: Initialization: \n\n9: \n\n10: \n\nend for 15: \n\n16: end for 17: return x 0 \n\nContinuous-Time Variants. To apply DTM to continuoustime diffusion and flow matching, we adapt the transient costs C tr . We call the following Continuous-Time Diffusion Trajectory Matching, derived for continuous-time diffusion (Song et al., 2020) in Appendix A.2: \n\nSimilarly, for flow matching (Lipman et al., 2023;Liu et al., 2023;Albergo et al., 2023), we refer to this as Flow Trajectory Matching (FTM), see Appendix A.3: \n\nNext, we present a specific parameterization of our framework and its instantiation using standard diffusion models.\n\nTitle: Improving Clinical Dataset Condensation with Mode Connectivity-based Trajectory Surrogates\nSnippet: • We introduce mode connectivity-based trajectory surrogates (quadratic Bézier curves) as compact, low-curvature replacements for full SGD paths in TM-based DC framework. This proposed mechanism can be employed in any existing TM framework. \n\n• We theoretically justify the use of mode connectivity, specifically quadratic Bézier curves, as an effective surrogate for full optimisation trajectories, explaining why it preserves essential training signals while avoiding SGD stochasticity. \n\n• We conduct an extensive empirical evaluation on five real-world clinical datasets, demonstrating that the proposed approach produces clinically useful condensed datasets that support reliable downstream model development. (Du et al., 2023), Difficulty-Aligned Trajectory Matching (DATM) (Guo et al., 2024), and TrajEctory matching with Soft Label Assignment (TESLA) (Liu et al., 2023) introduce curvature regularisation, difficulty-based curricula, and scalable soft-label assignment respectively. Despite strong results, TM methods depend on dense trajectories-tens to hundreds of checkpoints-and inherit the noise and curvature of SGD paths, inflating storage and introducing instability that limits clinical use.",
        "called": true,
        "timeout": false,
        "runtime": 15.264132022857666,
        "error": "",
        "call_id": "0c4e9332",
        "raw_output": {
          "data": [
            {
              "score": 0.43071938898539885,
              "paper": {
                "corpusId": "277502453",
                "title": "Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions",
                "authors": [
                  "J. Choi",
                  "Junoh Kang",
                  "Bohyung Han"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2504.01855, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "We further apply the proposed method to advanced ODE samplers with higher-order accuracy. Table 2 presents the effectiveness of RX-DPM when applied to DPM-Solvers (Lu et al., 2022) on CIFAR-10 and LSUN Bedroom (Yu et al., 2015). Among the variations of DPM solvers, we utilize the singlestep versions of DPM-Solver-2 and DPM-Solver-3. Note that, since a single-step DPM-solver-n can be considered as an n th -order Runge-Kutta-like solver, we apply RX-DPM with p = n + 1 in Equation ( 22) for the DPM-solver-n. Additionally, we compare our method with another accelerated diffusion sampler, DEIS (Zhang & Chen, 2023), for class-conditioned image generation on ImageNet (64 × 64) in Table 4 of Appendix B.1. As shown in the results, RX-DPM consistently achieves the best performance across all NFEs. \n\nAs another type of advanced sampler, we consider PNDM (Liu et al., 2022). S-PNDM and F-PNDM employ linear multistep methods, specifically the 2-step and 4-step Adams-Bashforth methods, respectively, except for the initial few time steps. Accordingly, we apply RX-DPM with p = 3 and p = 5 in Equation ( 22) for S-PNDM and F-PNDM, respectively. The results on the CIFAR-10, CelebA (Liu et al., 2015), and LSUN Church (Yu et al., 2015) datasets are presented in Table 3. While RX-DPM improves performance in most cases, an exception arises with F-PNDM on the LSUN Church dataset, where RX-DPM does not provide a clear advantage. Upon analysis, we observe that the baseline performance of F-PNDM is highest when using 10 time steps and degrades as the number of steps increases (Liu et al., 2022).",
                "snippetKind": "body",
                "section": "COMPARISONS ON HIGHER-ORDER SOLVERS",
                "snippetOffset": {
                  "start": 22681,
                  "end": 24275
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 163,
                      "end": 180,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 210,
                      "end": 227,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 855,
                      "end": 873,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1180,
                      "end": 1198,
                      "matchedPaperCorpusId": "459456"
                    },
                    {
                      "start": 1216,
                      "end": 1233,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 89
                    },
                    {
                      "start": 90,
                      "end": 228
                    },
                    {
                      "start": 229,
                      "end": 334
                    },
                    {
                      "start": 335,
                      "end": 510
                    },
                    {
                      "start": 511,
                      "end": 706
                    },
                    {
                      "start": 707,
                      "end": 798
                    },
                    {
                      "start": 801,
                      "end": 874
                    },
                    {
                      "start": 875,
                      "end": 1038
                    },
                    {
                      "start": 1039,
                      "end": 1143
                    },
                    {
                      "start": 1144,
                      "end": 1268
                    },
                    {
                      "start": 1269,
                      "end": 1426
                    },
                    {
                      "start": 1427,
                      "end": 1594
                    }
                  ]
                }
              }
            },
            {
              "score": 0.4114471374680064,
              "paper": {
                "corpusId": "268536996",
                "title": "Optimal Flow Matching: Learning Straight Trajectories in Just One Step",
                "authors": [
                  "Nikita Kornilov",
                  "Alexander Gasnikov",
                  "Alexander Korotin"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2403.13117, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Recent success in generative modeling Liu et al. [2023], Esser et al. [2024], Cao et al. [2024] is mostly driven by Flow Matching (FM) Lipman et al. [2022] models.These models move a known distribution to a target one via ordinary differential equations (ODE) describing the mass movement.However, such processes usually have curved trajectories, resulting in time-consuming ODE integration for sampling.To overcome this issue, researches developed several improvements of the FM Liu [2022], Liu et al. [2022], Pooladian et al. [2023], which aim to recover more straight paths.\n\nRectified Flow (RF) method Liu [2022], Liu et al. [2022] iteratively solves FM and gradually rectifies trajectories.Unfortunately, in each FM iteration, it accumulates the error, see [Liu et al., 2022, §2.2] and [Liu, 2022, §6].This may spoil the performance of the method.The other popular branch of approaches to straighten trajectories is based on the connection between straight paths and Optimal Transport (OT) Villani [2021].The main goal of OT is to find the way to move one probability distribution to another with the minimal effort.Such OT maps are usually described by ODEs with straight trajectories.In OT Conditional Flow Matching (OT-CFM) Pooladian et al. [2023], Tong et al. [2023], the authors propose to apply FM on top of OT solution between batches from considered distributions.Unfortunately, such a heuristic does not guarantee straight paths because of minibatch OT biases, see, e.g., [Tong et al., 2023, Figure 1, right] for the practical illustration.\n\nContributions.In this paper, we fix the above-mentioned problems of the straightening methods.\n\nWe propose a novel Optimal Flow Matching (OFM) approach ( §3) that after a single FM iteration obtains straight trajectories which can be simulated without ODE solving.",
                "snippetKind": "body",
                "section": "Introduction",
                "snippetOffset": {
                  "start": 15,
                  "end": 1835
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 38,
                      "end": 55,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 57,
                      "end": 76,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 78,
                      "end": 95,
                      "matchedPaperCorpusId": "265039918"
                    },
                    {
                      "start": 135,
                      "end": 155,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 477,
                      "end": 490,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 492,
                      "end": 509,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 511,
                      "end": 534,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 606,
                      "end": 616,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 618,
                      "end": 635,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 762,
                      "end": 785,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 791,
                      "end": 806,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 995,
                      "end": 1009,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1232,
                      "end": 1255,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1257,
                      "end": 1275,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1486,
                      "end": 1522,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 163
                    },
                    {
                      "start": 163,
                      "end": 289
                    },
                    {
                      "start": 289,
                      "end": 404
                    },
                    {
                      "start": 404,
                      "end": 577
                    },
                    {
                      "start": 579,
                      "end": 695
                    },
                    {
                      "start": 695,
                      "end": 807
                    },
                    {
                      "start": 807,
                      "end": 852
                    },
                    {
                      "start": 852,
                      "end": 1010
                    },
                    {
                      "start": 1010,
                      "end": 1121
                    },
                    {
                      "start": 1121,
                      "end": 1191
                    },
                    {
                      "start": 1191,
                      "end": 1377
                    },
                    {
                      "start": 1377,
                      "end": 1554
                    },
                    {
                      "start": 1556,
                      "end": 1570
                    },
                    {
                      "start": 1570,
                      "end": 1650
                    },
                    {
                      "start": 1652,
                      "end": 1820
                    }
                  ]
                }
              }
            },
            {
              "score": 0.3983458533962454,
              "paper": {
                "corpusId": "273638670",
                "title": "Flow Generator Matching",
                "authors": [
                  "Zemin Huang",
                  "Zhengyang Geng",
                  "Weijian Luo",
                  "Guo-Jun Qi"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2410.19310, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "In recent years, there have been efforts to accelerate the sampling process of flow-matching models, most current work focuses on straightening the trajectories of ordinary differential equations (ODEs). ReFlow (Liu et al., 2022) replaces the arbitrary coupling of noise and data originally used for training flow matching with a deterministic coupling generated by a teacher model, enabling the model to learn a rectified flow from the data. CFM (Yang et al., 2024) shares a similar concept with consistency models but differs by applying consistency constraints to the velocity field space instead of the sample space. This approach also serves as a form of regularization aimed at straightening the trajectories of ODEs. Though these works have demonstrated decent accelerations, they are essentially different from our proposed FGM. The FGM is built upon a probabilistic perspective that guarantees the generator distribution matches the teacher FM by minimizing the flow-matching objective. Besides, as we show in Section 5.1, the FGM outperforms the mentioned methods with significant margins.",
                "snippetKind": "body",
                "section": "RELATED WORKS",
                "snippetOffset": {
                  "start": 5467,
                  "end": 6566
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 211,
                      "end": 229,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 447,
                      "end": 466,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 203
                    },
                    {
                      "start": 204,
                      "end": 442
                    },
                    {
                      "start": 443,
                      "end": 620
                    },
                    {
                      "start": 621,
                      "end": 723
                    },
                    {
                      "start": 724,
                      "end": 836
                    },
                    {
                      "start": 837,
                      "end": 995
                    },
                    {
                      "start": 996,
                      "end": 1099
                    }
                  ]
                }
              }
            },
            {
              "score": 0.38768229406063526,
              "paper": {
                "corpusId": "276161220",
                "title": "Variational Control for Guidance in Diffusion Models",
                "authors": [
                  "Kushagra Pandey",
                  "Farrin Marouf Sofian",
                  "Felix Draxler",
                  "Theofanis Karaletsos",
                  "Stephan Mandt"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.03686, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Sampling proceeds by inferring the control (shaded) followed by sampling from the guided posterior (shaded) at any time t 1: Input: Optimization Steps: N, Guidance: γ, Pretrained denoiser: ϵ θ (., .), Timestep schedule: {t} T j=0 , DDIM Coefficients: α t , σ t , Loss Weights: τ t , κ t , w T 2: Initialization: \n\n9: \n\n10: \n\nend for 15: \n\n16: end for 17: return x 0 \n\nContinuous-Time Variants. To apply DTM to continuoustime diffusion and flow matching, we adapt the transient costs C tr . We call the following Continuous-Time Diffusion Trajectory Matching, derived for continuous-time diffusion (Song et al., 2020) in Appendix A.2: \n\nSimilarly, for flow matching (Lipman et al., 2023;Liu et al., 2023;Albergo et al., 2023), we refer to this as Flow Trajectory Matching (FTM), see Appendix A.3: \n\nNext, we present a specific parameterization of our framework and its instantiation using standard diffusion models.",
                "snippetKind": "body",
                "section": "Variational Control for Diffusion Guidance",
                "snippetOffset": {
                  "start": 10462,
                  "end": 11376
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 597,
                      "end": 616,
                      "matchedPaperCorpusId": "227209335"
                    },
                    {
                      "start": 665,
                      "end": 686,
                      "matchedPaperCorpusId": "252734897"
                    },
                    {
                      "start": 686,
                      "end": 703,
                      "matchedPaperCorpusId": "252111177"
                    },
                    {
                      "start": 703,
                      "end": 724,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 200
                    },
                    {
                      "start": 201,
                      "end": 311
                    },
                    {
                      "start": 314,
                      "end": 316
                    },
                    {
                      "start": 319,
                      "end": 322
                    },
                    {
                      "start": 325,
                      "end": 336
                    },
                    {
                      "start": 339,
                      "end": 365
                    },
                    {
                      "start": 368,
                      "end": 393
                    },
                    {
                      "start": 394,
                      "end": 489
                    },
                    {
                      "start": 490,
                      "end": 633
                    },
                    {
                      "start": 636,
                      "end": 795
                    },
                    {
                      "start": 798,
                      "end": 914
                    }
                  ]
                }
              }
            },
            {
              "score": 0.37960688116957325,
              "paper": {
                "corpusId": "281887040",
                "title": "Improving Clinical Dataset Condensation with Mode Connectivity-based Trajectory Surrogates",
                "authors": [
                  "P. Nganjimi",
                  "Andrew A. S. Soltan",
                  "Danielle Belgrave",
                  "Lei A. Clifton",
                  "David A. Clifton",
                  "Anshul Thakur"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2510.05805, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "• We introduce mode connectivity-based trajectory surrogates (quadratic Bézier curves) as compact, low-curvature replacements for full SGD paths in TM-based DC framework. This proposed mechanism can be employed in any existing TM framework. \n\n• We theoretically justify the use of mode connectivity, specifically quadratic Bézier curves, as an effective surrogate for full optimisation trajectories, explaining why it preserves essential training signals while avoiding SGD stochasticity. \n\n• We conduct an extensive empirical evaluation on five real-world clinical datasets, demonstrating that the proposed approach produces clinically useful condensed datasets that support reliable downstream model development. (Du et al., 2023), Difficulty-Aligned Trajectory Matching (DATM) (Guo et al., 2024), and TrajEctory matching with Soft Label Assignment (TESLA) (Liu et al., 2023) introduce curvature regularisation, difficulty-based curricula, and scalable soft-label assignment respectively. Despite strong results, TM methods depend on dense trajectories-tens to hundreds of checkpoints-and inherit the noise and curvature of SGD paths, inflating storage and introducing instability that limits clinical use.",
                "snippetKind": "body",
                "section": "INTRODUCTION",
                "snippetOffset": {
                  "start": 4198,
                  "end": 5406
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 715,
                      "end": 732,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 780,
                      "end": 798,
                      "matchedPaperCorpusId": "263831254"
                    },
                    {
                      "start": 859,
                      "end": 877,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 170
                    },
                    {
                      "start": 171,
                      "end": 240
                    },
                    {
                      "start": 243,
                      "end": 488
                    },
                    {
                      "start": 491,
                      "end": 714
                    },
                    {
                      "start": 715,
                      "end": 990
                    },
                    {
                      "start": 991,
                      "end": 1208
                    }
                  ]
                }
              }
            }
          ],
          "retrievalVersion": "pa1-v1"
        },
        "documents": [
          {
            "id": "a76a4b36-ad11-449d-a4b4-a70546270d17",
            "title": "Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions",
            "url": "",
            "snippet": "We further apply the proposed method to advanced ODE samplers with higher-order accuracy. Table 2 presents the effectiveness of RX-DPM when applied to DPM-Solvers (Lu et al., 2022) on CIFAR-10 and LSUN Bedroom (Yu et al., 2015). Among the variations of DPM solvers, we utilize the singlestep versions of DPM-Solver-2 and DPM-Solver-3. Note that, since a single-step DPM-solver-n can be considered as an n th -order Runge-Kutta-like solver, we apply RX-DPM with p = n + 1 in Equation ( 22) for the DPM-solver-n. Additionally, we compare our method with another accelerated diffusion sampler, DEIS (Zhang & Chen, 2023), for class-conditioned image generation on ImageNet (64 × 64) in Table 4 of Appendix B.1. As shown in the results, RX-DPM consistently achieves the best performance across all NFEs. \n\nAs another type of advanced sampler, we consider PNDM (Liu et al., 2022). S-PNDM and F-PNDM employ linear multistep methods, specifically the 2-step and 4-step Adams-Bashforth methods, respectively, except for the initial few time steps. Accordingly, we apply RX-DPM with p = 3 and p = 5 in Equation ( 22) for S-PNDM and F-PNDM, respectively. The results on the CIFAR-10, CelebA (Liu et al., 2015), and LSUN Church (Yu et al., 2015) datasets are presented in Table 3. While RX-DPM improves performance in most cases, an exception arises with F-PNDM on the LSUN Church dataset, where RX-DPM does not provide a clear advantage. Upon analysis, we observe that the baseline performance of F-PNDM is highest when using 10 time steps and degrades as the number of steps increases (Liu et al., 2022).",
            "text": "",
            "summary": null,
            "score": 0.43071938898539885,
            "error": null
          },
          {
            "id": "49149368-cbb7-4057-899a-4f8b609eb63c",
            "title": "Optimal Flow Matching: Learning Straight Trajectories in Just One Step",
            "url": "",
            "snippet": "Recent success in generative modeling Liu et al. [2023], Esser et al. [2024], Cao et al. [2024] is mostly driven by Flow Matching (FM) Lipman et al. [2022] models.These models move a known distribution to a target one via ordinary differential equations (ODE) describing the mass movement.However, such processes usually have curved trajectories, resulting in time-consuming ODE integration for sampling.To overcome this issue, researches developed several improvements of the FM Liu [2022], Liu et al. [2022], Pooladian et al. [2023], which aim to recover more straight paths.\n\nRectified Flow (RF) method Liu [2022], Liu et al. [2022] iteratively solves FM and gradually rectifies trajectories.Unfortunately, in each FM iteration, it accumulates the error, see [Liu et al., 2022, §2.2] and [Liu, 2022, §6].This may spoil the performance of the method.The other popular branch of approaches to straighten trajectories is based on the connection between straight paths and Optimal Transport (OT) Villani [2021].The main goal of OT is to find the way to move one probability distribution to another with the minimal effort.Such OT maps are usually described by ODEs with straight trajectories.In OT Conditional Flow Matching (OT-CFM) Pooladian et al. [2023], Tong et al. [2023], the authors propose to apply FM on top of OT solution between batches from considered distributions.Unfortunately, such a heuristic does not guarantee straight paths because of minibatch OT biases, see, e.g., [Tong et al., 2023, Figure 1, right] for the practical illustration.\n\nContributions.In this paper, we fix the above-mentioned problems of the straightening methods.\n\nWe propose a novel Optimal Flow Matching (OFM) approach ( §3) that after a single FM iteration obtains straight trajectories which can be simulated without ODE solving.",
            "text": "",
            "summary": null,
            "score": 0.4114471374680064,
            "error": null
          },
          {
            "id": "8a4633a9-d2cb-4206-9249-9bdd2509ed5b",
            "title": "Flow Generator Matching",
            "url": "",
            "snippet": "In recent years, there have been efforts to accelerate the sampling process of flow-matching models, most current work focuses on straightening the trajectories of ordinary differential equations (ODEs). ReFlow (Liu et al., 2022) replaces the arbitrary coupling of noise and data originally used for training flow matching with a deterministic coupling generated by a teacher model, enabling the model to learn a rectified flow from the data. CFM (Yang et al., 2024) shares a similar concept with consistency models but differs by applying consistency constraints to the velocity field space instead of the sample space. This approach also serves as a form of regularization aimed at straightening the trajectories of ODEs. Though these works have demonstrated decent accelerations, they are essentially different from our proposed FGM. The FGM is built upon a probabilistic perspective that guarantees the generator distribution matches the teacher FM by minimizing the flow-matching objective. Besides, as we show in Section 5.1, the FGM outperforms the mentioned methods with significant margins.",
            "text": "",
            "summary": null,
            "score": 0.3983458533962454,
            "error": null
          },
          {
            "id": "9bb86fb0-a945-453d-9d5d-af1896d0e40f",
            "title": "Variational Control for Guidance in Diffusion Models",
            "url": "",
            "snippet": "Sampling proceeds by inferring the control (shaded) followed by sampling from the guided posterior (shaded) at any time t 1: Input: Optimization Steps: N, Guidance: γ, Pretrained denoiser: ϵ θ (., .), Timestep schedule: {t} T j=0 , DDIM Coefficients: α t , σ t , Loss Weights: τ t , κ t , w T 2: Initialization: \n\n9: \n\n10: \n\nend for 15: \n\n16: end for 17: return x 0 \n\nContinuous-Time Variants. To apply DTM to continuoustime diffusion and flow matching, we adapt the transient costs C tr . We call the following Continuous-Time Diffusion Trajectory Matching, derived for continuous-time diffusion (Song et al., 2020) in Appendix A.2: \n\nSimilarly, for flow matching (Lipman et al., 2023;Liu et al., 2023;Albergo et al., 2023), we refer to this as Flow Trajectory Matching (FTM), see Appendix A.3: \n\nNext, we present a specific parameterization of our framework and its instantiation using standard diffusion models.",
            "text": "",
            "summary": null,
            "score": 0.38768229406063526,
            "error": null
          },
          {
            "id": "ad45e784-b28d-4de0-97cf-605b189ce6b0",
            "title": "Improving Clinical Dataset Condensation with Mode Connectivity-based Trajectory Surrogates",
            "url": "",
            "snippet": "• We introduce mode connectivity-based trajectory surrogates (quadratic Bézier curves) as compact, low-curvature replacements for full SGD paths in TM-based DC framework. This proposed mechanism can be employed in any existing TM framework. \n\n• We theoretically justify the use of mode connectivity, specifically quadratic Bézier curves, as an effective surrogate for full optimisation trajectories, explaining why it preserves essential training signals while avoiding SGD stochasticity. \n\n• We conduct an extensive empirical evaluation on five real-world clinical datasets, demonstrating that the proposed approach produces clinically useful condensed datasets that support reliable downstream model development. (Du et al., 2023), Difficulty-Aligned Trajectory Matching (DATM) (Guo et al., 2024), and TrajEctory matching with Soft Label Assignment (TESLA) (Liu et al., 2023) introduce curvature regularisation, difficulty-based curricula, and scalable soft-label assignment respectively. Despite strong results, TM methods depend on dense trajectories-tens to hundreds of checkpoints-and inherit the noise and curvature of SGD paths, inflating storage and introducing instability that limits clinical use.",
            "text": "",
            "summary": null,
            "score": 0.37960688116957325,
            "error": null
          }
        ],
        "query": "DPM-Solver-2 flow matching dense trajectories Liu Gong Liu 2023 arXiv"
      },
      {
        "tool_name": "snippet_search",
        "output": "Title: Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions\nSnippet: We further apply the proposed method to advanced ODE samplers with higher-order accuracy. Table 2 presents the effectiveness of RX-DPM when applied to DPM-Solvers (Lu et al., 2022) on CIFAR-10 and LSUN Bedroom (Yu et al., 2015). Among the variations of DPM solvers, we utilize the singlestep versions of DPM-Solver-2 and DPM-Solver-3. Note that, since a single-step DPM-solver-n can be considered as an n th -order Runge-Kutta-like solver, we apply RX-DPM with p = n + 1 in Equation ( 22) for the DPM-solver-n. Additionally, we compare our method with another accelerated diffusion sampler, DEIS (Zhang & Chen, 2023), for class-conditioned image generation on ImageNet (64 × 64) in Table 4 of Appendix B.1. As shown in the results, RX-DPM consistently achieves the best performance across all NFEs. \n\nAs another type of advanced sampler, we consider PNDM (Liu et al., 2022). S-PNDM and F-PNDM employ linear multistep methods, specifically the 2-step and 4-step Adams-Bashforth methods, respectively, except for the initial few time steps. Accordingly, we apply RX-DPM with p = 3 and p = 5 in Equation ( 22) for S-PNDM and F-PNDM, respectively. The results on the CIFAR-10, CelebA (Liu et al., 2015), and LSUN Church (Yu et al., 2015) datasets are presented in Table 3. While RX-DPM improves performance in most cases, an exception arises with F-PNDM on the LSUN Church dataset, where RX-DPM does not provide a clear advantage. Upon analysis, we observe that the baseline performance of F-PNDM is highest when using 10 time steps and degrades as the number of steps increases (Liu et al., 2022).\n\nTitle: Hyper-Spherical Optimal Transport for Semantic Alignment in Text-to-3D End-to-End Generation\nSnippet: Venue E2E Open 3D dataset Size Kiss3DGen [55] arXiv 2025 ✓ ✓ OBJ 100 TRELLIS [56] arXiv 2024 ✓ ✗ OBJ NA 3DTopia-XL [57] arXiv 2024 ✓ ✗ OBJ NA Ln3diff [58] ECCV 2024 ✓ ✓ SPN & OBJ NA Xcube [38] CVPR 2024 ✓ ✓ SPN & OBJ 30 EXIM [39] TOG 2023 ✓ ✓ SPN & 3DF NA Michelangelo [40] NIPS 2024 ✓ ✓ SPN 2592 Diffusion-SDF [17] CVPR 2023 ✓ ✓ Text2Shape NA Shap•E [18] arXiv 2023 ✓ ✓ Point-e NA TAPS3D [33] CVPR 2023 ✓ ✓ SPN 1000 SDFusion [7] CVPR 2023 ✓ ✓ Text2shape NA CLIP-Forge [16] CVPR 2022 ✓ ✓ SPN 234 Hunyuan3D [59] arXiv 2024 × ✓ OBJ 70 DreamMesh [54] ECCV achieved by integrating existing text-to-image algorithms. Michelangelo [40] aligns shape and clip text/image features through autoencoders to generate high-quality shapes, but there are still significant semantic inconsistencies in publicly available models. These CLIP-guided text-to-3D content generation methods have yielded impressive results, but as remarked in Dream3d [20], [40], most of them overlooked the gap between the text and image embedding spaces. Consequently, semantic alignment is the key to filling this gap and improving text-shape consistency.\n\nTitle: Trajectory Consistency Distillation\nSnippet: To illustrate the effectiveness and superiority of our methods, we perform qualitative and quantitative comparisons with prior works, including Euler (Karras et al., 2022), efficient numerical ODE solvers like DDIM (Song et al., 2020a) and DPM-Solver++(2S) (Lu et al., 2022b), and a relevant work LCM (Luo et al., 2023a) as baseline. \n\nQualitative Results. As illustrated in Figure 4, prior efficient numerical methods produce suboptimal images with 4 steps, while LCM can generate relatively better images. Our TCD further enhances visual quality. With an increased number of function evaluations (20 steps), the quality of samples generated by DDIM or DPM-Solver++(2S) improves rapidly. However, the improvement in LCM is not as noticeable, resulting in smoother and less detailed images due to the accumulated error in multistep sampling. In contrast, TCD addresses this flaw, producing more detailed images that surpass even the teacher model, e.g., SDXL with DDIM. \n\nQuantitative Comparison. For the quantitative evaluation, we conducted zero-shot image generation using 5K captions from COCO2017 validation set. We employed the Frechet Inception Distance (FID) and the Image Complexity Score (Feng et al., 2022) to assess the sample quality and visual complexity of generated images. Additionally, we used Image Reward (Xu et al., 2023) and PickScore (Kirstain et al., 2023) to quantify text-image alignment and human preference. As depicted in Table 1, TCD shows an improvement in the performance of LCM across various timesteps and metrics. In comparison to numerical ODE-Solver, TCD exhibits the ability to generate high-quality images in only 2 or 4 steps, surpassing them significantly. When increasing steps to 8 or 20, LCM's performance tends to decline, while TCD even outperforms its teacher in almost all metrics.\n\nTitle: The Poisson Midpoint Method for Langevin Dynamics: Provably Efficient Discretization for Diffusion Models\nSnippet: For unconditional image generation of high-resolution images, third order (order=3) Multistep DPM-Solvers with uniform time steps are recommended. To ensure a competitive benchmark, we evaluate the DPM-Solver on six different settings by tuning the parameters 'order' and 'skip_type'. Our evaluations are shown in Table 7, where the best score for every setting, highlighted in bold, are chosen in our plots for comparison. We use the official code of [37] with parameters 'algorithm_type = dpmsolver' 'method = multistep' and vary the parameters 'order' and 'skip_type' accordingly.\n\nTitle: Solving General Noisy Inverse Problem via Posterior Sampling: A Policy Gradient Viewpoint\nSnippet: All the experiments are implemented using NVIDIA A100 GPU.We display the running time for each image in Table 3.Notice that by using the DDPM solver, DPG takes more time than DPS due to MC sampling.However, the guidance score estimated by DPG is more accurate.Therefore, we have use the DDIM solver to retrieve images with less running time.",
        "called": true,
        "timeout": false,
        "runtime": 16.448132038116455,
        "error": "",
        "call_id": "c4780ee6",
        "raw_output": {
          "data": [
            {
              "score": 0.3736440293740152,
              "paper": {
                "corpusId": "277502453",
                "title": "Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions",
                "authors": [
                  "J. Choi",
                  "Junoh Kang",
                  "Bohyung Han"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2504.01855, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "We further apply the proposed method to advanced ODE samplers with higher-order accuracy. Table 2 presents the effectiveness of RX-DPM when applied to DPM-Solvers (Lu et al., 2022) on CIFAR-10 and LSUN Bedroom (Yu et al., 2015). Among the variations of DPM solvers, we utilize the singlestep versions of DPM-Solver-2 and DPM-Solver-3. Note that, since a single-step DPM-solver-n can be considered as an n th -order Runge-Kutta-like solver, we apply RX-DPM with p = n + 1 in Equation ( 22) for the DPM-solver-n. Additionally, we compare our method with another accelerated diffusion sampler, DEIS (Zhang & Chen, 2023), for class-conditioned image generation on ImageNet (64 × 64) in Table 4 of Appendix B.1. As shown in the results, RX-DPM consistently achieves the best performance across all NFEs. \n\nAs another type of advanced sampler, we consider PNDM (Liu et al., 2022). S-PNDM and F-PNDM employ linear multistep methods, specifically the 2-step and 4-step Adams-Bashforth methods, respectively, except for the initial few time steps. Accordingly, we apply RX-DPM with p = 3 and p = 5 in Equation ( 22) for S-PNDM and F-PNDM, respectively. The results on the CIFAR-10, CelebA (Liu et al., 2015), and LSUN Church (Yu et al., 2015) datasets are presented in Table 3. While RX-DPM improves performance in most cases, an exception arises with F-PNDM on the LSUN Church dataset, where RX-DPM does not provide a clear advantage. Upon analysis, we observe that the baseline performance of F-PNDM is highest when using 10 time steps and degrades as the number of steps increases (Liu et al., 2022).",
                "snippetKind": "body",
                "section": "COMPARISONS ON HIGHER-ORDER SOLVERS",
                "snippetOffset": {
                  "start": 22681,
                  "end": 24275
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 163,
                      "end": 180,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 210,
                      "end": 227,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 855,
                      "end": 873,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1180,
                      "end": 1198,
                      "matchedPaperCorpusId": "459456"
                    },
                    {
                      "start": 1216,
                      "end": 1233,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 89
                    },
                    {
                      "start": 90,
                      "end": 228
                    },
                    {
                      "start": 229,
                      "end": 334
                    },
                    {
                      "start": 335,
                      "end": 510
                    },
                    {
                      "start": 511,
                      "end": 706
                    },
                    {
                      "start": 707,
                      "end": 798
                    },
                    {
                      "start": 801,
                      "end": 874
                    },
                    {
                      "start": 875,
                      "end": 1038
                    },
                    {
                      "start": 1039,
                      "end": 1143
                    },
                    {
                      "start": 1144,
                      "end": 1268
                    },
                    {
                      "start": 1269,
                      "end": 1426
                    },
                    {
                      "start": 1427,
                      "end": 1594
                    }
                  ]
                }
              }
            },
            {
              "score": 0.35609623633450327,
              "paper": {
                "corpusId": "271310356",
                "title": "Hyper-Spherical Optimal Transport for Semantic Alignment in Text-to-3D End-to-End Generation",
                "authors": [
                  "Zezeng Li",
                  "Weimin Wang",
                  "WenHai Li",
                  "Na Lei",
                  "Xianfeng Gu"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2407.14419, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Venue E2E Open 3D dataset Size Kiss3DGen [55] arXiv 2025 ✓ ✓ OBJ 100 TRELLIS [56] arXiv 2024 ✓ ✗ OBJ NA 3DTopia-XL [57] arXiv 2024 ✓ ✗ OBJ NA Ln3diff [58] ECCV 2024 ✓ ✓ SPN & OBJ NA Xcube [38] CVPR 2024 ✓ ✓ SPN & OBJ 30 EXIM [39] TOG 2023 ✓ ✓ SPN & 3DF NA Michelangelo [40] NIPS 2024 ✓ ✓ SPN 2592 Diffusion-SDF [17] CVPR 2023 ✓ ✓ Text2Shape NA Shap•E [18] arXiv 2023 ✓ ✓ Point-e NA TAPS3D [33] CVPR 2023 ✓ ✓ SPN 1000 SDFusion [7] CVPR 2023 ✓ ✓ Text2shape NA CLIP-Forge [16] CVPR 2022 ✓ ✓ SPN 234 Hunyuan3D [59] arXiv 2024 × ✓ OBJ 70 DreamMesh [54] ECCV achieved by integrating existing text-to-image algorithms. Michelangelo [40] aligns shape and clip text/image features through autoencoders to generate high-quality shapes, but there are still significant semantic inconsistencies in publicly available models. These CLIP-guided text-to-3D content generation methods have yielded impressive results, but as remarked in Dream3d [20], [40], most of them overlooked the gap between the text and image embedding spaces. Consequently, semantic alignment is the key to filling this gap and improving text-shape consistency.",
                "snippetKind": "body",
                "section": "Methods",
                "snippetOffset": {
                  "start": 6971,
                  "end": 8090
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 41,
                      "end": 45,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 77,
                      "end": 81,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 115,
                      "end": 119,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 150,
                      "end": 154,
                      "matchedPaperCorpusId": "268531938"
                    },
                    {
                      "start": 188,
                      "end": 192,
                      "matchedPaperCorpusId": "273025441"
                    },
                    {
                      "start": 225,
                      "end": 229,
                      "matchedPaperCorpusId": "265018909"
                    },
                    {
                      "start": 269,
                      "end": 273,
                      "matchedPaperCorpusId": "259287391"
                    },
                    {
                      "start": 311,
                      "end": 315,
                      "matchedPaperCorpusId": "254366593"
                    },
                    {
                      "start": 351,
                      "end": 355,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 389,
                      "end": 393,
                      "matchedPaperCorpusId": "257687804"
                    },
                    {
                      "start": 426,
                      "end": 429,
                      "matchedPaperCorpusId": "254408516"
                    },
                    {
                      "start": 469,
                      "end": 473,
                      "matchedPaperCorpusId": "238408362"
                    },
                    {
                      "start": 506,
                      "end": 510,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 543,
                      "end": 547,
                      "matchedPaperCorpusId": "272593104"
                    },
                    {
                      "start": 625,
                      "end": 629,
                      "matchedPaperCorpusId": "259287391"
                    },
                    {
                      "start": 929,
                      "end": 933,
                      "matchedPaperCorpusId": "255340806"
                    },
                    {
                      "start": 935,
                      "end": 939,
                      "matchedPaperCorpusId": "259287391"
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 611
                    },
                    {
                      "start": 612,
                      "end": 812
                    },
                    {
                      "start": 813,
                      "end": 1017
                    },
                    {
                      "start": 1018,
                      "end": 1119
                    }
                  ]
                }
              }
            },
            {
              "score": 0.3276843530888929,
              "paper": {
                "corpusId": "268063329",
                "title": "Trajectory Consistency Distillation",
                "authors": [
                  "Jianbin Zheng",
                  "Minghui Hu",
                  "Zhongyi Fan",
                  "Chaoyue Wang",
                  "Changxing Ding",
                  "Dacheng Tao",
                  "Tat-Jen Cham"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2402.19159, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "To illustrate the effectiveness and superiority of our methods, we perform qualitative and quantitative comparisons with prior works, including Euler (Karras et al., 2022), efficient numerical ODE solvers like DDIM (Song et al., 2020a) and DPM-Solver++(2S) (Lu et al., 2022b), and a relevant work LCM (Luo et al., 2023a) as baseline. \n\nQualitative Results. As illustrated in Figure 4, prior efficient numerical methods produce suboptimal images with 4 steps, while LCM can generate relatively better images. Our TCD further enhances visual quality. With an increased number of function evaluations (20 steps), the quality of samples generated by DDIM or DPM-Solver++(2S) improves rapidly. However, the improvement in LCM is not as noticeable, resulting in smoother and less detailed images due to the accumulated error in multistep sampling. In contrast, TCD addresses this flaw, producing more detailed images that surpass even the teacher model, e.g., SDXL with DDIM. \n\nQuantitative Comparison. For the quantitative evaluation, we conducted zero-shot image generation using 5K captions from COCO2017 validation set. We employed the Frechet Inception Distance (FID) and the Image Complexity Score (Feng et al., 2022) to assess the sample quality and visual complexity of generated images. Additionally, we used Image Reward (Xu et al., 2023) and PickScore (Kirstain et al., 2023) to quantify text-image alignment and human preference. As depicted in Table 1, TCD shows an improvement in the performance of LCM across various timesteps and metrics. In comparison to numerical ODE-Solver, TCD exhibits the ability to generate high-quality images in only 2 or 4 steps, surpassing them significantly. When increasing steps to 8 or 20, LCM's performance tends to decline, while TCD even outperforms its teacher in almost all metrics.",
                "snippetKind": "body",
                "section": "Main Results",
                "snippetOffset": {
                  "start": 30716,
                  "end": 32545
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 150,
                      "end": 171,
                      "matchedPaperCorpusId": "249240415"
                    },
                    {
                      "start": 215,
                      "end": 235,
                      "matchedPaperCorpusId": "222140788"
                    },
                    {
                      "start": 257,
                      "end": 275,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 301,
                      "end": 320,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1198,
                      "end": 1217,
                      "matchedPaperCorpusId": "259129772"
                    },
                    {
                      "start": 1325,
                      "end": 1342,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1357,
                      "end": 1380,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 333
                    },
                    {
                      "start": 336,
                      "end": 356
                    },
                    {
                      "start": 357,
                      "end": 507
                    },
                    {
                      "start": 508,
                      "end": 548
                    },
                    {
                      "start": 549,
                      "end": 688
                    },
                    {
                      "start": 689,
                      "end": 841
                    },
                    {
                      "start": 842,
                      "end": 969
                    },
                    {
                      "start": 972,
                      "end": 996
                    },
                    {
                      "start": 997,
                      "end": 1117
                    },
                    {
                      "start": 1118,
                      "end": 1289
                    },
                    {
                      "start": 1290,
                      "end": 1435
                    },
                    {
                      "start": 1436,
                      "end": 1548
                    },
                    {
                      "start": 1549,
                      "end": 1697
                    },
                    {
                      "start": 1698,
                      "end": 1829
                    }
                  ]
                }
              }
            },
            {
              "score": 0.3244780451268607,
              "paper": {
                "corpusId": "270064288",
                "title": "The Poisson Midpoint Method for Langevin Dynamics: Provably Efficient Discretization for Diffusion Models",
                "authors": [
                  "S. Kandasamy",
                  "Dheeraj M. Nagaraj"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2405.17068, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "For unconditional image generation of high-resolution images, third order (order=3) Multistep DPM-Solvers with uniform time steps are recommended. To ensure a competitive benchmark, we evaluate the DPM-Solver on six different settings by tuning the parameters 'order' and 'skip_type'. Our evaluations are shown in Table 7, where the best score for every setting, highlighted in bold, are chosen in our plots for comparison. We use the official code of [37] with parameters 'algorithm_type = dpmsolver' 'method = multistep' and vary the parameters 'order' and 'skip_type' accordingly.",
                "snippetKind": "body",
                "section": "B DPM-Solver Variant Details",
                "snippetOffset": {
                  "start": 28744,
                  "end": 29327
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 452,
                      "end": 456,
                      "matchedPaperCorpusId": "249879327"
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 146
                    },
                    {
                      "start": 147,
                      "end": 284
                    },
                    {
                      "start": 285,
                      "end": 423
                    },
                    {
                      "start": 424,
                      "end": 583
                    }
                  ]
                }
              }
            },
            {
              "score": 0.3213007535264759,
              "paper": {
                "corpusId": "268513515",
                "title": "Solving General Noisy Inverse Problem via Posterior Sampling: A Policy Gradient Viewpoint",
                "authors": [
                  "Haoyue Tang",
                  "Tian Xie",
                  "Aosong Feng",
                  "Hanyu Wang",
                  "Chenyang Zhang",
                  "Yang Bai"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2403.10585, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "All the experiments are implemented using NVIDIA A100 GPU.We display the running time for each image in Table 3.Notice that by using the DDPM solver, DPG takes more time than DPS due to MC sampling.However, the guidance score estimated by DPG is more accurate.Therefore, we have use the DDIM solver to retrieve images with less running time.",
                "snippetKind": "body",
                "section": "Runtime Comparisons",
                "snippetOffset": {
                  "start": 18816,
                  "end": 19157
                },
                "annotations": {
                  "refMentions": null,
                  "sentences": [
                    {
                      "start": 0,
                      "end": 58
                    },
                    {
                      "start": 58,
                      "end": 112
                    },
                    {
                      "start": 112,
                      "end": 198
                    },
                    {
                      "start": 198,
                      "end": 260
                    },
                    {
                      "start": 260,
                      "end": 341
                    }
                  ]
                }
              }
            }
          ],
          "retrievalVersion": "pa1-v1"
        },
        "documents": [
          {
            "id": "e7e34309-ade4-4c32-b243-6245bb88f9ff",
            "title": "Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions",
            "url": "",
            "snippet": "We further apply the proposed method to advanced ODE samplers with higher-order accuracy. Table 2 presents the effectiveness of RX-DPM when applied to DPM-Solvers (Lu et al., 2022) on CIFAR-10 and LSUN Bedroom (Yu et al., 2015). Among the variations of DPM solvers, we utilize the singlestep versions of DPM-Solver-2 and DPM-Solver-3. Note that, since a single-step DPM-solver-n can be considered as an n th -order Runge-Kutta-like solver, we apply RX-DPM with p = n + 1 in Equation ( 22) for the DPM-solver-n. Additionally, we compare our method with another accelerated diffusion sampler, DEIS (Zhang & Chen, 2023), for class-conditioned image generation on ImageNet (64 × 64) in Table 4 of Appendix B.1. As shown in the results, RX-DPM consistently achieves the best performance across all NFEs. \n\nAs another type of advanced sampler, we consider PNDM (Liu et al., 2022). S-PNDM and F-PNDM employ linear multistep methods, specifically the 2-step and 4-step Adams-Bashforth methods, respectively, except for the initial few time steps. Accordingly, we apply RX-DPM with p = 3 and p = 5 in Equation ( 22) for S-PNDM and F-PNDM, respectively. The results on the CIFAR-10, CelebA (Liu et al., 2015), and LSUN Church (Yu et al., 2015) datasets are presented in Table 3. While RX-DPM improves performance in most cases, an exception arises with F-PNDM on the LSUN Church dataset, where RX-DPM does not provide a clear advantage. Upon analysis, we observe that the baseline performance of F-PNDM is highest when using 10 time steps and degrades as the number of steps increases (Liu et al., 2022).",
            "text": "",
            "summary": null,
            "score": 0.3736440293740152,
            "error": null
          },
          {
            "id": "d26e6d5d-ee0c-44d7-a23c-9dba5dbd525a",
            "title": "Hyper-Spherical Optimal Transport for Semantic Alignment in Text-to-3D End-to-End Generation",
            "url": "",
            "snippet": "Venue E2E Open 3D dataset Size Kiss3DGen [55] arXiv 2025 ✓ ✓ OBJ 100 TRELLIS [56] arXiv 2024 ✓ ✗ OBJ NA 3DTopia-XL [57] arXiv 2024 ✓ ✗ OBJ NA Ln3diff [58] ECCV 2024 ✓ ✓ SPN & OBJ NA Xcube [38] CVPR 2024 ✓ ✓ SPN & OBJ 30 EXIM [39] TOG 2023 ✓ ✓ SPN & 3DF NA Michelangelo [40] NIPS 2024 ✓ ✓ SPN 2592 Diffusion-SDF [17] CVPR 2023 ✓ ✓ Text2Shape NA Shap•E [18] arXiv 2023 ✓ ✓ Point-e NA TAPS3D [33] CVPR 2023 ✓ ✓ SPN 1000 SDFusion [7] CVPR 2023 ✓ ✓ Text2shape NA CLIP-Forge [16] CVPR 2022 ✓ ✓ SPN 234 Hunyuan3D [59] arXiv 2024 × ✓ OBJ 70 DreamMesh [54] ECCV achieved by integrating existing text-to-image algorithms. Michelangelo [40] aligns shape and clip text/image features through autoencoders to generate high-quality shapes, but there are still significant semantic inconsistencies in publicly available models. These CLIP-guided text-to-3D content generation methods have yielded impressive results, but as remarked in Dream3d [20], [40], most of them overlooked the gap between the text and image embedding spaces. Consequently, semantic alignment is the key to filling this gap and improving text-shape consistency.",
            "text": "",
            "summary": null,
            "score": 0.35609623633450327,
            "error": null
          },
          {
            "id": "a18dccdd-93e8-42d7-add3-4535529610e4",
            "title": "Trajectory Consistency Distillation",
            "url": "",
            "snippet": "To illustrate the effectiveness and superiority of our methods, we perform qualitative and quantitative comparisons with prior works, including Euler (Karras et al., 2022), efficient numerical ODE solvers like DDIM (Song et al., 2020a) and DPM-Solver++(2S) (Lu et al., 2022b), and a relevant work LCM (Luo et al., 2023a) as baseline. \n\nQualitative Results. As illustrated in Figure 4, prior efficient numerical methods produce suboptimal images with 4 steps, while LCM can generate relatively better images. Our TCD further enhances visual quality. With an increased number of function evaluations (20 steps), the quality of samples generated by DDIM or DPM-Solver++(2S) improves rapidly. However, the improvement in LCM is not as noticeable, resulting in smoother and less detailed images due to the accumulated error in multistep sampling. In contrast, TCD addresses this flaw, producing more detailed images that surpass even the teacher model, e.g., SDXL with DDIM. \n\nQuantitative Comparison. For the quantitative evaluation, we conducted zero-shot image generation using 5K captions from COCO2017 validation set. We employed the Frechet Inception Distance (FID) and the Image Complexity Score (Feng et al., 2022) to assess the sample quality and visual complexity of generated images. Additionally, we used Image Reward (Xu et al., 2023) and PickScore (Kirstain et al., 2023) to quantify text-image alignment and human preference. As depicted in Table 1, TCD shows an improvement in the performance of LCM across various timesteps and metrics. In comparison to numerical ODE-Solver, TCD exhibits the ability to generate high-quality images in only 2 or 4 steps, surpassing them significantly. When increasing steps to 8 or 20, LCM's performance tends to decline, while TCD even outperforms its teacher in almost all metrics.",
            "text": "",
            "summary": null,
            "score": 0.3276843530888929,
            "error": null
          },
          {
            "id": "2bed0676-026e-4e76-81d1-3e38eb1ea23f",
            "title": "The Poisson Midpoint Method for Langevin Dynamics: Provably Efficient Discretization for Diffusion Models",
            "url": "",
            "snippet": "For unconditional image generation of high-resolution images, third order (order=3) Multistep DPM-Solvers with uniform time steps are recommended. To ensure a competitive benchmark, we evaluate the DPM-Solver on six different settings by tuning the parameters 'order' and 'skip_type'. Our evaluations are shown in Table 7, where the best score for every setting, highlighted in bold, are chosen in our plots for comparison. We use the official code of [37] with parameters 'algorithm_type = dpmsolver' 'method = multistep' and vary the parameters 'order' and 'skip_type' accordingly.",
            "text": "",
            "summary": null,
            "score": 0.3244780451268607,
            "error": null
          },
          {
            "id": "65008991-a3a3-4ad9-8f93-f82542628ece",
            "title": "Solving General Noisy Inverse Problem via Posterior Sampling: A Policy Gradient Viewpoint",
            "url": "",
            "snippet": "All the experiments are implemented using NVIDIA A100 GPU.We display the running time for each image in Table 3.Notice that by using the DDPM solver, DPG takes more time than DPS due to MC sampling.However, the guidance score estimated by DPG is more accurate.Therefore, we have use the DDIM solver to retrieve images with less running time.",
            "text": "",
            "summary": null,
            "score": 0.3213007535264759,
            "error": null
          }
        ],
        "query": "DPM-Solver-2 dense trajectories Liu Gong Liu 2022 2023 arXiv text-to-image"
      },
      {
        "tool_name": "snippet_search",
        "output": "Title: PixelFlow: Pixel-Space Generative Models with Flow\nSnippet: The Flow Matching algorithm [1,38,40] progressively transforms a sample from a prior distribution, which is typically a standard normal distribution, to the target data distribution. This is accomplished by defining a forward process consisting of a sequence of linear paths that directly connect samples from the prior distribution to corresponding \n\nPixelFlow for cascaded image generation from pixel space. We partition the entire generation procedure into series resolution stages. At the beginning of each resolution stage, we upscale the relatively noisy results from the preceding stage and use them as the starting point for the current stage. Consequently, as the resolution enhances, more refined samples can be obtained. \n\nsamples in the target distribution. During training, a training example is constructed by first sampling a target sample x 1 , drawing noise x 0 ∼ N (0, 1) from the standard normal distribution, and selecting a timestep t ∈ [0, 1]. The training example is then defined through a linear interpolation: \n\nThe model is trained to approximate the velocity defined by an ordinary differential equation (ODE), v t = dxt dt , enabling it to effectively guide the transformation from the intermediate sample x t to the real data sample x 1 . \n\nA notable advantage of Flow Matching is its ability to interpolate between two arbitrary distributions, not restricted to using only a standard Gaussian as the source domain. Consequently, in image generation tasks, Flow Matching extends beyond noise-to-image scenarios and can be effectively employed for diverse applications such as image-toimage translation.\n\nTitle: FlowSDF: Flow Matching for Medical Image Segmentation Using Distance Transforms\nSnippet: Flow matching has been shown to be a more robust and stable alternative to diffusion models offering enhanced performance (Lipman et al., 2022), and has recently been applied to high-quality, unconditional image synthesis (Esser et al., 2024). Moreover, recent studies demonstrated its effectiveness in various domains such as depth estimation, label-conditioned image generation and image inpainting (Dao et al., 2023;Gui et al., 2024;Yariv et al., 2023). The subsequent section will introduce flow matching in more detail.\n\nTitle: Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation\nSnippet: Flow matching is emerging as the competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution. The deterministic property is favored in many generative applications, such as image inversion (Pokle et al. 2023) and editing (Hu et al. 2024), as well as in video and beyond (Davtyan, Sameni, and Favaro 2023;Song et al. 2024;Gao et al. 2024), due to its fast generation capability and reduced need for large NFE (Liu, Gong, and Liu 2023;Lipman et al. 2023;Liu 2022;Dao et al. 2023). Recently, some works has linked the connection between diffusion models (known as score-based models) and flow matching (Kingma and Gao 2024;Ma et al. 2024). Given these advantages, SDv3 (Esser et al. 2024) has adopted flow matching as their core framework, combined with a powerful transformer-based architecture (Peebles and Xie 2022), resulting in groundbreaking image generation capabilities. However, the computational complexity of iterative sampling still hinders these models from achieving real-time performance and lags behind GAN counterparts (Kang et al. 2023;Sauer et al. 2023a). Therefore, developing one-step and few-step sampling techniques is crucial to strike a balance between generation quality and sampling speed.\n\nTitle: EventFlow: Forecasting Temporal Point Processes with Flow Matching\nSnippet: The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows (Papamakarios et al., 2021) and diffusion models (Ho et al., 2020;Song et al., 2021). Intuitively, these models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution. These models are a popular alternative to diffusion, providing greater flexibility in model design, with recent applications in image generation (Ma et al., 2024;Dao et al., 2023), DNA and protein design (Stark et al., 2024;Campbell et al., 2024), and point cloud generation (Buhmann et al., 2023;Wu et al., 2023). To the best of our knowledge, our work is the first to explore flow matching for TPPs.\n\nTitle: Weighted Conditional Flow Matching\nSnippet: We evaluate our flow matching framework across three complementary domains: 2D toy transports, unconditional image generation, and a fidelity and diversity analysis of the generated samples. In these experiments, we demonstrate our framework's performance and competitiveness in comparison to well-established baselines.",
        "called": true,
        "timeout": false,
        "runtime": 0.5977239608764648,
        "error": "",
        "call_id": "53505b66",
        "raw_output": {
          "data": [
            {
              "score": 0.6679016686217252,
              "paper": {
                "corpusId": "277667747",
                "title": "PixelFlow: Pixel-Space Generative Models with Flow",
                "authors": [
                  "Shoufa Chen",
                  "Chongjian Ge",
                  "Shilong Zhang",
                  "Peize Sun",
                  "Ping Luo"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2504.07963, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "The Flow Matching algorithm [1,38,40] progressively transforms a sample from a prior distribution, which is typically a standard normal distribution, to the target data distribution. This is accomplished by defining a forward process consisting of a sequence of linear paths that directly connect samples from the prior distribution to corresponding \n\nPixelFlow for cascaded image generation from pixel space. We partition the entire generation procedure into series resolution stages. At the beginning of each resolution stage, we upscale the relatively noisy results from the preceding stage and use them as the starting point for the current stage. Consequently, as the resolution enhances, more refined samples can be obtained. \n\nsamples in the target distribution. During training, a training example is constructed by first sampling a target sample x 1 , drawing noise x 0 ∼ N (0, 1) from the standard normal distribution, and selecting a timestep t ∈ [0, 1]. The training example is then defined through a linear interpolation: \n\nThe model is trained to approximate the velocity defined by an ordinary differential equation (ODE), v t = dxt dt , enabling it to effectively guide the transformation from the intermediate sample x t to the real data sample x 1 . \n\nA notable advantage of Flow Matching is its ability to interpolate between two arbitrary distributions, not restricted to using only a standard Gaussian as the source domain. Consequently, in image generation tasks, Flow Matching extends beyond noise-to-image scenarios and can be effectively employed for diverse applications such as image-toimage translation.",
                "snippetKind": "body",
                "section": "Preliminary: Flow Matching",
                "snippetOffset": {
                  "start": 5871,
                  "end": 7502
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 28,
                      "end": 31,
                      "matchedPaperCorpusId": "252668615"
                    },
                    {
                      "start": 31,
                      "end": 34,
                      "matchedPaperCorpusId": "252734897"
                    },
                    {
                      "start": 34,
                      "end": 37,
                      "matchedPaperCorpusId": "252111177"
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 182
                    },
                    {
                      "start": 183,
                      "end": 349
                    },
                    {
                      "start": 352,
                      "end": 409
                    },
                    {
                      "start": 410,
                      "end": 485
                    },
                    {
                      "start": 486,
                      "end": 651
                    },
                    {
                      "start": 652,
                      "end": 731
                    },
                    {
                      "start": 734,
                      "end": 769
                    },
                    {
                      "start": 770,
                      "end": 965
                    },
                    {
                      "start": 966,
                      "end": 1034
                    },
                    {
                      "start": 1037,
                      "end": 1267
                    },
                    {
                      "start": 1270,
                      "end": 1444
                    },
                    {
                      "start": 1445,
                      "end": 1631
                    }
                  ]
                }
              }
            },
            {
              "score": 0.6539952157147974,
              "paper": {
                "corpusId": "270068161",
                "title": "FlowSDF: Flow Matching for Medical Image Segmentation Using Distance Transforms",
                "authors": [
                  "L. Bogensperger",
                  "Dominik Narnhofer",
                  "Alexander Falk",
                  "Konrad Schindler",
                  "Thomas Pock"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2405.18087, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Flow matching has been shown to be a more robust and stable alternative to diffusion models offering enhanced performance (Lipman et al., 2022), and has recently been applied to high-quality, unconditional image synthesis (Esser et al., 2024). Moreover, recent studies demonstrated its effectiveness in various domains such as depth estimation, label-conditioned image generation and image inpainting (Dao et al., 2023;Gui et al., 2024;Yariv et al., 2023). The subsequent section will introduce flow matching in more detail.",
                "snippetKind": "body",
                "section": "Medical Image Segmentation",
                "snippetOffset": {
                  "start": 8974,
                  "end": 9498
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 122,
                      "end": 143,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 222,
                      "end": 242,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 401,
                      "end": 419,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 419,
                      "end": 436,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 436,
                      "end": 455,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 243
                    },
                    {
                      "start": 244,
                      "end": 456
                    },
                    {
                      "start": 457,
                      "end": 524
                    }
                  ]
                }
              }
            },
            {
              "score": 0.6051169825169789,
              "paper": {
                "corpusId": "274982059",
                "title": "Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation",
                "authors": [
                  "Quan Dao",
                  "Hao Phung",
                  "T. Dao",
                  "Dimitris N. Metaxas",
                  "Anh Tran"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.16906, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Flow matching is emerging as the competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution. The deterministic property is favored in many generative applications, such as image inversion (Pokle et al. 2023) and editing (Hu et al. 2024), as well as in video and beyond (Davtyan, Sameni, and Favaro 2023;Song et al. 2024;Gao et al. 2024), due to its fast generation capability and reduced need for large NFE (Liu, Gong, and Liu 2023;Lipman et al. 2023;Liu 2022;Dao et al. 2023). Recently, some works has linked the connection between diffusion models (known as score-based models) and flow matching (Kingma and Gao 2024;Ma et al. 2024). Given these advantages, SDv3 (Esser et al. 2024) has adopted flow matching as their core framework, combined with a powerful transformer-based architecture (Peebles and Xie 2022), resulting in groundbreaking image generation capabilities. However, the computational complexity of iterative sampling still hinders these models from achieving real-time performance and lags behind GAN counterparts (Kang et al. 2023;Sauer et al. 2023a). Therefore, developing one-step and few-step sampling techniques is crucial to strike a balance between generation quality and sampling speed.",
                "snippetKind": "body",
                "section": "Related Work Flow Matching",
                "snippetOffset": {
                  "start": 6118,
                  "end": 7394
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 252,
                      "end": 270,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 284,
                      "end": 300,
                      "matchedPaperCorpusId": "221640669"
                    },
                    {
                      "start": 333,
                      "end": 367,
                      "matchedPaperCorpusId": "254044658"
                    },
                    {
                      "start": 367,
                      "end": 384,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 384,
                      "end": 400,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 471,
                      "end": 496,
                      "matchedPaperCorpusId": "261697392"
                    },
                    {
                      "start": 496,
                      "end": 515,
                      "matchedPaperCorpusId": "252734897"
                    },
                    {
                      "start": 515,
                      "end": 524,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 524,
                      "end": 540,
                      "matchedPaperCorpusId": "265498823"
                    },
                    {
                      "start": 662,
                      "end": 683,
                      "matchedPaperCorpusId": "260332161"
                    },
                    {
                      "start": 683,
                      "end": 698,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 729,
                      "end": 747,
                      "matchedPaperCorpusId": "268247980"
                    },
                    {
                      "start": 1096,
                      "end": 1114,
                      "matchedPaperCorpusId": "257427461"
                    },
                    {
                      "start": 1114,
                      "end": 1132,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 156
                    },
                    {
                      "start": 157,
                      "end": 541
                    },
                    {
                      "start": 542,
                      "end": 699
                    },
                    {
                      "start": 700,
                      "end": 938
                    },
                    {
                      "start": 939,
                      "end": 1134
                    },
                    {
                      "start": 1135,
                      "end": 1276
                    }
                  ]
                }
              }
            },
            {
              "score": 0.5694838406665296,
              "paper": {
                "corpusId": "278960160",
                "title": "EventFlow: Forecasting Temporal Point Processes with Flow Matching",
                "authors": [
                  "Gavin Kerrigan",
                  "Kai Nelson",
                  "Padhraic Smyth"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2410.07430, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows (Papamakarios et al., 2021) and diffusion models (Ho et al., 2020;Song et al., 2021). Intuitively, these models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution. These models are a popular alternative to diffusion, providing greater flexibility in model design, with recent applications in image generation (Ma et al., 2024;Dao et al., 2023), DNA and protein design (Stark et al., 2024;Campbell et al., 2024), and point cloud generation (Buhmann et al., 2023;Wu et al., 2023). To the best of our knowledge, our work is the first to explore flow matching for TPPs.",
                "snippetKind": "body",
                "section": "Flow Matching",
                "snippetOffset": {
                  "start": 7146,
                  "end": 8024
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 77,
                      "end": 98,
                      "matchedPaperCorpusId": "252734897"
                    },
                    {
                      "start": 98,
                      "end": 129,
                      "matchedPaperCorpusId": "252668615"
                    },
                    {
                      "start": 129,
                      "end": 146,
                      "matchedPaperCorpusId": "252111177"
                    },
                    {
                      "start": 238,
                      "end": 265,
                      "matchedPaperCorpusId": "208637478"
                    },
                    {
                      "start": 287,
                      "end": 304,
                      "matchedPaperCorpusId": "219955663"
                    },
                    {
                      "start": 304,
                      "end": 322,
                      "matchedPaperCorpusId": "227209335"
                    },
                    {
                      "start": 622,
                      "end": 639,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 639,
                      "end": 656,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 681,
                      "end": 701,
                      "matchedPaperCorpusId": "267547708"
                    },
                    {
                      "start": 701,
                      "end": 723,
                      "matchedPaperCorpusId": "267523194"
                    },
                    {
                      "start": 752,
                      "end": 774,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 774,
                      "end": 790,
                      "matchedPaperCorpusId": "254246595"
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 323
                    },
                    {
                      "start": 324,
                      "end": 476
                    },
                    {
                      "start": 477,
                      "end": 791
                    },
                    {
                      "start": 792,
                      "end": 878
                    }
                  ]
                }
              }
            },
            {
              "score": 0.5528985147593463,
              "paper": {
                "corpusId": "280391810",
                "title": "Weighted Conditional Flow Matching",
                "authors": [
                  "Sergio Calvo-Ordoñez",
                  "Matthieu Meunier",
                  "Alvaro Cartea",
                  "Christoph Reisinger",
                  "Yarin Gal",
                  "José Miguel Hernández-Lobato"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2507.22270, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "We evaluate our flow matching framework across three complementary domains: 2D toy transports, unconditional image generation, and a fidelity and diversity analysis of the generated samples. In these experiments, we demonstrate our framework's performance and competitiveness in comparison to well-established baselines.",
                "snippetKind": "body",
                "section": "EXPERIMENTS",
                "snippetOffset": {
                  "start": 20105,
                  "end": 20425
                },
                "annotations": {
                  "refMentions": null,
                  "sentences": [
                    {
                      "start": 0,
                      "end": 190
                    },
                    {
                      "start": 191,
                      "end": 320
                    }
                  ]
                }
              }
            }
          ],
          "retrievalVersion": "pa1-v1"
        },
        "documents": [
          {
            "id": "02a0fbdc-1530-4044-a92a-c0e7c149d7bd",
            "title": "PixelFlow: Pixel-Space Generative Models with Flow",
            "url": "",
            "snippet": "The Flow Matching algorithm [1,38,40] progressively transforms a sample from a prior distribution, which is typically a standard normal distribution, to the target data distribution. This is accomplished by defining a forward process consisting of a sequence of linear paths that directly connect samples from the prior distribution to corresponding \n\nPixelFlow for cascaded image generation from pixel space. We partition the entire generation procedure into series resolution stages. At the beginning of each resolution stage, we upscale the relatively noisy results from the preceding stage and use them as the starting point for the current stage. Consequently, as the resolution enhances, more refined samples can be obtained. \n\nsamples in the target distribution. During training, a training example is constructed by first sampling a target sample x 1 , drawing noise x 0 ∼ N (0, 1) from the standard normal distribution, and selecting a timestep t ∈ [0, 1]. The training example is then defined through a linear interpolation: \n\nThe model is trained to approximate the velocity defined by an ordinary differential equation (ODE), v t = dxt dt , enabling it to effectively guide the transformation from the intermediate sample x t to the real data sample x 1 . \n\nA notable advantage of Flow Matching is its ability to interpolate between two arbitrary distributions, not restricted to using only a standard Gaussian as the source domain. Consequently, in image generation tasks, Flow Matching extends beyond noise-to-image scenarios and can be effectively employed for diverse applications such as image-toimage translation.",
            "text": "",
            "summary": null,
            "score": 0.6679016686217252,
            "error": null
          },
          {
            "id": "ca748eef-29ab-486b-86da-ed809c3ab2a5",
            "title": "FlowSDF: Flow Matching for Medical Image Segmentation Using Distance Transforms",
            "url": "",
            "snippet": "Flow matching has been shown to be a more robust and stable alternative to diffusion models offering enhanced performance (Lipman et al., 2022), and has recently been applied to high-quality, unconditional image synthesis (Esser et al., 2024). Moreover, recent studies demonstrated its effectiveness in various domains such as depth estimation, label-conditioned image generation and image inpainting (Dao et al., 2023;Gui et al., 2024;Yariv et al., 2023). The subsequent section will introduce flow matching in more detail.",
            "text": "",
            "summary": null,
            "score": 0.6539952157147974,
            "error": null
          },
          {
            "id": "86b608fe-1d80-4e15-a127-8bd889e8a8e5",
            "title": "Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation",
            "url": "",
            "snippet": "Flow matching is emerging as the competitive alternative to diffusion models, as it deterministically finds the mapping between noise and data distribution. The deterministic property is favored in many generative applications, such as image inversion (Pokle et al. 2023) and editing (Hu et al. 2024), as well as in video and beyond (Davtyan, Sameni, and Favaro 2023;Song et al. 2024;Gao et al. 2024), due to its fast generation capability and reduced need for large NFE (Liu, Gong, and Liu 2023;Lipman et al. 2023;Liu 2022;Dao et al. 2023). Recently, some works has linked the connection between diffusion models (known as score-based models) and flow matching (Kingma and Gao 2024;Ma et al. 2024). Given these advantages, SDv3 (Esser et al. 2024) has adopted flow matching as their core framework, combined with a powerful transformer-based architecture (Peebles and Xie 2022), resulting in groundbreaking image generation capabilities. However, the computational complexity of iterative sampling still hinders these models from achieving real-time performance and lags behind GAN counterparts (Kang et al. 2023;Sauer et al. 2023a). Therefore, developing one-step and few-step sampling techniques is crucial to strike a balance between generation quality and sampling speed.",
            "text": "",
            "summary": null,
            "score": 0.6051169825169789,
            "error": null
          },
          {
            "id": "e8b36acd-bf89-440b-bbf3-e8edade26642",
            "title": "EventFlow: Forecasting Temporal Point Processes with Flow Matching",
            "url": "",
            "snippet": "The recently introduced flow matching framework (or stochastic interpolants) (Lipman et al., 2023;Albergo & Vanden-Eijnden, 2023;Liu et al., 2023) describes a class of generative models which are closely related to both normalizing flows (Papamakarios et al., 2021) and diffusion models (Ho et al., 2020;Song et al., 2021). Intuitively, these models learn a path of probability distributions which interpolates between a fixed reference distribution and the data distribution. These models are a popular alternative to diffusion, providing greater flexibility in model design, with recent applications in image generation (Ma et al., 2024;Dao et al., 2023), DNA and protein design (Stark et al., 2024;Campbell et al., 2024), and point cloud generation (Buhmann et al., 2023;Wu et al., 2023). To the best of our knowledge, our work is the first to explore flow matching for TPPs.",
            "text": "",
            "summary": null,
            "score": 0.5694838406665296,
            "error": null
          },
          {
            "id": "42979813-cfd7-4b9e-afaa-246e59f83414",
            "title": "Weighted Conditional Flow Matching",
            "url": "",
            "snippet": "We evaluate our flow matching framework across three complementary domains: 2D toy transports, unconditional image generation, and a fidelity and diversity analysis of the generated samples. In these experiments, we demonstrate our framework's performance and competitiveness in comparison to well-established baselines.",
            "text": "",
            "summary": null,
            "score": 0.5528985147593463,
            "error": null
          }
        ],
        "query": "Flow Matching for Image Generation Lipman arXiv 2023"
      },
      {
        "tool_name": "snippet_search",
        "output": "Title: CoVAE: Consistency Training of Variational Autoencoders\nSnippet: We report in  (Lu et al., 2022) 10 4.70 DPM-Solver++ (Lu et al., 2025) 10 2.91 DPM-Solver-v3 (Zheng et al., 2023) 10 2.51 Score SDE (Song et al., 2021b) 2000 2.20 DDPM (Ho et al., 2020) 1000 3.17 Flow Matching (Lipman et al., 2023) 142 6.35 EDM (Karras et al., (Song et al., 2023) 1 3.55 2 2.93 sCD (Lu & Song, 2025) 1 3.66 2 2.52 CTM (Kim et al., 2024) 2 1.87\n\nTitle: SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers\nSnippet: Specifically, when t ≈ T , the data prediction model approximates a constant: \n\nThus, for t ≈ T , the data prediction model becomes approximately constant, and the discretization error for integrating this constant is significantly smaller than for the linear noise prediction model. This insight guides our development of an improved Flow-DPM-Solver based on DPM-Solver++ (Lu et al., 2022b), which adapts a velocity prediction model Sana to a data prediction one, enhancing performance for guided sampling. \n\nFlow-based DPM-Solver Algorithm. We present the rectified flow-based DPM-Solver sampling process in Algorithm 1. This modified algorithm incorporates several key changes: hyper-parameter and time-step transformations, as well as model output transformations. These adjustments are highlighted in blue to differentiate them from the original solver. \n\nIn addition to improvements in FID and CLIP-Score, which are shown in Figure 8 of the main paper, our Flow-DPM-Solver also demonstrates superior convergence speed and stability compared to the Flow-Euler sampler. As illustrated in Figure 10, Flow-DPM-Solver retains the strengths of the original DPM-Solver, converging in only 10-20 steps to produce stable, high-quality images. By comparison, the Flow-Euler sampler typically requires 30-50 steps to reach a stable result. \n\n11: \n\nif i < M then 13: \n\nQbuffer ← x θ (xt i , ti) \n\n14: \n\nend if 15: end for 16: return xt M Multi-Caption Auto-labeling Pipeline. In Figure 11, we present the results of our CLIP-Scorebased multi-caption auto-labeling pipeline, where each image is paired with its original prompt and 4 captions generated by different powerful VLMs. These captions complement each other, enhancing semantic alignment through their variations. \n\nTriton Acceleration Training/Inference Detail. This section describes how to accelerate the training inference with kernel fusion using Triton. Specifically, for the forward pass, the ReLU activations are fused to the end of QKV projection, the precision conversions and padding operations are fused to the start of KV and QKV multiplications, and the divisions are fused to the end of QKV\n\nTitle: How to build a consistency model: Learning flow maps via self-distillation\nSnippet: Flow matching and diffusion models. Our approach builds directly on methods from flow matching and stochastic interpolants (Lipman et al., 2022;Albergo and Vanden-Eijnden, 2022 (Song et al., 2020;Ho et al., 2020;Maoutsa et al., 2020;Boffi and Vanden-Eijnden, 2023). These methods define an ordinary differential equation whose solution evaluates the flow map at a single time. Due to the computational expense associated with solving these equations, a line of recent work asks how to resolve the flow more efficiently with higher-order numerical solvers (Dockhorn et al., 2022;Lu et al., 2022;Karras et al., 2022;Li et al., 2024) and parallel sampling schemes (Chen et al., 2024;Bortoli et al., 2025). Our approach instead estimates the flow map to enable accelerated sampling by avoiding the differential equation solve altogether. \n\nConsistency models. Appearing under several names, the flow map has become a central object of study in recent efforts to obtain accelerated inference. Consistency models (Song et al., 2023;Song and Dhariwal, 2023) estimate the single-time flow map to jump from any time s to data, given by X s,1 in our notation. Consistency trajectory models (Kim et al., 2024;Li and He, 2025;Luo et al., 2023) estimate the two-time flow map, enabling multistep sampling. Both approaches implicitly leverage the Eulerian characterization (9), which we find leads to gradient instability, explaining recent engineering efforts for stable training (Lu and Song, 2024). Progressive distillation (Salimans and Ho, 2022a) uses the semigroup condition (10) to train a model that can recursively replicate two steps of a pre-trained teacher. Progressive flow map matching (Boffi et al., 2024) enforces this iteratively over a flow map after pre-training, while shortcut models apply a discretized semigroup condition (Frans et al., 2024).\n\nTitle: CurveFlow: Curvature-Guided Flow Matching for Image Generation\nSnippet: Generative modeling has undergone a transformative shift with the emergence of diffusion-based approaches, which excel at generating high-quality images by progressively transforming noise into structured data (Ho, Jain, and Abbeel 2020). However, diffusion models, such as Denoising Diffusion Probabilistic Models (DDPMs) (Ho, Jain, and Abbeel 2020), rely on a highly temporally non-linear noise addition forward process and require many steps to sample high-quality data due to its stochastic inference process. Recent advances, such as Denoising Diffusion Implicit Models (DDIMs) (Song, Meng, and Ermon 2021) and DMP-Solver (Lu et al. 2022), have speeded up inference by modeling the inference process as a deterministic ordinary differential equation (ODE). Flow Matching (FM) models (Lipman et al. 2023;Albergo and Vanden-Eijnden 2023) learn a continuous flow of ODE that maps samples from a simple distribution (typically a standard Gaussian) to the data dis- Figure 1: Limitations of linear trajectory hypothesis in rectified flows (RFs). Rectified flow's linear trajectory hypothesis could break down when modeling complex data distributions. Real data typically resides on non-linear manifolds (blue curve), while rectified flows enforce linear paths (red dashed line) that deviate from the optimal transport path (green), leading to generation artifacts. As a result, the images generated by rectified flows may not accurately capture the semantics of the prompts. \n\ntribution with learned velocity fields. Compared to diffusion models such as DDPM and DDIM, flow matching models define the forward process through explicitly hypothesized trajectories, rather than a highly temporally non-linear noise addition forward process. The most popular flow matching model, Rectified Flow (RF) (Albergo and Vanden-Eijnden 2023), explicitly uses linear interpolation between data samples and noise (Gaussian samples) as the initial forward pro-arXiv:2508.15093v2\n\nTitle: SPIRiT-Diffusion: Self-Consistency Driven Diffusion Model for Accelerated MRI\nSnippet: 2022. \n\n[45] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu, \"Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps,\" arXiv preprint arXiv:2206.00927, 2022.",
        "called": true,
        "timeout": false,
        "runtime": 4.0719358921051025,
        "error": "",
        "call_id": "ffef5314",
        "raw_output": {
          "data": [
            {
              "score": 0.43920888697611304,
              "paper": {
                "corpusId": "280294138",
                "title": "CoVAE: Consistency Training of Variational Autoencoders",
                "authors": [
                  "Gianluigi Silvestri",
                  "Luca Ambrogioni"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2507.09103, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "We report in  (Lu et al., 2022) 10 4.70 DPM-Solver++ (Lu et al., 2025) 10 2.91 DPM-Solver-v3 (Zheng et al., 2023) 10 2.51 Score SDE (Song et al., 2021b) 2000 2.20 DDPM (Ho et al., 2020) 1000 3.17 Flow Matching (Lipman et al., 2023) 142 6.35 EDM (Karras et al., (Song et al., 2023) 1 3.55 2 2.93 sCD (Lu & Song, 2025) 1 3.66 2 2.52 CTM (Kim et al., 2024) 2 1.87",
                "snippetKind": "body",
                "section": "C.2 Broader comparison on CIFAR-10",
                "snippetOffset": {
                  "start": 32607,
                  "end": 32967
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 14,
                      "end": 31,
                      "matchedPaperCorpusId": "249282317"
                    },
                    {
                      "start": 53,
                      "end": 70,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 93,
                      "end": 113,
                      "matchedPaperCorpusId": "264405880"
                    },
                    {
                      "start": 132,
                      "end": 152,
                      "matchedPaperCorpusId": "227209335"
                    },
                    {
                      "start": 168,
                      "end": 185,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 210,
                      "end": 231,
                      "matchedPaperCorpusId": "252734897"
                    },
                    {
                      "start": 245,
                      "end": 260,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 261,
                      "end": 280,
                      "matchedPaperCorpusId": "257280191"
                    },
                    {
                      "start": 299,
                      "end": 316,
                      "matchedPaperCorpusId": "273350750"
                    },
                    {
                      "start": 335,
                      "end": 353,
                      "matchedPaperCorpusId": "263622294"
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 360
                    }
                  ]
                }
              }
            },
            {
              "score": 0.3946961894953656,
              "paper": {
                "corpusId": "273346094",
                "title": "SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers",
                "authors": [
                  "Enze Xie",
                  "Junsong Chen",
                  "Junyu Chen",
                  "Han Cai",
                  "Haotian Tang",
                  "Yujun Lin",
                  "Zhekai Zhang",
                  "Muyang Li",
                  "Ligeng Zhu",
                  "Yao Lu",
                  "Song Han"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2410.10629, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Specifically, when t ≈ T , the data prediction model approximates a constant: \n\nThus, for t ≈ T , the data prediction model becomes approximately constant, and the discretization error for integrating this constant is significantly smaller than for the linear noise prediction model. This insight guides our development of an improved Flow-DPM-Solver based on DPM-Solver++ (Lu et al., 2022b), which adapts a velocity prediction model Sana to a data prediction one, enhancing performance for guided sampling. \n\nFlow-based DPM-Solver Algorithm. We present the rectified flow-based DPM-Solver sampling process in Algorithm 1. This modified algorithm incorporates several key changes: hyper-parameter and time-step transformations, as well as model output transformations. These adjustments are highlighted in blue to differentiate them from the original solver. \n\nIn addition to improvements in FID and CLIP-Score, which are shown in Figure 8 of the main paper, our Flow-DPM-Solver also demonstrates superior convergence speed and stability compared to the Flow-Euler sampler. As illustrated in Figure 10, Flow-DPM-Solver retains the strengths of the original DPM-Solver, converging in only 10-20 steps to produce stable, high-quality images. By comparison, the Flow-Euler sampler typically requires 30-50 steps to reach a stable result. \n\n11: \n\nif i < M then 13: \n\nQbuffer ← x θ (xt i , ti) \n\n14: \n\nend if 15: end for 16: return xt M Multi-Caption Auto-labeling Pipeline. In Figure 11, we present the results of our CLIP-Scorebased multi-caption auto-labeling pipeline, where each image is paired with its original prompt and 4 captions generated by different powerful VLMs. These captions complement each other, enhancing semantic alignment through their variations. \n\nTriton Acceleration Training/Inference Detail. This section describes how to accelerate the training inference with kernel fusion using Triton. Specifically, for the forward pass, the ReLU activations are fused to the end of QKV projection, the precision conversions and padding operations are fused to the start of KV and QKV multiplications, and the divisions are fused to the end of QKV",
                "snippetKind": "body",
                "section": "B MORE IMPLEMENTATION DETAILS",
                "snippetOffset": {
                  "start": 31982,
                  "end": 34139
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 373,
                      "end": 391,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 77
                    },
                    {
                      "start": 80,
                      "end": 283
                    },
                    {
                      "start": 284,
                      "end": 507
                    },
                    {
                      "start": 510,
                      "end": 542
                    },
                    {
                      "start": 543,
                      "end": 622
                    },
                    {
                      "start": 623,
                      "end": 768
                    },
                    {
                      "start": 769,
                      "end": 858
                    },
                    {
                      "start": 861,
                      "end": 1073
                    },
                    {
                      "start": 1074,
                      "end": 1239
                    },
                    {
                      "start": 1240,
                      "end": 1334
                    },
                    {
                      "start": 1337,
                      "end": 1340
                    },
                    {
                      "start": 1343,
                      "end": 1360
                    },
                    {
                      "start": 1363,
                      "end": 1388
                    },
                    {
                      "start": 1391,
                      "end": 1394
                    },
                    {
                      "start": 1397,
                      "end": 1469
                    },
                    {
                      "start": 1470,
                      "end": 1672
                    },
                    {
                      "start": 1673,
                      "end": 1765
                    },
                    {
                      "start": 1768,
                      "end": 1814
                    },
                    {
                      "start": 1815,
                      "end": 1911
                    },
                    {
                      "start": 1912,
                      "end": 2157
                    }
                  ]
                }
              }
            },
            {
              "score": 0.39434271569409546,
              "paper": {
                "corpusId": "278905945",
                "title": "How to build a consistency model: Learning flow maps via self-distillation",
                "authors": [
                  "Nicholas M. Boffi",
                  "M. S. Albergo",
                  "Eric Vanden-Eijnden"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2505.18825, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Flow matching and diffusion models. Our approach builds directly on methods from flow matching and stochastic interpolants (Lipman et al., 2022;Albergo and Vanden-Eijnden, 2022 (Song et al., 2020;Ho et al., 2020;Maoutsa et al., 2020;Boffi and Vanden-Eijnden, 2023). These methods define an ordinary differential equation whose solution evaluates the flow map at a single time. Due to the computational expense associated with solving these equations, a line of recent work asks how to resolve the flow more efficiently with higher-order numerical solvers (Dockhorn et al., 2022;Lu et al., 2022;Karras et al., 2022;Li et al., 2024) and parallel sampling schemes (Chen et al., 2024;Bortoli et al., 2025). Our approach instead estimates the flow map to enable accelerated sampling by avoiding the differential equation solve altogether. \n\nConsistency models. Appearing under several names, the flow map has become a central object of study in recent efforts to obtain accelerated inference. Consistency models (Song et al., 2023;Song and Dhariwal, 2023) estimate the single-time flow map to jump from any time s to data, given by X s,1 in our notation. Consistency trajectory models (Kim et al., 2024;Li and He, 2025;Luo et al., 2023) estimate the two-time flow map, enabling multistep sampling. Both approaches implicitly leverage the Eulerian characterization (9), which we find leads to gradient instability, explaining recent engineering efforts for stable training (Lu and Song, 2024). Progressive distillation (Salimans and Ho, 2022a) uses the semigroup condition (10) to train a model that can recursively replicate two steps of a pre-trained teacher. Progressive flow map matching (Boffi et al., 2024) enforces this iteratively over a flow map after pre-training, while shortcut models apply a discretized semigroup condition (Frans et al., 2024).",
                "snippetKind": "body",
                "section": "Related work",
                "snippetOffset": {
                  "start": 22020,
                  "end": 23872
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 123,
                      "end": 144,
                      "matchedPaperCorpusId": "252734897"
                    },
                    {
                      "start": 144,
                      "end": 176,
                      "matchedPaperCorpusId": "252668615"
                    },
                    {
                      "start": 177,
                      "end": 196,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 196,
                      "end": 212,
                      "matchedPaperCorpusId": "219955663"
                    },
                    {
                      "start": 212,
                      "end": 233,
                      "matchedPaperCorpusId": "219177326"
                    },
                    {
                      "start": 233,
                      "end": 264,
                      "matchedPaperCorpusId": "249538281"
                    },
                    {
                      "start": 555,
                      "end": 578,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 578,
                      "end": 594,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 594,
                      "end": 614,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 614,
                      "end": 630,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 661,
                      "end": 680,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 680,
                      "end": 701,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1007,
                      "end": 1026,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1026,
                      "end": 1050,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1180,
                      "end": 1198,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1198,
                      "end": 1214,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1214,
                      "end": 1231,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1467,
                      "end": 1486,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1513,
                      "end": 1537,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 35
                    },
                    {
                      "start": 36,
                      "end": 265
                    },
                    {
                      "start": 266,
                      "end": 376
                    },
                    {
                      "start": 377,
                      "end": 702
                    },
                    {
                      "start": 703,
                      "end": 833
                    },
                    {
                      "start": 836,
                      "end": 855
                    },
                    {
                      "start": 856,
                      "end": 987
                    },
                    {
                      "start": 988,
                      "end": 1149
                    },
                    {
                      "start": 1150,
                      "end": 1292
                    },
                    {
                      "start": 1293,
                      "end": 1487
                    },
                    {
                      "start": 1488,
                      "end": 1655
                    },
                    {
                      "start": 1656,
                      "end": 1852
                    }
                  ]
                }
              }
            },
            {
              "score": 0.3940454914431184,
              "paper": {
                "corpusId": "280700540",
                "title": "CurveFlow: Curvature-Guided Flow Matching for Image Generation",
                "authors": [
                  "Yan Luo",
                  "Drake Du",
                  "Hao Huang",
                  "Yi Fang",
                  "Mengyu Wang"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2508.15093, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "Generative modeling has undergone a transformative shift with the emergence of diffusion-based approaches, which excel at generating high-quality images by progressively transforming noise into structured data (Ho, Jain, and Abbeel 2020). However, diffusion models, such as Denoising Diffusion Probabilistic Models (DDPMs) (Ho, Jain, and Abbeel 2020), rely on a highly temporally non-linear noise addition forward process and require many steps to sample high-quality data due to its stochastic inference process. Recent advances, such as Denoising Diffusion Implicit Models (DDIMs) (Song, Meng, and Ermon 2021) and DMP-Solver (Lu et al. 2022), have speeded up inference by modeling the inference process as a deterministic ordinary differential equation (ODE). Flow Matching (FM) models (Lipman et al. 2023;Albergo and Vanden-Eijnden 2023) learn a continuous flow of ODE that maps samples from a simple distribution (typically a standard Gaussian) to the data dis- Figure 1: Limitations of linear trajectory hypothesis in rectified flows (RFs). Rectified flow's linear trajectory hypothesis could break down when modeling complex data distributions. Real data typically resides on non-linear manifolds (blue curve), while rectified flows enforce linear paths (red dashed line) that deviate from the optimal transport path (green), leading to generation artifacts. As a result, the images generated by rectified flows may not accurately capture the semantics of the prompts. \n\ntribution with learned velocity fields. Compared to diffusion models such as DDPM and DDIM, flow matching models define the forward process through explicitly hypothesized trajectories, rather than a highly temporally non-linear noise addition forward process. The most popular flow matching model, Rectified Flow (RF) (Albergo and Vanden-Eijnden 2023), explicitly uses linear interpolation between data samples and noise (Gaussian samples) as the initial forward pro-arXiv:2508.15093v2",
                "snippetKind": "body",
                "section": "Introduction",
                "snippetOffset": {
                  "start": 15,
                  "end": 1978
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 210,
                      "end": 237,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 323,
                      "end": 350,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 583,
                      "end": 611,
                      "matchedPaperCorpusId": "222140788"
                    },
                    {
                      "start": 627,
                      "end": 643,
                      "matchedPaperCorpusId": "249282317"
                    },
                    {
                      "start": 788,
                      "end": 808,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 808,
                      "end": 839,
                      "matchedPaperCorpusId": "252668615"
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 238
                    },
                    {
                      "start": 239,
                      "end": 513
                    },
                    {
                      "start": 514,
                      "end": 761
                    },
                    {
                      "start": 762,
                      "end": 1045
                    },
                    {
                      "start": 1046,
                      "end": 1150
                    },
                    {
                      "start": 1151,
                      "end": 1364
                    },
                    {
                      "start": 1365,
                      "end": 1474
                    },
                    {
                      "start": 1477,
                      "end": 1516
                    },
                    {
                      "start": 1517,
                      "end": 1737
                    },
                    {
                      "start": 1738,
                      "end": 1963
                    }
                  ]
                }
              }
            },
            {
              "score": 0.38314726988238745,
              "paper": {
                "corpusId": "258059872",
                "title": "SPIRiT-Diffusion: Self-Consistency Driven Diffusion Model for Accelerated MRI",
                "authors": [
                  "Zhuoxu Cui",
                  "Chentao Cao",
                  "Jing Cheng",
                  "Seng Jia",
                  "Hairong Zheng",
                  "Dong Liang",
                  "Yanjie Zhu"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": "GREEN",
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2304.05060, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "2022. \n\n[45] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu, \"Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps,\" arXiv preprint arXiv:2206.00927, 2022.",
                "snippetKind": "body",
                "section": "A. Estimating Score Functions",
                "snippetOffset": {
                  "start": 30905,
                  "end": 31103
                },
                "annotations": {
                  "refMentions": null,
                  "sentences": [
                    {
                      "start": 0,
                      "end": 5
                    },
                    {
                      "start": 8,
                      "end": 192
                    },
                    {
                      "start": 193,
                      "end": 198
                    }
                  ]
                }
              }
            }
          ],
          "retrievalVersion": "pa1-v1"
        },
        "documents": [
          {
            "id": "027ac5a0-79c1-4ad2-a6c5-cb4132e1ab62",
            "title": "CoVAE: Consistency Training of Variational Autoencoders",
            "url": "",
            "snippet": "We report in  (Lu et al., 2022) 10 4.70 DPM-Solver++ (Lu et al., 2025) 10 2.91 DPM-Solver-v3 (Zheng et al., 2023) 10 2.51 Score SDE (Song et al., 2021b) 2000 2.20 DDPM (Ho et al., 2020) 1000 3.17 Flow Matching (Lipman et al., 2023) 142 6.35 EDM (Karras et al., (Song et al., 2023) 1 3.55 2 2.93 sCD (Lu & Song, 2025) 1 3.66 2 2.52 CTM (Kim et al., 2024) 2 1.87",
            "text": "",
            "summary": null,
            "score": 0.43920888697611304,
            "error": null
          },
          {
            "id": "12e656ef-9bde-4a85-a750-bd06d6882524",
            "title": "SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers",
            "url": "",
            "snippet": "Specifically, when t ≈ T , the data prediction model approximates a constant: \n\nThus, for t ≈ T , the data prediction model becomes approximately constant, and the discretization error for integrating this constant is significantly smaller than for the linear noise prediction model. This insight guides our development of an improved Flow-DPM-Solver based on DPM-Solver++ (Lu et al., 2022b), which adapts a velocity prediction model Sana to a data prediction one, enhancing performance for guided sampling. \n\nFlow-based DPM-Solver Algorithm. We present the rectified flow-based DPM-Solver sampling process in Algorithm 1. This modified algorithm incorporates several key changes: hyper-parameter and time-step transformations, as well as model output transformations. These adjustments are highlighted in blue to differentiate them from the original solver. \n\nIn addition to improvements in FID and CLIP-Score, which are shown in Figure 8 of the main paper, our Flow-DPM-Solver also demonstrates superior convergence speed and stability compared to the Flow-Euler sampler. As illustrated in Figure 10, Flow-DPM-Solver retains the strengths of the original DPM-Solver, converging in only 10-20 steps to produce stable, high-quality images. By comparison, the Flow-Euler sampler typically requires 30-50 steps to reach a stable result. \n\n11: \n\nif i < M then 13: \n\nQbuffer ← x θ (xt i , ti) \n\n14: \n\nend if 15: end for 16: return xt M Multi-Caption Auto-labeling Pipeline. In Figure 11, we present the results of our CLIP-Scorebased multi-caption auto-labeling pipeline, where each image is paired with its original prompt and 4 captions generated by different powerful VLMs. These captions complement each other, enhancing semantic alignment through their variations. \n\nTriton Acceleration Training/Inference Detail. This section describes how to accelerate the training inference with kernel fusion using Triton. Specifically, for the forward pass, the ReLU activations are fused to the end of QKV projection, the precision conversions and padding operations are fused to the start of KV and QKV multiplications, and the divisions are fused to the end of QKV",
            "text": "",
            "summary": null,
            "score": 0.3946961894953656,
            "error": null
          },
          {
            "id": "7a0f1839-e753-45da-935b-060b6505ee0b",
            "title": "How to build a consistency model: Learning flow maps via self-distillation",
            "url": "",
            "snippet": "Flow matching and diffusion models. Our approach builds directly on methods from flow matching and stochastic interpolants (Lipman et al., 2022;Albergo and Vanden-Eijnden, 2022 (Song et al., 2020;Ho et al., 2020;Maoutsa et al., 2020;Boffi and Vanden-Eijnden, 2023). These methods define an ordinary differential equation whose solution evaluates the flow map at a single time. Due to the computational expense associated with solving these equations, a line of recent work asks how to resolve the flow more efficiently with higher-order numerical solvers (Dockhorn et al., 2022;Lu et al., 2022;Karras et al., 2022;Li et al., 2024) and parallel sampling schemes (Chen et al., 2024;Bortoli et al., 2025). Our approach instead estimates the flow map to enable accelerated sampling by avoiding the differential equation solve altogether. \n\nConsistency models. Appearing under several names, the flow map has become a central object of study in recent efforts to obtain accelerated inference. Consistency models (Song et al., 2023;Song and Dhariwal, 2023) estimate the single-time flow map to jump from any time s to data, given by X s,1 in our notation. Consistency trajectory models (Kim et al., 2024;Li and He, 2025;Luo et al., 2023) estimate the two-time flow map, enabling multistep sampling. Both approaches implicitly leverage the Eulerian characterization (9), which we find leads to gradient instability, explaining recent engineering efforts for stable training (Lu and Song, 2024). Progressive distillation (Salimans and Ho, 2022a) uses the semigroup condition (10) to train a model that can recursively replicate two steps of a pre-trained teacher. Progressive flow map matching (Boffi et al., 2024) enforces this iteratively over a flow map after pre-training, while shortcut models apply a discretized semigroup condition (Frans et al., 2024).",
            "text": "",
            "summary": null,
            "score": 0.39434271569409546,
            "error": null
          },
          {
            "id": "ed9da146-f687-4f42-8d1a-7fab7a306ec6",
            "title": "CurveFlow: Curvature-Guided Flow Matching for Image Generation",
            "url": "",
            "snippet": "Generative modeling has undergone a transformative shift with the emergence of diffusion-based approaches, which excel at generating high-quality images by progressively transforming noise into structured data (Ho, Jain, and Abbeel 2020). However, diffusion models, such as Denoising Diffusion Probabilistic Models (DDPMs) (Ho, Jain, and Abbeel 2020), rely on a highly temporally non-linear noise addition forward process and require many steps to sample high-quality data due to its stochastic inference process. Recent advances, such as Denoising Diffusion Implicit Models (DDIMs) (Song, Meng, and Ermon 2021) and DMP-Solver (Lu et al. 2022), have speeded up inference by modeling the inference process as a deterministic ordinary differential equation (ODE). Flow Matching (FM) models (Lipman et al. 2023;Albergo and Vanden-Eijnden 2023) learn a continuous flow of ODE that maps samples from a simple distribution (typically a standard Gaussian) to the data dis- Figure 1: Limitations of linear trajectory hypothesis in rectified flows (RFs). Rectified flow's linear trajectory hypothesis could break down when modeling complex data distributions. Real data typically resides on non-linear manifolds (blue curve), while rectified flows enforce linear paths (red dashed line) that deviate from the optimal transport path (green), leading to generation artifacts. As a result, the images generated by rectified flows may not accurately capture the semantics of the prompts. \n\ntribution with learned velocity fields. Compared to diffusion models such as DDPM and DDIM, flow matching models define the forward process through explicitly hypothesized trajectories, rather than a highly temporally non-linear noise addition forward process. The most popular flow matching model, Rectified Flow (RF) (Albergo and Vanden-Eijnden 2023), explicitly uses linear interpolation between data samples and noise (Gaussian samples) as the initial forward pro-arXiv:2508.15093v2",
            "text": "",
            "summary": null,
            "score": 0.3940454914431184,
            "error": null
          },
          {
            "id": "382dabd6-f865-44c0-95d6-454ee9192349",
            "title": "SPIRiT-Diffusion: Self-Consistency Driven Diffusion Model for Accelerated MRI",
            "url": "",
            "snippet": "2022. \n\n[45] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu, \"Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps,\" arXiv preprint arXiv:2206.00927, 2022.",
            "text": "",
            "summary": null,
            "score": 0.38314726988238745,
            "error": null
          }
        ],
        "query": "DPM-Solver-2 Lu et al. 2022 arXiv dense trajectories multi-step flow matching text-to-image"
      },
      {
        "tool_name": "snippet_search",
        "output": "Title: CoVAE: Consistency Training of Variational Autoencoders\nSnippet: We report in  (Lu et al., 2022) 10 4.70 DPM-Solver++ (Lu et al., 2025) 10 2.91 DPM-Solver-v3 (Zheng et al., 2023) 10 2.51 Score SDE (Song et al., 2021b) 2000 2.20 DDPM (Ho et al., 2020) 1000 3.17 Flow Matching (Lipman et al., 2023) 142 6.35 EDM (Karras et al., (Song et al., 2023) 1 3.55 2 2.93 sCD (Lu & Song, 2025) 1 3.66 2 2.52 CTM (Kim et al., 2024) 2 1.87\n\nTitle: Quantizing Diffusion Models from a Sampling-Aware Perspective\nSnippet: To counteract the swift accumulation of errors, we employ mixed-order trajectory quantization to foster a more linear probability flow. As detailed in Appendix A.1, for sampling within the interval (λ ti−1 , λ ti ), a first-order sampler directly evaluates ϵ θ (x λt i−1 , λ ti−1 ) to determine the sampling direction. In contrast, a k-order sampler generates k − 1 intermediate points {s i } k−2 i=0 and evaluates ϵ θ (x λs i , λ si ) at each point s i , iteratively refining the direction based on ϵ θ (x λt i−1 , λ ti−1 ). Each ϵ θ (x λs i , λ si ) encodes higher-order derivative information, thereby enhancing the directional precision of the sampling process. Drawing inspiration from this, we achieve mixed-order trajectory quantization by aligning the quantized first-order sampling direction trajectory {ε θ (x λt , λ t )} 0 t=T with the full-precision higher-order sampling direction trajectory {ϵ θ (x λs , λ s )} s∈S at the intermediate nodes. The quantization objective is defined as: \n\nFor example, taking DPM-Solver sampling as a case study. Given an initial value x T and M + 1 time steps {t i } M i=0 decreasing from t 0 = T to t M = 0. Starting with xt0 = x T , the DPM-Solver-1 sampling sequence {x ti } M i=1 is computed iteratively as follows: \n\nwhere h i = λ ti − λ ti−1 . The corresponding sampling formula for DPM-Solver-2 is given in Alg. 1. \n\nAlgorithm 1 DPM-Solver-2 \n\nRequire: Initial value x T , time steps \n\nBy aligning the quantized directional term εθ (x ti−1 , t i−1 ) with the full-precision directional term ϵ θ (u i , s i ), we can effectively linearize higher-order sampling trajectories, as illustrated in Fig. 2d. Dual-Order Trajectory Sampling.\n\nTitle: SPIRiT-Diffusion: Self-Consistency Driven Diffusion Model for Accelerated MRI\nSnippet: 2022. \n\n[45] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu, \"Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps,\" arXiv preprint arXiv:2206.00927, 2022.\n\nTitle: MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE\nSnippet: However, this often requires thousands of steps, resulting in significant overhead. DDIM (Song et al., 2020a) introduced deterministic sampling and proposed a probability ODE sampling approach, reducing the number of sampling steps to around 100. Subsequently, inspired by the Fokker-Planck equation (Risken & Risken, 1996), Song et al. (2020b) established a unification of SDE and ODE sampling methods from the perspective of the score function. Then, more higher-order ODE Preprint solvers were proposed e.g., DPM-Solver (Lu et al., 2022a) and DPM-Solver++ (Lu et al., 2022b), which utilize multistep methods for differential discretization. These approaches significantly reduce the number of sampling steps to around 10 while preserving accuracy. Higher-performance solvers (Zheng et al., 2023;Zhao et al., 2023) continue to be proposed; however, the gains are relatively marginal and have ultimately been replaced by the distillation method (Salimans & Ho, 2022;Yin et al., 2024). During the same period, flow matching models (Lipman et al., 2022;Esser et al., 2024) simplified and stabilized training by predicting the vector field velocity, enabling deterministic sampling with ODEs under 50 steps. Recent theoretical works (Gao et al., 2024;Albergo et al., 2023) has proven that the sampling method of flow matching is equivalent to DDIM, and demonstrated that flow matching models share the same equivalent SDE and ODE formulations as diffusion models. This provides important theoretical support and insights for our work, and we may explore interleaved sampling of SDE and ODE in probability flow models as a potential approach.\n\nTitle: Diffusion Sampling Correction via Approximately 10 Parameters\nSnippet: We investigated the impact of solver selection for generating ground truth trajectories on the performance of PAS using the CIFAR10 32×32 (Krizhevsky et al., 2009) and FFHQ 64×64 (Karras et al., 2019) datasets. We employed Heun's 2nd (Karras et al., 2022), DDIM (Song et al., 2021a), and DPM-Solver-2 (Lu et al., 2022a) solvers with 100 NFE to generate 10k trajectories for training the PAS to correct the DDIM solver, as shown in Table 9. Our findings indicate that the choice of solver for generating ground truth trajectories has negligible impact on the performance of PAS. This suggests that regardless of the solver used, a sufficient number of NFE (e.g., 100 NFE) enables the solving process to approximate the ground truth trajectories closely. Therefore, we simply fixed Heun's 2nd solver for all experiments.",
        "called": true,
        "timeout": false,
        "runtime": 3.6030614376068115,
        "error": "",
        "call_id": "ef8d8842",
        "raw_output": {
          "data": [
            {
              "score": 0.5497537367939214,
              "paper": {
                "corpusId": "280294138",
                "title": "CoVAE: Consistency Training of Variational Autoencoders",
                "authors": [
                  "Gianluigi Silvestri",
                  "Luca Ambrogioni"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2507.09103, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "We report in  (Lu et al., 2022) 10 4.70 DPM-Solver++ (Lu et al., 2025) 10 2.91 DPM-Solver-v3 (Zheng et al., 2023) 10 2.51 Score SDE (Song et al., 2021b) 2000 2.20 DDPM (Ho et al., 2020) 1000 3.17 Flow Matching (Lipman et al., 2023) 142 6.35 EDM (Karras et al., (Song et al., 2023) 1 3.55 2 2.93 sCD (Lu & Song, 2025) 1 3.66 2 2.52 CTM (Kim et al., 2024) 2 1.87",
                "snippetKind": "body",
                "section": "C.2 Broader comparison on CIFAR-10",
                "snippetOffset": {
                  "start": 32607,
                  "end": 32967
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 14,
                      "end": 31,
                      "matchedPaperCorpusId": "249282317"
                    },
                    {
                      "start": 53,
                      "end": 70,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 93,
                      "end": 113,
                      "matchedPaperCorpusId": "264405880"
                    },
                    {
                      "start": 132,
                      "end": 152,
                      "matchedPaperCorpusId": "227209335"
                    },
                    {
                      "start": 168,
                      "end": 185,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 210,
                      "end": 231,
                      "matchedPaperCorpusId": "252734897"
                    },
                    {
                      "start": 245,
                      "end": 260,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 261,
                      "end": 280,
                      "matchedPaperCorpusId": "257280191"
                    },
                    {
                      "start": 299,
                      "end": 316,
                      "matchedPaperCorpusId": "273350750"
                    },
                    {
                      "start": 335,
                      "end": 353,
                      "matchedPaperCorpusId": "263622294"
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 360
                    }
                  ]
                }
              }
            },
            {
              "score": 0.5222882748233887,
              "paper": {
                "corpusId": "278328051",
                "title": "Quantizing Diffusion Models from a Sampling-Aware Perspective",
                "authors": [
                  "Qian Zeng",
                  "Jie Song",
                  "Yuanyu Wan",
                  "Huiqiong Wang",
                  "Mingli Song"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2505.02242, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "To counteract the swift accumulation of errors, we employ mixed-order trajectory quantization to foster a more linear probability flow. As detailed in Appendix A.1, for sampling within the interval (λ ti−1 , λ ti ), a first-order sampler directly evaluates ϵ θ (x λt i−1 , λ ti−1 ) to determine the sampling direction. In contrast, a k-order sampler generates k − 1 intermediate points {s i } k−2 i=0 and evaluates ϵ θ (x λs i , λ si ) at each point s i , iteratively refining the direction based on ϵ θ (x λt i−1 , λ ti−1 ). Each ϵ θ (x λs i , λ si ) encodes higher-order derivative information, thereby enhancing the directional precision of the sampling process. Drawing inspiration from this, we achieve mixed-order trajectory quantization by aligning the quantized first-order sampling direction trajectory {ε θ (x λt , λ t )} 0 t=T with the full-precision higher-order sampling direction trajectory {ϵ θ (x λs , λ s )} s∈S at the intermediate nodes. The quantization objective is defined as: \n\nFor example, taking DPM-Solver sampling as a case study. Given an initial value x T and M + 1 time steps {t i } M i=0 decreasing from t 0 = T to t M = 0. Starting with xt0 = x T , the DPM-Solver-1 sampling sequence {x ti } M i=1 is computed iteratively as follows: \n\nwhere h i = λ ti − λ ti−1 . The corresponding sampling formula for DPM-Solver-2 is given in Alg. 1. \n\nAlgorithm 1 DPM-Solver-2 \n\nRequire: Initial value x T , time steps \n\nBy aligning the quantized directional term εθ (x ti−1 , t i−1 ) with the full-precision directional term ϵ θ (u i , s i ), we can effectively linearize higher-order sampling trajectories, as illustrated in Fig. 2d. Dual-Order Trajectory Sampling.",
                "snippetKind": "body",
                "section": "Mixed-Order Trajectory Alignment",
                "snippetOffset": {
                  "start": 14636,
                  "end": 16320
                },
                "annotations": {
                  "refMentions": null,
                  "sentences": [
                    {
                      "start": 0,
                      "end": 135
                    },
                    {
                      "start": 136,
                      "end": 318
                    },
                    {
                      "start": 319,
                      "end": 525
                    },
                    {
                      "start": 526,
                      "end": 665
                    },
                    {
                      "start": 666,
                      "end": 955
                    },
                    {
                      "start": 956,
                      "end": 997
                    },
                    {
                      "start": 1000,
                      "end": 1056
                    },
                    {
                      "start": 1057,
                      "end": 1264
                    },
                    {
                      "start": 1267,
                      "end": 1294
                    },
                    {
                      "start": 1295,
                      "end": 1366
                    },
                    {
                      "start": 1369,
                      "end": 1393
                    },
                    {
                      "start": 1396,
                      "end": 1435
                    },
                    {
                      "start": 1438,
                      "end": 1652
                    },
                    {
                      "start": 1653,
                      "end": 1684
                    }
                  ]
                }
              }
            },
            {
              "score": 0.5084549193375264,
              "paper": {
                "corpusId": "258059872",
                "title": "SPIRiT-Diffusion: Self-Consistency Driven Diffusion Model for Accelerated MRI",
                "authors": [
                  "Zhuoxu Cui",
                  "Chentao Cao",
                  "Jing Cheng",
                  "Seng Jia",
                  "Hairong Zheng",
                  "Dong Liang",
                  "Yanjie Zhu"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": "GREEN",
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2304.05060, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "2022. \n\n[45] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu, \"Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps,\" arXiv preprint arXiv:2206.00927, 2022.",
                "snippetKind": "body",
                "section": "A. Estimating Score Functions",
                "snippetOffset": {
                  "start": 30905,
                  "end": 31103
                },
                "annotations": {
                  "refMentions": null,
                  "sentences": [
                    {
                      "start": 0,
                      "end": 5
                    },
                    {
                      "start": 8,
                      "end": 192
                    },
                    {
                      "start": 193,
                      "end": 198
                    }
                  ]
                }
              }
            },
            {
              "score": 0.49945335128994395,
              "paper": {
                "corpusId": "280337225",
                "title": "MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE",
                "authors": [
                  "Junzhe Li",
                  "Yutao Cui",
                  "Tao Huang",
                  "Yinping Ma",
                  "Chun Fan",
                  "Miles Yang",
                  "Zhao Zhong"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2507.21802, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "However, this often requires thousands of steps, resulting in significant overhead. DDIM (Song et al., 2020a) introduced deterministic sampling and proposed a probability ODE sampling approach, reducing the number of sampling steps to around 100. Subsequently, inspired by the Fokker-Planck equation (Risken & Risken, 1996), Song et al. (2020b) established a unification of SDE and ODE sampling methods from the perspective of the score function. Then, more higher-order ODE Preprint solvers were proposed e.g., DPM-Solver (Lu et al., 2022a) and DPM-Solver++ (Lu et al., 2022b), which utilize multistep methods for differential discretization. These approaches significantly reduce the number of sampling steps to around 10 while preserving accuracy. Higher-performance solvers (Zheng et al., 2023;Zhao et al., 2023) continue to be proposed; however, the gains are relatively marginal and have ultimately been replaced by the distillation method (Salimans & Ho, 2022;Yin et al., 2024). During the same period, flow matching models (Lipman et al., 2022;Esser et al., 2024) simplified and stabilized training by predicting the vector field velocity, enabling deterministic sampling with ODEs under 50 steps. Recent theoretical works (Gao et al., 2024;Albergo et al., 2023) has proven that the sampling method of flow matching is equivalent to DDIM, and demonstrated that flow matching models share the same equivalent SDE and ODE formulations as diffusion models. This provides important theoretical support and insights for our work, and we may explore interleaved sampling of SDE and ODE in probability flow models as a potential approach.",
                "snippetKind": "body",
                "section": "RL FOR IMAGE GENERATION",
                "snippetOffset": {
                  "start": 6976,
                  "end": 8615
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 89,
                      "end": 109,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 300,
                      "end": 323,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 325,
                      "end": 344,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 523,
                      "end": 541,
                      "matchedPaperCorpusId": "249282317"
                    },
                    {
                      "start": 559,
                      "end": 577,
                      "matchedPaperCorpusId": "253254916"
                    },
                    {
                      "start": 778,
                      "end": 798,
                      "matchedPaperCorpusId": "264405880"
                    },
                    {
                      "start": 798,
                      "end": 816,
                      "matchedPaperCorpusId": "256697404"
                    },
                    {
                      "start": 946,
                      "end": 967,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 967,
                      "end": 984,
                      "matchedPaperCorpusId": "265506768"
                    },
                    {
                      "start": 1031,
                      "end": 1052,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1052,
                      "end": 1071,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1231,
                      "end": 1249,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 1249,
                      "end": 1270,
                      "matchedPaperCorpusId": null
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 83
                    },
                    {
                      "start": 84,
                      "end": 246
                    },
                    {
                      "start": 247,
                      "end": 446
                    },
                    {
                      "start": 447,
                      "end": 643
                    },
                    {
                      "start": 644,
                      "end": 750
                    },
                    {
                      "start": 751,
                      "end": 985
                    },
                    {
                      "start": 986,
                      "end": 1205
                    },
                    {
                      "start": 1206,
                      "end": 1461
                    },
                    {
                      "start": 1462,
                      "end": 1639
                    }
                  ]
                }
              }
            },
            {
              "score": 0.485119435206101,
              "paper": {
                "corpusId": "273962742",
                "title": "Diffusion Sampling Correction via Approximately 10 Parameters",
                "authors": [
                  "Guangyi Wang",
                  "Wei Peng",
                  "Lijiang Li",
                  "Wenyu Chen",
                  "Yuren Cai",
                  "Songzhi Su"
                ],
                "openAccessInfo": {
                  "license": null,
                  "status": null,
                  "disclaimer": "Notice: This snippet is extracted from the open access paper or abstract available at https://arxiv.org/abs/2411.06503, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
                }
              },
              "snippet": {
                "text": "We investigated the impact of solver selection for generating ground truth trajectories on the performance of PAS using the CIFAR10 32×32 (Krizhevsky et al., 2009) and FFHQ 64×64 (Karras et al., 2019) datasets. We employed Heun's 2nd (Karras et al., 2022), DDIM (Song et al., 2021a), and DPM-Solver-2 (Lu et al., 2022a) solvers with 100 NFE to generate 10k trajectories for training the PAS to correct the DDIM solver, as shown in Table 9. Our findings indicate that the choice of solver for generating ground truth trajectories has negligible impact on the performance of PAS. This suggests that regardless of the solver used, a sufficient number of NFE (e.g., 100 NFE) enables the solving process to approximate the ground truth trajectories closely. Therefore, we simply fixed Heun's 2nd solver for all experiments.",
                "snippetKind": "body",
                "section": "Solvers for trajectory generation",
                "snippetOffset": {
                  "start": 43991,
                  "end": 44809
                },
                "annotations": {
                  "refMentions": [
                    {
                      "start": 138,
                      "end": 163,
                      "matchedPaperCorpusId": null
                    },
                    {
                      "start": 179,
                      "end": 200,
                      "matchedPaperCorpusId": "54482423"
                    },
                    {
                      "start": 234,
                      "end": 255,
                      "matchedPaperCorpusId": "249240415"
                    },
                    {
                      "start": 262,
                      "end": 282,
                      "matchedPaperCorpusId": "222140788"
                    },
                    {
                      "start": 301,
                      "end": 319,
                      "matchedPaperCorpusId": "249282317"
                    }
                  ],
                  "sentences": [
                    {
                      "start": 0,
                      "end": 210
                    },
                    {
                      "start": 211,
                      "end": 439
                    },
                    {
                      "start": 440,
                      "end": 577
                    },
                    {
                      "start": 578,
                      "end": 752
                    },
                    {
                      "start": 753,
                      "end": 818
                    }
                  ]
                }
              }
            }
          ],
          "retrievalVersion": "pa1-v1"
        },
        "documents": [
          {
            "id": "c782d490-0abb-4d0b-9852-cf353f4bbd21",
            "title": "CoVAE: Consistency Training of Variational Autoencoders",
            "url": "",
            "snippet": "We report in  (Lu et al., 2022) 10 4.70 DPM-Solver++ (Lu et al., 2025) 10 2.91 DPM-Solver-v3 (Zheng et al., 2023) 10 2.51 Score SDE (Song et al., 2021b) 2000 2.20 DDPM (Ho et al., 2020) 1000 3.17 Flow Matching (Lipman et al., 2023) 142 6.35 EDM (Karras et al., (Song et al., 2023) 1 3.55 2 2.93 sCD (Lu & Song, 2025) 1 3.66 2 2.52 CTM (Kim et al., 2024) 2 1.87",
            "text": "",
            "summary": null,
            "score": 0.5497537367939214,
            "error": null
          },
          {
            "id": "d8cc1a57-d935-48a3-b7f9-a036ff6ff25c",
            "title": "Quantizing Diffusion Models from a Sampling-Aware Perspective",
            "url": "",
            "snippet": "To counteract the swift accumulation of errors, we employ mixed-order trajectory quantization to foster a more linear probability flow. As detailed in Appendix A.1, for sampling within the interval (λ ti−1 , λ ti ), a first-order sampler directly evaluates ϵ θ (x λt i−1 , λ ti−1 ) to determine the sampling direction. In contrast, a k-order sampler generates k − 1 intermediate points {s i } k−2 i=0 and evaluates ϵ θ (x λs i , λ si ) at each point s i , iteratively refining the direction based on ϵ θ (x λt i−1 , λ ti−1 ). Each ϵ θ (x λs i , λ si ) encodes higher-order derivative information, thereby enhancing the directional precision of the sampling process. Drawing inspiration from this, we achieve mixed-order trajectory quantization by aligning the quantized first-order sampling direction trajectory {ε θ (x λt , λ t )} 0 t=T with the full-precision higher-order sampling direction trajectory {ϵ θ (x λs , λ s )} s∈S at the intermediate nodes. The quantization objective is defined as: \n\nFor example, taking DPM-Solver sampling as a case study. Given an initial value x T and M + 1 time steps {t i } M i=0 decreasing from t 0 = T to t M = 0. Starting with xt0 = x T , the DPM-Solver-1 sampling sequence {x ti } M i=1 is computed iteratively as follows: \n\nwhere h i = λ ti − λ ti−1 . The corresponding sampling formula for DPM-Solver-2 is given in Alg. 1. \n\nAlgorithm 1 DPM-Solver-2 \n\nRequire: Initial value x T , time steps \n\nBy aligning the quantized directional term εθ (x ti−1 , t i−1 ) with the full-precision directional term ϵ θ (u i , s i ), we can effectively linearize higher-order sampling trajectories, as illustrated in Fig. 2d. Dual-Order Trajectory Sampling.",
            "text": "",
            "summary": null,
            "score": 0.5222882748233887,
            "error": null
          },
          {
            "id": "f295717b-e52b-4558-bd9a-ff9b2862cc16",
            "title": "SPIRiT-Diffusion: Self-Consistency Driven Diffusion Model for Accelerated MRI",
            "url": "",
            "snippet": "2022. \n\n[45] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu, \"Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps,\" arXiv preprint arXiv:2206.00927, 2022.",
            "text": "",
            "summary": null,
            "score": 0.5084549193375264,
            "error": null
          },
          {
            "id": "d3d6086c-7fdc-4ba6-a49d-7a8724272872",
            "title": "MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE",
            "url": "",
            "snippet": "However, this often requires thousands of steps, resulting in significant overhead. DDIM (Song et al., 2020a) introduced deterministic sampling and proposed a probability ODE sampling approach, reducing the number of sampling steps to around 100. Subsequently, inspired by the Fokker-Planck equation (Risken & Risken, 1996), Song et al. (2020b) established a unification of SDE and ODE sampling methods from the perspective of the score function. Then, more higher-order ODE Preprint solvers were proposed e.g., DPM-Solver (Lu et al., 2022a) and DPM-Solver++ (Lu et al., 2022b), which utilize multistep methods for differential discretization. These approaches significantly reduce the number of sampling steps to around 10 while preserving accuracy. Higher-performance solvers (Zheng et al., 2023;Zhao et al., 2023) continue to be proposed; however, the gains are relatively marginal and have ultimately been replaced by the distillation method (Salimans & Ho, 2022;Yin et al., 2024). During the same period, flow matching models (Lipman et al., 2022;Esser et al., 2024) simplified and stabilized training by predicting the vector field velocity, enabling deterministic sampling with ODEs under 50 steps. Recent theoretical works (Gao et al., 2024;Albergo et al., 2023) has proven that the sampling method of flow matching is equivalent to DDIM, and demonstrated that flow matching models share the same equivalent SDE and ODE formulations as diffusion models. This provides important theoretical support and insights for our work, and we may explore interleaved sampling of SDE and ODE in probability flow models as a potential approach.",
            "text": "",
            "summary": null,
            "score": 0.49945335128994395,
            "error": null
          },
          {
            "id": "d3d2a141-12b0-44f0-9647-8d28172d71dd",
            "title": "Diffusion Sampling Correction via Approximately 10 Parameters",
            "url": "",
            "snippet": "We investigated the impact of solver selection for generating ground truth trajectories on the performance of PAS using the CIFAR10 32×32 (Krizhevsky et al., 2009) and FFHQ 64×64 (Karras et al., 2019) datasets. We employed Heun's 2nd (Karras et al., 2022), DDIM (Song et al., 2021a), and DPM-Solver-2 (Lu et al., 2022a) solvers with 100 NFE to generate 10k trajectories for training the PAS to correct the DDIM solver, as shown in Table 9. Our findings indicate that the choice of solver for generating ground truth trajectories has negligible impact on the performance of PAS. This suggests that regardless of the solver used, a sufficient number of NFE (e.g., 100 NFE) enables the solving process to approximate the ground truth trajectories closely. Therefore, we simply fixed Heun's 2nd solver for all experiments.",
            "text": "",
            "summary": null,
            "score": 0.485119435206101,
            "error": null
          }
        ],
        "query": "DPM-Solver dense trajectories Lu 2022 arXiv trajectory sampling flow matching"
      }
    ]
  },
  "additional_output_data": {
    "browsed_links": [],
    "searched_links": [
      ""
    ],
    "total_tool_calls": 7,
    "total_failed_tool_calls": 0,
    "failed_tool_call_errors": []
  },
  "original_data": {
    "id": "9",
    "problem": "What are Flow Matching Models?",
    "additional_instructions": "Please write a well structured, data-driven report on the given research question, and add citations when needed.",
    "dataset_name": "sqav2"
  }
}